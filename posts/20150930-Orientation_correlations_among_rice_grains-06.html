<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2019-09-05 Thu 21:01 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Orientation correlations among rice grains, part 6: segmentation</title>
<meta name="generator" content="Org mode">
<link rel="stylesheet" href="../theme.css"/>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
<script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: {equationNumbers: {autoNumber: "AMS"}}});</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
extensions: ['tex2jax.js', 'TeX/AMSmath.js',
'TeX/AMSsymbols.js'],
jax: ['input/TeX', 'output/HTML-CSS'],
tex2jax: {
inlineMath: [ ['$','$'], ['\\(', '\\)'] ],
displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
processEscapes: true,
},
TeX: {
TagSide: 'left',
Macros: {
abs: ['\\left\|#1\\right\|', 1],
boxtimessym : '\\boxtimes^\\text s',
complexes: '\\mathbb C',
D: '\\mathrm{d}',
dS: ['\\operatorname{dS}_{#1}', 1],
dV: ['\\operatorname{dV}_{#1}', 1],
eff: '\\text{eff}',
integers: '\\mathbb Z',
meas: ['\\left\|#1\\right\|', 1],
naturals: '\\mathbb N',
rationals: '\\mathbb Q',
reals: '\\mathbb R',
tens: ['\\vec{#1}', 1],
tr: '\\operatorname{tr}',
transp: ['{#1}^{\\text T}', 1],
transpinv: ['{#1}^{-\\text T}', 1],
vec: ['{\\mathbf{#1}}', 1],
volavg: ['\\overline{#1}', 1],
}
},
'HTML-CSS': { availableFonts: ['TeX'] }
});
</script>
</head>
<body>
<div id="preamble" class="status">
<img id="banner" src="../images/banner.jpg"/>
<div class="navbar">
<span class="sitename"><a href="../index.html" title="">Sébastien Brisard's blog</a></span>
<ul>
<li><a href="../index.html" title="Home"><span class="fa fa-home"></span></a></li>
<li><a href="https://cv.archives-ouvertes.fr/sbrisard" title="About me"><span class="fa fa-user"></span></a></li>
<li><a href="archives.html" title="Archives"><span class="fa fa-archive"></span></a></li>
<li><a href="https://github.com/sbrisard" title="GitHub"><span class="fa fa-github"></span></a></li>
<li><a href="https://bitbucket.org/sbrisard" title="Bitbucket"><span class="fa fa-bitbucket"></span></a></li>
<li><a href="https://twitter.com/SebBrisard" title="Twitter"><span class="fa fa-twitter"></span></a></li>
<li><a href="../feed.xml" title="RSS"><span class="fa fa-rss"></span></a></li>
</ul>
</div>
<div id="titleblock">
<p class="date">2015-09-30</p>
<h1 class="title">Orientation correlations among rice grains, part 6: segmentation</h1>
</div>
</div>
<div id="content">
<h1 class="title">Orientation correlations among rice grains, part 6: segmentation</h1>
<p>
In the <a href="20150709-Orientation_correlations_among_rice_grains-05.html">previous instalment</a> of this series, I showed that a convincing binary image could be produced from the gray level 3D reconstruction of the assembly of rice grains, using Otsu's threshold. However, I intend to carry out statistical analyses of the <i>grains</i> themselves in the subsequent instalments. Therefore, instead of a binary image of the rice grains, what is really needed is a <i>labelled</i> image, where all voxels which are thought to belong to the same rice grain are tagged with the same label. This is called <i>segmentation</i>, which is the topic of the present post. I will first show that the most basic segmentation technique (namely, <a href="#orge97936a">detecting connected components</a> in the image) fails in the present case. This calls for a more elaborate strategy, based on the widely popular <a href="https://en.wikipedia.org/wiki/Watershed_(image_processing)">watershed</a> method. However, <a href="#org3a58377">blind application</a> of the standard watershed strategy leads to over-segmentation. This post will therefore close on a <a href="#org06d34a4">problem-dependent strategy</a> better suited to the present case.
</p>

<p>
Before we start, let me mention a book-keeping issue. Up to the previous post, 2D slices of the 3D image were stored in separate <code>*.tif</code> files, which is rather tedious to load and solve. From now on, I will store all analyses in a <code>*.hdf5</code> file. I am by no means an expert on this great file format (see <a href="https://www.hdfgroup.org/HDF5/">website</a>), but what I like about it is
</p>

<ol class="org-ol">
<li>it is language-agnostic,</li>
<li>it is platform- (and architecture-) independent: no indianness problem,</li>
<li>several arrays can be stored in the <i>same</i> file,</li>
<li>comments can be attached to a dataset.</li>
</ol>

<p>
The following code snippet (<a href="./20150930-Orientation_correlations_among_rice_grains-06/tif2hdf5.py">download</a>) converts the binary <code>*.tif</code> images into a single <code>*.hdf5</code> file. It uses the <a href="http://www.h5py.org/">h5py</a> library; <a href="http://www.pytables.org/">PyTables</a> is another option.
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> os.path

<span class="org-keyword">import</span> h5py
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> skimage.io

<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">'__main__'</span>:
    <span class="org-variable-name">root</span> =  os.path.join(<span class="org-string">'F:\\'</span>, <span class="org-string">'sebastien'</span>, <span class="org-string">'experimental_data'</span>, <span class="org-string">'navier'</span>,
                         <span class="org-string">'riz'</span>)
    <span class="org-variable-name">input_name</span> = os.path.join(root, <span class="org-string">'bin_4x4x4-otsu'</span>,
                              <span class="org-string">'rice-bin_4x4x4-otsu_126-{0:03d}.tif'</span>)
    <span class="org-variable-name">output_name</span> = os.path.join(root, <span class="org-string">'rice-bin_4x4x4.hdf5'</span>)
    <span class="org-variable-name">num_slices</span> = 172

    <span class="org-variable-name">binary</span> = <span class="org-constant">None</span>
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_slices):
        <span class="org-variable-name">slc</span> = skimage.io.imread(input_name.<span class="org-builtin">format</span>(i))
        <span class="org-keyword">if</span> binary <span class="org-keyword">is</span> <span class="org-constant">None</span>:
            <span class="org-variable-name">binary</span> = np.zeros((num_slices,)+slc.shape, dtype=slc.dtype)
        <span class="org-variable-name">binary</span>[i] = slc

    <span class="org-keyword">with</span> h5py.File(output_name, <span class="org-string">'w'</span>) <span class="org-keyword">as</span> f:
        <span class="org-variable-name">dset</span>=f.create_dataset(<span class="org-string">'binary'</span>, data=binary)
        <span class="org-variable-name">dset.attrs</span>[<span class="org-string">'description'</span>] = np.string_(<span class="org-string">'Otsu threshold 126'</span>)
</pre>
</div>

<p>
Now, on to segmentation!
</p>

<div id="outline-container-orgf3b7b2e" class="outline-2">
<h2 id="orgf3b7b2e">Detecting connected components <a id="orge97936a"></a></h2>
<div class="outline-text-2" id="text-orgf3b7b2e">
<p>
This is probably the most simple segmentation technique. In this approach, a <i>feature</i> is defined as a connected component of the image. Let's be honnest: it rarely works on real-life images, because most of the times, distinct objects usually touch, and therefore appear as connected. Fig. <a href="#org4afd297">1</a> shows that our 3D image is no exception to this rule!
</p>


<div id="org4afd297" class="figure">
<p><img src="./20150930-Orientation_correlations_among_rice_grains-06/binary.png" alt="binary.png" width="50%">
</p>
<p><span class="figure-number">Figure 1: </span>A slice of the binary image. Clearly, some rice grains are connected. In other words, detecting connected components is not a suitable strategy for the segmentation of rice grains.</p>
</div>

<p>
So, we should expect no miracle from this approach. However, it is interesting to show how easy it is to identify the connected components of an image, using the <code>scipy.ndimage</code> module (<a href="http://docs.scipy.org/doc/scipy/reference/ndimage.html">documentation</a>), in particular the <code>scipy.ndimage.label</code> function (<a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.measurements.label.html#scipy-ndimage-measurements-label">documentation</a>). Note the use of <code>np.ones((3, 3, 3))</code> as a structuring element, meaning 26-connectivity.
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">import</span> os.path

<span class="org-keyword">import</span> h5py
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> scipy <span class="org-keyword">import</span> ndimage <span class="org-keyword">as</span> ndi
<span class="org-keyword">from</span> skimage.io <span class="org-keyword">import</span> imsave

<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">'__main__'</span>:
    <span class="org-variable-name">root</span> =  os.path.join(<span class="org-string">'F:\\'</span>, <span class="org-string">'sebastien'</span>, <span class="org-string">'experimental_data'</span>, <span class="org-string">'navier'</span>,
                         <span class="org-string">'riz'</span>)
    <span class="org-keyword">with</span> h5py.File(os.path.join(root, <span class="org-string">'rice-bin_4x4x4.hdf5'</span>)) <span class="org-keyword">as</span> f:
        <span class="org-variable-name">binary</span> = np.asarray(f[<span class="org-string">'binary'</span>])

    <span class="org-keyword">print</span>(<span class="org-string">'Selecting markers from distance local maxima...'</span>)
    <span class="org-variable-name">labels</span>, <span class="org-variable-name">num_labels</span> = ndi.label(binary,
                                   structure=np.ones((3, 3, 3), dtype=np.int8))
    <span class="org-keyword">print</span>(<span class="org-string">'    ... found {} connected components'</span>.<span class="org-builtin">format</span>(num_labels))

    <span class="org-variable-name">index</span> = 100
    np.random.seed(20150928)
    <span class="org-variable-name">colors</span> = np.random.randint(255, size=(labels.<span class="org-builtin">max</span>()+1, 3)).astype(np.uint8)
    <span class="org-variable-name">colors</span>[0] = [0, 0, 0]

    imsave(<span class="org-string">'connected_components.png'</span>, colors[labels[index]])
</pre>
</div>

<p>
The above code snippet (<a href="./20150930-Orientation_correlations_among_rice_grains-06/connected_components.py">download</a>) detects 117 connected components, and produces the following colored image (one color per label), see Fig. <a href="#orgdb19e06">2</a>. Unsurprisingly, all grains are connected on this slice, and we have produced a very poor segmentation indeed!
</p>


<div id="orgdb19e06" class="figure">
<p><img src="./20150930-Orientation_correlations_among_rice_grains-06/connected_components.png" alt="connected_components.png" width="50%">
</p>
<p><span class="figure-number">Figure 2: </span>All rice grains of the slice shown on Fig. <a href="#org4afd297">1</a> are connected!</p>
</div>

<p>
To close this section, it should be noted that the last lines of the above script produce a color image where each label receives a random color. Standard color maps are indeed ill-suited to visualization of labelled images. Indeed, these color maps are most of the times smooth, which means that close labels are barely distinguishable. This is undesirable, since neighbouring features usually get close labels.
</p>

<p>
Also note the use of <a href="http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#indexing">advanced indexing</a> of the Numpy arrays (<code>colors[labels[index]]</code>)&#x2026; Python and Numpy rock!
</p>
</div>
</div>

<div id="outline-container-orgaaa21db" class="outline-2">
<h2 id="orgaaa21db">Watershed segmentation, blind application <a id="org3a58377"></a></h2>
<div class="outline-text-2" id="text-orgaaa21db">
<p>
The watershed segmentation is a very popular technique to segment overlapping objects. Describing this technique is out of the scope of this post. Suffice it to say that watershed segmentation is a three-step process
</p>

<ol class="org-ol">
<li>compute the <i>topography</i> of the image (usually, a gradient map or the opposite of the distance map to the background),</li>
<li>select seeds,</li>
<li>grow connected region from seeds.</li>
</ol>

<p>
The second step is the critical one, since each seed results in exactly one feature in the segmented image. Too many seeds result in an oversegmented image (grains are split), while too little seeds result in an under-segmented image (grains are merged).
</p>

<p>
While tedious, manual seeding is probably your best choice (as argued by <a href="http://emmanuelle.github.io/a-tutorial-on-segmentation.html#semi-supervised-approach-segmenting-the-image-from-user-defined-markers">Emmanuelle Gouillart</a>). There are about 2000 rice grains in the 3D image we are working with, so this semi-supervised approach is unfortunately not an option for us.
</p>

<p>
The standard unsupervised seeding technique consists in selecting the local maxima of the map of the distance to the background. The opposite of the distance map is then used as topography. This is essentially what the script below does (<a href="20150930-Orientation_correlations_among_rice_grains-06/watershed-distance_local_max.py">download</a>). It draws heavily on the example from the <a href="http://scikit-image.org/docs/dev/api/skimage.morphology.html#watershed">scikit-image</a> documentation.
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-doc">"""Watershed using local maxima of the distance map as seeds."""</span>

<span class="org-keyword">import</span> os.path

<span class="org-keyword">import</span> h5py
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> scipy <span class="org-keyword">import</span> ndimage <span class="org-keyword">as</span> ndi
<span class="org-keyword">from</span> skimage.feature <span class="org-keyword">import</span> peak_local_max
<span class="org-keyword">from</span> skimage.io <span class="org-keyword">import</span> imread, imsave, imshow
<span class="org-keyword">from</span> skimage.morphology <span class="org-keyword">import</span> watershed

<span class="org-keyword">def</span> <span class="org-function-name">markers_from_distance_local_max</span>(image, distance=<span class="org-constant">None</span>, min_distance=10):
    <span class="org-keyword">if</span> distance <span class="org-keyword">is</span> <span class="org-constant">None</span>:
        <span class="org-variable-name">distance</span> = ndi.distance_transform_edt(image)
    <span class="org-keyword">return</span>

<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">'__main__'</span>:
    <span class="org-variable-name">root</span> =  os.path.join(<span class="org-string">'F:\\'</span>, <span class="org-string">'sebastien'</span>, <span class="org-string">'experimental_data'</span>, <span class="org-string">'navier'</span>,
                         <span class="org-string">'riz'</span>)
    <span class="org-keyword">with</span> h5py.File(os.path.join(root, <span class="org-string">'rice-bin_4x4x4.hdf5'</span>)) <span class="org-keyword">as</span> f:
        <span class="org-variable-name">binary</span> = np.asarray(f[<span class="org-string">'binary'</span>])

    <span class="org-keyword">print</span>(<span class="org-string">'Computing distance transform'</span>)
    <span class="org-variable-name">distance</span> = ndi.distance_transform_edt(binary)

    <span class="org-keyword">print</span>(<span class="org-string">'Selecting markers from distance local maxima...'</span>)
    <span class="org-variable-name">local_maxi</span> = peak_local_max(distance, labels=binary,
                                min_distance=10,
                                indices=<span class="org-constant">False</span>)
    <span class="org-variable-name">markers</span>, <span class="org-variable-name">num_seeds</span> = ndi.label(local_maxi,
                                   structure=np.ones((3, 3, 3), dtype=np.int8))
    <span class="org-keyword">print</span>(<span class="org-string">'    ... found {} seeds'</span>.<span class="org-builtin">format</span>(num_seeds))

    <span class="org-keyword">print</span>(<span class="org-string">'Computing watershed transform'</span>)
    <span class="org-variable-name">labels</span> = watershed(-distance, markers, mask=binary)

    <span class="org-variable-name">index</span> = 100
    np.random.seed(20150929)
    <span class="org-variable-name">colors</span> = np.random.randint(255, size=(labels.<span class="org-builtin">max</span>()+1, 3)).astype(np.uint8)
    <span class="org-variable-name">colors</span>[0] = [0, 0, 0]

    imsave(<span class="org-string">'distance.png'</span>, distance[index]/distance.<span class="org-builtin">max</span>())
    imsave(<span class="org-string">'watershed-distance_local_max.png'</span>, colors[labels[index]])
</pre>
</div>

<p>
The result of this operation is shown on Fig. <a href="#org627701e">3</a>, where over-segmentation is observed. The reason for this is very simple, and typical of elongated objects: there are several local maxima of the distance map in each grain (see Fig. <a href="#org767abf8">4</a>), resulting in too many seeds.
</p>


<div id="org627701e" class="figure">
<p><img src="./20150930-Orientation_correlations_among_rice_grains-06/watershed-distance_local_max.png" alt="watershed-distance_local_max.png" width="50%">
</p>
<p><span class="figure-number">Figure 3: </span>The result of watershed segmentation using local maxima of the map of the distance to the background as seeds. Clearly, over-segmentation occurs, which is typical with elongated objects.</p>
</div>


<div id="org767abf8" class="figure">
<p><img src="./20150930-Orientation_correlations_among_rice_grains-06/distance.png" alt="distance.png" width="50%">
</p>
<p><span class="figure-number">Figure 4: </span>The map of the distance to the background. There are several local maxima in each grain.</p>
</div>

<p>
One possible response would be to use so-called <i>vertical filters</i> (<a href="https://doi.org/10.5566/ias.v27.p23-28">Tariel et al., 2008</a>). I used here a more intuitive approach by providing a <code>min_distance</code> parameter to the <a href="http://scikit-image.org/">scikit-image</a> <code>peak_local_max</code> (<a href="http://scikit-image.org/docs/stable/api/skimage.feature.html#peak-local-max">documentation</a>) function. The selected value (namely, 10 px) corresponds to the typical equatorial radius of the rice grains (as manually measured on the binary images). This indeed reduces over-segmentation, but does not solve the problem completely.
</p>

<p>
In the next section, we will see how a problem dependent solution can be proposed.
</p>
</div>
</div>

<div id="outline-container-org67eb584" class="outline-2">
<h2 id="org67eb584">Watershed segmentation with directional erosion <a id="org06d34a4"></a></h2>
<div class="outline-text-2" id="text-org67eb584">
<p>
In the <a href="#org3a58377">previous section</a>, over-segmentation occured because of the anisotropy of the objects. In other words, had the grains been nearly spherical, then we would have produced a very convincing segmentation with the above method.
</p>

<p>
The grains are elongated: this is a fact. Instead of ignoring it (at the cost of over-segmentation), we should take this important piece of information into account in the seeding process. In the present section I propose to erode the binary image with elongated structuring elements. Only those grains which have roughly the same orientation as the structuring element will remain. If we vary the orientation of the structuring element, we should be able to seed each grain.
</p>

<p>
The proposed procedure is summarized below.
</p>

<ol class="org-ol">
<li>Generate a set of orientations: we will use the vertices of an icosahedron, which give 20 orientations, uniformly distributed on the unit sphere.</li>
<li>Generate the corresponding ellipsoidal structuring elements, using the class <code>Spheroid</code>, defined <a href="./20150930-Orientation_correlations_among_rice_grains-06/spheroid.py">here</a>. I will not comment this module in the present post (I might make it the topic of a future post!). Suffice it to say that the aspect ratio of the structuring element is close to that of the actual rice grains. The structuring element should be neither too small, nor too large. I (manually) selected an equatorial radius of 3.5 px, and a polar radius of 9.5 px.</li>
<li>Generate 20 eroded images.</li>
<li>Evaluate the OR combination of the 20 eroded images.</li>
<li>Identify the connected components of the combined eroded images.</li>
<li>Use these connected components to seed the watershed process.</li>
</ol>

<p>
The resulting script is very simple (<a href="./20150930-Orientation_correlations_among_rice_grains-06/watershed-directional_erosion.py">download</a>).
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-doc">"""Watershed using directional erosions."""</span>

<span class="org-keyword">import</span> os.path

<span class="org-keyword">import</span> h5py
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np

<span class="org-keyword">from</span> scipy <span class="org-keyword">import</span> ndimage <span class="org-keyword">as</span> ndi
<span class="org-keyword">from</span> skimage.feature <span class="org-keyword">import</span> peak_local_max
<span class="org-keyword">from</span> skimage.io <span class="org-keyword">import</span> imread, imsave, imshow
<span class="org-keyword">from</span> skimage.morphology <span class="org-keyword">import</span> watershed

<span class="org-keyword">from</span> spheroid <span class="org-keyword">import</span> Spheroid


<span class="org-keyword">def</span> <span class="org-function-name">icosahedron</span>():
    <span class="org-variable-name">t</span> = (1+np.sqrt(5))/2
    <span class="org-variable-name">u</span> = t/np.sqrt(1+t**2)
    <span class="org-variable-name">v</span> = 1/np.sqrt(1+t**2)
    <span class="org-variable-name">vertices</span> = np.array([[ u,  v,  0], [-u,  v,  0], [ u, -v,  0],
                         [-u, -v,  0], [ v,  0,  u], [ v,  0, -u],
                         [-v,  0,  u], [-v,  0, -u], [ 0,  u,  v],
                         [ 0, -u,  v], [ 0,  u, -v], [ 0, -u, -v]],
                        dtype=np.float64)
    <span class="org-variable-name">faces</span> = np.array([[ 0,  8,  4], [ 0,  5, 10], [ 2,  4,  9], [ 2, 11,  5],
                      [ 1,  6,  8], [ 1, 10,  7], [ 3,  9,  6], [ 3,  7, 11],
                      [ 0, 10,  8], [ 1,  8, 10], [ 2,  9, 11], [ 3, 11,  9],
                      [ 4,  2,  0], [ 5,  0,  2], [ 6,  1,  3], [ 7,  3,  1],
                      [ 8,  6,  4], [ 9,  4,  6], [10,  5,  7], [11,  7,  5]],
                     dtype=np.uint8)
    <span class="org-keyword">return</span> vertices, faces


<span class="org-keyword">if</span> <span class="org-builtin">__name__</span> == <span class="org-string">'__main__'</span>:
    <span class="org-variable-name">root</span> =  os.path.join(<span class="org-string">'F:\\'</span>, <span class="org-string">'sebastien'</span>, <span class="org-string">'experimental_data'</span>, <span class="org-string">'navier'</span>,
                         <span class="org-string">'riz'</span>)
    <span class="org-keyword">with</span> h5py.File(os.path.join(root, <span class="org-string">'rice-bin_4x4x4.hdf5'</span>)) <span class="org-keyword">as</span> f:
        <span class="org-variable-name">binary</span> = np.asarray(f[<span class="org-string">'binary'</span>])

        <span class="org-keyword">print</span>(<span class="org-string">'Computing distance transform'</span>)
        <span class="org-variable-name">distance</span> = ndi.distance_transform_edt(binary)
        <span class="org-variable-name">dset</span> = f.create_dataset(<span class="org-string">'distance'</span>, data=distance)
        <span class="org-variable-name">dset.attrs</span>[<span class="org-string">'description'</span>] = np.string_(<span class="org-string">'distance transform of `binary`'</span>)

        <span class="org-keyword">print</span>(<span class="org-string">'Selecting markers from directional erosion...'</span>)
        <span class="org-variable-name">a</span>, <span class="org-variable-name">c</span> = 3.5, 9.5
        <span class="org-variable-name">vertices</span>  = icosahedron()[0]
        <span class="org-variable-name">eroded</span> = np.zeros_like(binary, dtype=np.<span class="org-builtin">bool</span>)
        <span class="org-keyword">for</span> v <span class="org-keyword">in</span> vertices:
            <span class="org-variable-name">spheroid</span> = Spheroid(a, c, v).digitize()
            np.logical_or(eroded,
                          ndi.binary_erosion(binary,
                                             structure=spheroid),
                          out=eroded)
        <span class="org-variable-name">markers</span>, <span class="org-variable-name">num_seeds</span> =  ndi.label(eroded,
                                        structure=np.ones((3, 3, 3),
                                                          dtype=np.int8))
        <span class="org-variable-name">dset</span> = f.create_dataset(<span class="org-string">'markers'</span>, data=markers)
        <span class="org-variable-name">descr</span> = (<span class="org-string">'`binary` image was eroded with 20 spheroids '</span>+
                 <span class="org-string">'(a={}, c={}) '</span>.<span class="org-builtin">format</span>(a, c)+
                 <span class="org-string">'using the vertices of a icosahedron as orientations. This'</span>+
                 <span class="org-string">'image is the logical OR of all 20 eroded images.'</span>)
        <span class="org-variable-name">dset.attrs</span>[<span class="org-string">'description'</span>] = np.string_(descr)
        <span class="org-keyword">print</span>(<span class="org-string">'    ... found {} seeds'</span>.<span class="org-builtin">format</span>(num_seeds))

        <span class="org-keyword">print</span>(<span class="org-string">'Computing watershed transform'</span>)
        <span class="org-variable-name">labels</span> = watershed(-distance, markers, mask=binary)
        <span class="org-variable-name">dset</span> = f.create_dataset(<span class="org-string">'labels'</span>, data=labels)
        <span class="org-variable-name">descr</span> = <span class="org-string">'watershed using `markers` and the opposite of `distance`.'</span>
        <span class="org-variable-name">dset.attrs</span>[<span class="org-string">'description'</span>] = np.string_(descr)

    <span class="org-variable-name">index</span> = 100
    np.random.seed(20150924)
    <span class="org-variable-name">colors</span> = np.random.randint(255, size=(labels.<span class="org-builtin">max</span>()+1, 3)).astype(np.uint8)
    <span class="org-variable-name">colors</span>[0] = [0, 0, 0]

    imsave(<span class="org-string">'distance.png'</span>, distance[index]/distance.<span class="org-builtin">max</span>())
    imsave(<span class="org-string">'makers-directional_erosion.png'</span>, colors[markers[index]])
    imsave(<span class="org-string">'watershed-directional_erosion.png'</span>, colors[labels[index]])
</pre>
</div>

<p>
It identifies 2362 seeds (instead of 2672 in the previous approach). The resulting segmentation is shown in Fig. <a href="#org75c70ab">5</a>. It can be seen that we almost got rid of over-segmentation.
</p>


<div id="org75c70ab" class="figure">
<p><img src="./20150930-Orientation_correlations_among_rice_grains-06/watershed-directional_erosion.png" alt="watershed-directional_erosion.png" width="50%">
</p>
<p><span class="figure-number">Figure 5: </span>The result of watershed segmentation using directional erosions of the map of the distance to the background as seeds. Very little over-segmentation is observed.</p>
</div>
</div>
</div>

<div id="outline-container-org04f2613" class="outline-2">
<h2 id="org04f2613">Conclusion</h2>
<div class="outline-text-2" id="text-org04f2613">
<p>
In an image analysis pipeline, segmentation is notoriously the critical step of the process. <a href="https://en.wikipedia.org/wiki/Watershed_(image_processing)">Watershed</a> is a very efficient technique, which requires careful seeding. For anisotropic object, ad-hoc techniques have to be adopted. In the present blog, I showed how some simple <a href="https://en.wikipedia.org/wiki/Mathematical_morphology">mathematical morphology</a> operations could be used to produce a satisfactory set of seeds. It should be noted however that the reason why the proposed approach works so well is that rice grains are nearly spheroidal. In other words, correctly seeding the watershed process is highly problem dependent!
</p>

<p>
In the <a href="./20160219-Orientation_correlations_among_rice_grains-07.html">next instalment</a> of this series, I will show how to analyse the shape and orientation of each individual grain.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br /><span xmlns:dct="https://purl.org/dc/terms/" property="dct:title">Except where otherwise noted, this blog</span> by <a xmlns:cc="https://creativecommons.org/ns#" href="https://sbrisard.github.io/blog/" property="cc:attributionName" rel="cc:attributionURL">Sébastien Brisard</a> is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
This blog was generated with <a href="http://www.gnu.org/software/emacs/">Emacs</a> and <a href="http://orgmode.org/">Org mode</a>. The theme is inspired from <a href="http://orgmode.org/worg/">Worg</a>. Icons come from the <a href="http://fontawesome.io/">Font Awesome</a> icon set.</p><div id="disqus_thread"></div>
<script type="text/javascript">
var disqus_shortname = 'sbrisard';
var disqus_identifier = 'posts/20150930-Orientation_correlations_among_rice_grains-06';
var disqus_title = 'Orientation correlations among rice grains, part 6: segmentation';
var disqus_url = 'https://sbrisard.github.io/posts/20150930-Orientation_correlations_among_rice_grains-06.html';
(function() {
var dsq = document.createElement('script');
dsq.type = 'text/javascript';
dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
</body>
</html>
