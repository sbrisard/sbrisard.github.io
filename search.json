[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "You’ve reached the blog of Sébastien Brisard. My most recent posts are listed below.\nPlease also visit the documentation of some of my projects\n\nhttps://sbrisard.github.io/janus: the documentation of the Janus library,\nhttps://sbrisard.github.io/pw85: the documentation of the PW85 library.\n\nas well as some recent (work in progress) open books\n\nAn introduction to Lippmann–Schwinger solvers\nNotes on the Lyapunov–Schmidt–Koiter asymptotic method\n\nEnjoy reading!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical analysis of a spring mesh\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2021\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolic analysis of a spring mesh\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2021\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is homogenization? Part 5: introducing the representative volume element\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2021\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is homogenization? Part 4: a first example\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2020\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nOn the stiffness matrix of a linear spring\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2020\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is homogenization? Part 3: ensemble averages vs. volume averages\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2020\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is homogenization? Part 2: experimental vs. theoretical homogenization\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2020\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is homogenization? Part 1: on the separation of scales\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2020\n\n\nSébastien Brisard\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 7: improved implementation of Moisan’s algorithm\n\n\n\n\n\n\n\n\n\n\n\nMar 26, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 6: minimizing the energy, the clever way\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 5: minimizing the energy, the clumsy way\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 4: implementing the linear operators\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 3: the energy as a quadratic form\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 2: defining the decomposition\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOn the periodic-plus-smooth decomposition of an image, part 1: introduction\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 8: estimating the correlations\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 7: analysis of the shape of the grains\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 6: segmentation\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 5: thresholding\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nWhen a thin shell is not so thin, part 3: the thick shell solution\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nWhen a thin shell is not so thin, part 2: the 3D, exact solution\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nWhen a thin shell is not so thin, part 1: Koiter’s linear theory\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 4: defining the ROI\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 3: intermezzo – Binning images\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 2: acquisition of tomography images\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nOrientation correlations among rice grains, part 1: introduction\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nDecomposition of transverse isotropic, fourth-rank tensors\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2014\n\n\n\n\n\n\n\n\n\n\n\n\nOn the double dot product\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2014\n\n\n\n\n\n\n\n\n\n\n\n\nThe elastic acoustic tensor and its inverse\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2014\n\n\n\n\n\n\n\n\n\n\n\n\nElastic constants of an isotropic material, part 3: putting it all together\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2014\n\n\n\n\n\n\n\n\n\n\n\n\nElastic constants of an isotropic material, part 2: plane strain elasticity\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2013\n\n\n\n\n\n\n\n\n\n\n\n\nElastic constants of an isotropic material, part 1: 3D elasticity\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2013\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20150330-Orientation_correlations_among_rice_grains-03/index.html",
    "href": "posts/20150330-Orientation_correlations_among_rice_grains-03/index.html",
    "title": "Orientation correlations among rice grains, part 3: intermezzo – Binning images",
    "section": "",
    "text": "The full reconstructed image resulting from the tomography experiment described in the second instalment of this series is a 1747×1751×688 stack. The voxel size is about 0.030 mm. This is far too much for the purpose of the present study, since all we are interested in is the determination of the location (coordinates of the centroid) and orientation (principal axes of inertia) of the rice grains. In order to reduce the computation time, the images will first be binned, that is each set of (say) 4×4×4 voxels will be replaced with a unique voxel, with average gray value (see below for an illustration). 3D binning would usually require three uggly nested loops. There is, however, a much more pythonic way. This is the topic of the present post."
  },
  {
    "objectID": "posts/20150330-Orientation_correlations_among_rice_grains-03/index.html#towards-thinking-in-higher-dimensions",
    "href": "posts/20150330-Orientation_correlations_among_rice_grains-03/index.html#towards-thinking-in-higher-dimensions",
    "title": "Orientation correlations among rice grains, part 3: intermezzo – Binning images",
    "section": "Towards thinking in higher dimensions",
    "text": "Towards thinking in higher dimensions\nInstead of looping over all cells of the original array, we could loop over the cells of the binned array. We then loop over all cells of the original array which contribute to the current cell of the binned array.\nbinned2 = np.zeros(binned_shape, dtype=np.float64)\nfor j0 in range(binned_shape[0]):\n    for j2 in range(bin_size):\n        i0 = bin_size*j0 + j2\n        for j1 in range(binned_shape[1]):\n            for j3 in range(bin_size):\n                i1 = bin_size*j1 + j3\n                binned2[j0, j1] += a2[i0, i1]\n\nbinned2 /= bin_size**2\nbinned2\narray([[0.52302399, 0.53382782],\n       [0.45544097, 0.48257402],\n       [0.48637204, 0.50609471]])\nWe can check that both methods lead to the same result\nnp.linalg.norm(binned2 - binned1)\n0.0\nOK, that’s fine. But this solution is even worse than the previous one, since we are now left with four nested loops! However, the above code snippet suggests that we could consider a2 as a four-dimensional array, where all cells are grouped in 4×4 macro-cells, as shown below.\n\nIn other words, if we introduced the auxiliary array a4 defined as follows\n\n(1)    a4[j0, j1, j2, j3] = a2[bin_size*j0 + j2, bin_size*j1 + j3]\nthen, the binned array could simply be computed through the following NumPy command\nbinned3 = np.mean(a4, axis=(-1, -2))\nIn the next section, we will show that creation of a4 with NumPy is actually straightforward, and entails no data copy."
  },
  {
    "objectID": "posts/20150608-When_a_thin_shell_is_not_so_thin-01/index.html",
    "href": "posts/20150608-When_a_thin_shell_is_not_so_thin-01/index.html",
    "title": "When a thin shell is not so thin, part 1: Koiter’s linear theory",
    "section": "",
    "text": "In structural analysis, thick beams (resp. plates) usually refer to shear deformability, and the Timoshenko beam theory (resp. Mindlin–Reissner plate theory). With curved elements however (e.g. curved beams or shells), the situation is more subtle, as thickness corrections may be necessary even in shells where the shear force is null at any point. In this series, this is illustrated with a spherical pressure vessel, for which the stress resultants and couples are studied. “Easy enough”, you probably think: \\(N=pR/2\\), \\(M=0\\) and that’s the end of it (Wikipedia). Well, maybe…\nIn the first part of this series, Koiter’s thin shell theory (Koiter, 1970, Actes du Congrès International des Mathématiciens, vol. 3, pp. 123–130) is used to analyse the equilibrium of the spherical pressure vessel. In particular, it is shown that the results deviate slightly from what is expected from the membrane theory.\n\nDescription of the problem\nWe consider a spherical vessel, subjected to an internal pressure \\(p\\). \\(R\\) denotes the radius of the midsurface, \\(h\\) the thickness of the shell, so that the inner and outer radii of the shell are\n\\[R_\\text{in}=R-\\frac h2\\quad\\text{and}\\quad R_\\text{out}=R+\\frac h2.\\]\nThe problem is solved in spherical coordinates. From symmetry considerations (the problem is fully isotropic), the deflection \\(w\\) (normal displacement of the midsurface) is constant. Similarly, the strain \\(\\epsilon_{\\alpha\\beta}\\), the change of curvature \\(\\kappa_{\\alpha\\beta}\\), the membrane force \\(N_{\\alpha\\beta}\\) and the bending moment \\(M_{\\alpha\\beta}\\) are all diagonal tensors with constant components \\[\n\\epsilon_{\\theta\\theta}=\\epsilon,\\quad\\epsilon_{\\phi\\phi}=\\epsilon,\\quad\\epsilon_{\\theta\\phi}=0,\n\\tag{1}\\] \\[\n\\kappa_{\\theta\\theta}=\\kappa,\\quad\\kappa_{\\phi\\phi}=\\kappa,\\quad\\kappa_{\\theta\\phi}=0,\n\\tag{2}\\] \\[\nN_{\\theta\\theta}=N,\\quad N_{\\phi\\phi}=N,\\quad N_{\\theta\\phi}=0,\n\\] \\[\nM_{\\theta\\theta}=M,\\quad M_{\\phi\\phi}=M,\\quad M_{\\theta\\phi}=0,\n\\] where \\(\\epsilon\\), \\(\\kappa\\), \\(N\\) and \\(M\\) are four scalar constants, which will be determined in the next section by means of Koiter's linear theory of thin shells (Koiter, 1970).\n\n\nThe thin shell solution\nUp to terms which are quadratic in the displacement, the trace of the tensor of membrane strains is equal to the relative variation of surface area of the shell. Therefore \\[\n\\epsilon=\\frac12\\epsilon_{\\alpha\\alpha}=\\frac12\\frac{4\\pi\\bigl(R+w\\bigr)^2-4\\pi R^2}{4\\pi R^2}\\simeq\\frac wR.\n\\tag{3}\\]\nThere is no simple geometrical derivation that I know of for the determination of the change of curvature, and you will have to trust me on this [… or use Eq. (3.4) in the paper by Koiter (1970)]. \\[\n\\kappa=-\\frac w{R^2}.\n\\tag{4}\\]\nThe deflection \\(w\\) of the shell is found by minimizing its total potential energy \\(\\Pi=U-V\\), where \\(U\\) denotes the srain energy, and \\(V\\) denotes the potential of external forces. In Koiter’s theory of thin shells, the strain energy \\(U\\) of the shell is the sum of two contributions: \\(U=U_\\epsilon+U_\\kappa\\), with \\[\nU_\\epsilon=\\frac12\\frac{Eh}{1-\\nu^2}\\int_{\\Sigma}\\bigl[\\bigl(1-\\nu\\bigr)\\epsilon_{\\alpha\\beta}\\epsilon^{\\alpha\\beta}+\\nu\\bigl(\\epsilon_\\gamma^\\gamma\\bigr)^2\\bigr]\\mathrm{d}\\Sigma=4\\pi R^2\\frac{Eh}{1-\\nu}\\epsilon^2,\n\\] \\[\nU_\\kappa=\\frac12\\frac{Eh^3}{12\\bigl(1-\\nu^2\\bigr)}\\int_{\\Sigma}\\bigl[\\bigl(1-\\nu\\bigr)\\kappa_{\\alpha\\beta}\\kappa^{\\alpha\\beta}+\\nu\\bigl(\\kappa_\\gamma^\\gamma\\bigr)^2\\bigr]\\mathrm{d}\\Sigma=4\\pi R^2\\frac{Eh^3}{12\\bigl(1-\\nu\\bigr)}\\kappa^2,\n\\] where use has been made of Eqs. (1) and (2). The strain energy of the shell therefore reads \\[\nU=4\\pi R^2\\frac{Eh}{1-\\nu}\\Bigl(1+\\frac{h^2}{12R^2}\\Bigr)\\frac{w^2}{R^2},\n\\] while the potential of external loads \\(V\\) is clearly given by the following expression \\[\nV=4\\pi R^2 pw.\n\\]\nThe total potential energy \\[\n\\frac{\\Pi}{4\\pi R^2}=\\frac{Eh}{1-\\nu}\\Bigl(1+\\frac{h^2}{12R^2}\\Bigr)\\frac{w^2}{R^2}-pw\n\\] is then minimized with respect to the deflection \\(w\\), which leads to \\[\nw=\\frac{pR^2}{2Eh}\\frac{1-\\nu}{1+\\frac{h^2}{12R^2}}.\n\\tag{5}\\]\nThe stress resultants and couples are then retrieved from the constitutive laws. For the stress resultants, we have \\[\nN=N_{\\theta\\theta}=\\frac{Eh}{1-\\nu^2}\\bigl(\\epsilon_{\\theta\\theta}+\\nu\\epsilon_{\\phi\\phi}\\bigr)=\\frac{Eh}{1-\\nu^2}\\bigl(1+\\nu\\bigr)\\epsilon=\\frac{Eh}{1-\\nu}\\epsilon,\n\\tag{6}\\] and similarly for the stress couples \\[\nM=\\frac{Eh^3}{12\\bigl(1-\\nu\\bigr)}\\kappa.\n\\tag{7}\\]\nSubstituting Eqs. (3), (4) and (5) in Eqs. (6) and (7) finally leads to the following expansions \\[\nN=\\frac{pR}2\\bigl(1-\\frac{h^2}{12R^2}\\bigr)+\\mathcal O\\bigl(\\frac{h^4}{R^4}\\bigr),\n\\] \\[\nM=-\\frac{ph^2}{24}\\bigl(1-\\frac{h^2}{12R^2}\\bigr)+\\mathcal O\\bigl(\\frac{h^6}{R^6}\\bigr).\n\\]\nThis is the first surprise in this series: the stress couple is not null, and the stress resultant differ slightly from the well-known formula \\(N=pR/2\\) (see Wikipedia).\nNota: the above-mentioned formula \\(N=pR/2\\) is known in french as “formule des chaudronniers”. One of my readers (Iliass Tahiri) kindly mentioned that it is known in english as Barlow’s formula, referring to the mathematician Peter Barlow.\n\n\nConclusion\nWe started with a very simple shell, which we expected to be in a state of membrane equilibrium. However, using Koiter’s linear theory of thin shells, we found that the stress couples, though small, are not null!\nSo what’s wrong with the above analysis? To dig deeper into this problem, we will use its full 3D solution to compute exact values of the stress resultants and couples… which will lead to other exciting findings in the next instalment of this series!"
  },
  {
    "objectID": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html",
    "href": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html",
    "title": "On the stiffness matrix of a linear spring",
    "section": "",
    "text": "This post is not going to be the most exciting I have ever written. We will derive the expression of the elastic energy of a linear spring as a function of the displacement of its two end-points. I will need this expression in my series on “What is homogenization”. Having derived the elastic energy, we will be only one step away from the stiffness matrix of the spring, to be used in a finite element setting."
  },
  {
    "objectID": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html#expression-of-the-elastic-energy",
    "href": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html#expression-of-the-elastic-energy",
    "title": "On the stiffness matrix of a linear spring",
    "section": "Expression of the elastic energy",
    "text": "Expression of the elastic energy\n\n\n\nA linear spring\n\n\nWe consider a spring located between points \\(A\\) and \\(B\\). Its initial length (at rest) is \\(L\\), and we introduce the unit vector \\(\\vec n\\) that points from \\(A\\) to \\(B\\)\n\\[\\vec X_B=\\vec X_A+L\\,\\vec n,\\]\nwhere \\(\\vec X_A\\) and \\(\\vec X_B\\) denote the radius vectors of points \\(A\\) and \\(B\\) in the initial (undeformed) configuration.\nAt equilibrium, the length of the spring is \\(\\ell\\) and its elastic energy is \\[U=\\tfrac12k\\bigl(\\ell-L\\bigr)^2,\\] where \\(k\\) denotes the stiffness of the spring. We want to express this elastic energy as a function of the displacements \\(\\vec u_A\\) and \\(\\vec u_B\\) of the points \\(A\\) and \\(B\\)\n\\[\\vec x_A=\\vec X_A+\\vec u_A\\quad\\text{and}\\quad\\vec x_B=\\vec X_B+\\vec u_B,\\]\nwhere \\(\\vec x_A\\) and \\(\\vec x_B\\) now denote the radius vectors of points \\(A\\) and \\(B\\) in the current (deformed) configuration. We will work under the assumption that these displacements are small and we will keep only the lowest order term of the energy.\nWe have\n\\[\\ell=\\lVert\\vec x_B-\\vec x_A\\rVert=\\lVert\\vec X_B-\\vec X_A+\\vec u_B-\\vec u_A\\rVert=L\\lVert\\vec n+\\vec\\xi\\rVert,\\]\nwhere we have introduced the following dimensionless vector\n\\[\\vec\\xi=L^{-1}\\bigl(\\vec u_B-\\vec u_A\\bigr).\\]\nThen\n\\[\\ell^2=L^2\\bigl(\\vec n+\\vec\\xi\\bigr)^2=L^2\\bigl(1+2\\,\\vec n\\cdot\\vec\\xi+\\vec\\xi\\cdot\\vec\\xi\\bigr)\\]\nand, to first order in \\(\\vec\\xi\\)\n\\[\\ell=L\\bigl[1+\\vec n\\cdot\\vec\\xi+\\mathcal O(\\vec\\xi^2)\\bigr].\\]\nPlugging the expression of \\(\\vec\\xi\\) as a function of the displacements \\(\\vec\nu_A\\) and \\(\\vec u_B\\), we find the elongation of the spring\n\\[\\ell-L=\\vec n\\cdot\\bigl(\\vec u_B-\\vec u_A\\bigr)+\\text{h.o.t.}\\]\nFinally, the elastic energy of the spring is, to lowest order\n\\[U=\\tfrac12k\\bigl[\\vec n\\cdot\\bigl(\\vec u_B-\\vec u_A\\bigr)\\bigr]^2,\\]\nwhich is the expression we were looking for."
  },
  {
    "objectID": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html#expression-of-the-stiffness-matrix",
    "href": "posts/20201125-On_the_stiffness_matrix_of_a_linear_spring/index.html#expression-of-the-stiffness-matrix",
    "title": "On the stiffness matrix of a linear spring",
    "section": "Expression of the stiffness matrix",
    "text": "Expression of the stiffness matrix\nThe above expression can also be written\n\\[U=\\tfrac12k\\bigl(\\vec u_B-\\vec u_A\\bigr)\\cdot\\bigl(\\vec n\\otimes\\vec n\\bigr)\\cdot\\bigl(\\vec u_B-\\vec u_A\\bigr)\\]\nand, upon expansion\n\\[U=\\tfrac12k\\bigl[\\vec u_A\\cdot\\bigl(\\vec n\\otimes\\vec n\\bigr)\\cdot\\vec u_A+\\vec u_B\\cdot\\bigl(\\vec n\\otimes\\vec n\\bigr)\\cdot\\vec u_B-2\\vec u_A\\cdot\\bigl(\\vec n\\otimes\\vec n\\bigr)\\cdot\\vec u_B\\bigr].\\]\nThis delivers the expression of the stiffness matrix of the spring. Indeed, let \\(q\\) be the vector of dofs of the spring. This is a column vector of size \\(2d\\) (\\(d\\): number of spatial dimensions): \\(q=[\\vec u_A, \\vec u_B]^\\mathsf{T}\\), where we store first the \\(d\\) components of the displacement of point \\(A\\), then the \\(d\\) components of the displacement of point \\(B\\). The elastic energy of the spring can now be written\n\\[U=\\tfrac12q^\\mathsf{T}\\cdot K\\cdot q,\\]\nwhere the stiffness matrix \\(K\\) reads, in block form\n\\[\nK = k \\begin{bmatrix}\n\\vec n\\otimes\\vec n & -\\vec n\\otimes\\vec n\\\\\n-\\vec n\\otimes\\vec n &  \\vec n\\otimes\\vec n\n\\end{bmatrix}.\n\\]\nFor \\(d=2\\), we introduce the components \\(u_\\star\\) and \\(v_\\star\\) of the displacement \\(\\vec u_\\star\\)\n\\[\\vec u_\\star=u_\\star\\,\\vec e_x+v_\\star\\,\\vec e_y,\\quad q^\\mathsf{T}=\\bigl[u_A, v_A, u_B, v_B\\bigr]\\]\nand\n\\[\nK = k \\begin{bmatrix}\nn_x \\, n_x &  n_x \\, n_y & -n_x \\, n_x & -n_x \\, n_y\\\\\nn_x \\, n_y &  n_y \\, n_y & -n_x \\, n_y & -n_y \\, n_y\\\\\n-n_x \\, n_x & -n_x \\, n_y &  n_x \\, n_x &  n_x \\, n_y\\\\\n-n_x \\, n_y & -n_y \\, n_y &  n_x \\, n_y &  n_y \\, n_y\n\\end{bmatrix}.\n\\]\nFor \\(d=3\\), we introduce the components \\(u_\\star\\), \\(v_\\star\\) and \\(w_\\star\\) of the displacement \\(\\vec u_\\star\\)\n\\[\\vec u_\\star=u_\\star\\,\\vec e_x+v_\\star\\,\\vec e_y+w_\\star\\,\\vec e_z,\\quad q^\\mathsf{T}=\\bigl[u_A, v_A, w_A, u_B, v_B, w_B\\bigr]\\]\nand\n\\[\nK = k \\begin{bmatrix}\nn_x \\, n_x &  n_x \\, n_y &  n_x \\, n_z & -n_x \\, n_x & -n_x \\, n_y & -n_x \\, n_z\\\\\nn_y \\, n_x &  n_y \\, n_y &  n_y \\, n_z & -n_y \\, n_x & -n_y \\, n_y & -n_y \\, n_z\\\\\nn_z \\, n_x &  n_z \\, n_y &  n_z \\, n_z & -n_z \\, n_x & -n_z \\, n_y & -n_z \\, n_z\\\\\n-n_x \\, n_x & -n_x \\, n_y & -n_x \\, n_z &  n_x \\, n_x &  n_x \\, n_y &  n_x \\, n_z\\\\\n-n_y \\, n_x & -n_y \\, n_y & -n_y \\, n_z &  n_y \\, n_x &  n_y \\, n_y &  n_y \\, n_z\\\\\n-n_z \\, n_x & -n_z \\, n_y & -n_z \\, n_z &  n_z \\, n_x &  n_z \\, n_y &  n_z \\, n_z\n\\end{bmatrix}.\n\\]"
  },
  {
    "objectID": "posts/20131205-Elastic_constants_of_an_isotropic_material-01/index.html",
    "href": "posts/20131205-Elastic_constants_of_an_isotropic_material-01/index.html",
    "title": "Elastic constants of an isotropic material, part 1: 3D elasticity",
    "section": "",
    "text": "Among all classes of materials, the class of linearly elastic and isotropic materials is the simplest. Such materials are defined by two elastic constants: for example, Young's modulus \\(E\\) and Poisson's ratio \\(\\nu\\). However, depending on the situation, this pair of constants might not be the most appropriate (meaning that they may not lead to the most compact expressions). Alternative sets of elastic constants are\n\nLamé’s constants \\(\\lambda\\) and \\(\\mu\\),\nbulk and shear moduli \\(\\kappa\\) and \\(\\mu\\),\nshear modulus and Poisson ratio \\(\\mu\\) and \\(\\nu\\).\n\nEach pair of constants is of course strictly equivalent to any other. I tend to work primarily with \\(\\mu\\) and \\(\\nu\\), and always find myself looking for the expression of E, \\(\\lambda\\) and \\(\\kappa\\) as a function of \\(\\mu\\) and \\(\\nu\\). In this series, we will derive these expressions, starting with 3D elasticity.\n\nLamé’s constants\nThe constitutive equation of a linearly elastic and isotropic material reads \\[\n\\sigma_{ij} = \\lambda\\,\\varepsilon_{kk}\\,\\delta_{ij} + 2\\mu\\,\\varepsilon_{ij},\n\\tag{1}\\] where \\(\\sigma_{ij}\\) (resp. \\(\\varepsilon_{ij}\\)) denotes the stress (resp. strain) tensor, while \\(\\lambda\\) (resp. \\(\\mu\\)) is Lamé's first (resp. second) constant; \\(\\mu\\) is also called the shear modulus. Eq. (1) is inverted so as to express the strain tensor as a function of the stress tensor. Taking \\(i = j\\) and summing over repeated indices, we find \\[\n\\sigma_{ii} = (3\\lambda + 2\\mu)\\varepsilon_{kk},\n\\] where it is recalled that \\(\\delta_{ii} = 3\\) (the dimension of the physical space). Plugging into Eq. (1) \\[\n\\sigma_{ij} = \\frac{\\lambda}{3\\lambda+2\\mu}\\,\\sigma_{kk}\\,\\delta_{ij} + 2\\mu\\,\\varepsilon_{ij}\n\\] and finally \\[\n\\varepsilon_{ij} = \\frac{\\sigma_{ij}}{2\\mu} - \\frac{\\lambda}{2\\mu\\,(3\\lambda+2\\mu)}\\,\\sigma_{kk}\\,\\delta_{ij}.\n\\tag{2}\\]\n\n\nYoung’s modulus and Poisson ratio\nWe consider a uniaxial traction experiment, where the stress tensor reduces to \\(\\sigma\\,\\vec e_3\\otimes\\vec e_3\\) (\\(\\sigma\\) is the imposed uniaxial stress). Substitution in Eq. (2) leads to the following expression of the longitudinal strain \\[\n\\varepsilon_{33} = \\frac{\\lambda+\\mu}{\\mu(3\\lambda+2\\mu)}\\,\\sigma.\n\\]\nBy definition, Young’s modulus is the longitudinal stress to longitudinal strain ratio: \\(E=\\sigma/\\varepsilon_{33}\\), so that \\[\nE = \\frac{\\mu\\,(3\\lambda+2\\mu)}{\\lambda+\\mu}.\n\\tag{3}\\]\nThe expression of the transverse strains is again derived using Eq. (2) \\[\n\\varepsilon_{11} = \\varepsilon_{22} = -\\frac{\\lambda}{2\\mu\\,(3\\lambda+2\\mu)}\\sigma\n\\] and by definition, Poisson’s ratio is the oposite of the transverse to longitudinal strain ratio \\[\n\\nu = -\\frac{\\varepsilon_{11}}{\\varepsilon_{33}}\n= -\\frac{\\varepsilon_{22}}{\\varepsilon_{33}}\n= \\frac{\\lambda}{2(\\lambda+\\mu)}.\n\\tag{4}\\]\nExpressions (3) and (4) can be substituted in the constitutive equation (2), leading to \\[\n\\varepsilon_{ij} = \\frac{1+\\nu}E\\,\\sigma_{ij} - \\frac\\nu E\\,\\sigma_{kk}\\,\\delta_{ij}.\n\\tag{5}\\]\n\n\nBulk and shear moduli\nWe now consider an isotropic compression experiment, where the stress tensor reduces to a hydrostatic pressure \\(\\sigma_{ij}=-p\\,\\delta_{ij}\\). Using Eq. (1), we find that the strain tensor is also isotropic \\[\n\\varepsilon_{ij} = -\\frac{p\\,\\delta_{ij}}{3\\lambda+2\\mu}.\n\\tag{6}\\]\nIt is recalled that \\(\\varepsilon_\\text v=\\varepsilon_{kk}\\) denotes the relative volume change of the material. Then, from Eq. (6) \\[\n\\varepsilon_\\text v = -\\frac p{\\kappa_\\text{3D}},\n\\] where \\(\\kappa_\\text{3D}\\) denotes the bulk modulus, defined as follows \\[\n\\kappa_\\text{3D} = \\lambda + \\frac 23\\mu.\n\\tag{7}\\]\nAs we shall see in the next instalment of this series, the definition of the bulk modulus depends on the dimension of the physical space, hence the '3D' subscript. Using \\(\\kappa\\) and \\(\\mu\\) as elastic constants, Eq. (1) reads \\[\n\\sigma_{ij} = \\kappa_\\text{3D} \\, \\varepsilon_{kk} \\, \\delta_{ij}\n+2\\mu\\,\\left(\\varepsilon_{ij}-\\frac{\\varepsilon_{kk}}3\\,\\delta_{ij}\\right)\n\\tag{8}\\]\n\n\nShear modulus and Poisson ratio\nI quite often use the shear modulus \\(\\mu\\) and Poisson ratio \\(\\nu\\) as the constants defining the elastic material. One of the reasons for this is the fact that the components of the fourth-rank Green operator for strains have the same expression in 3D and 2D (plane strain) elasticity when expressed as a function of \\(\\mu\\) and \\(\\nu\\).\nIn the present section, all other elastic constants are expressed as functions of these two constants. First, from Eq. (4), it is readily found that \\[\n\\lambda = \\frac{2\\mu\\,\\nu}{1-2\\nu}.\n\\tag{9}\\]\nThen, combining Eqs. (3) and (4) \\[\nE = 2\\mu\\,(1+\\nu).\n\\]\nFinally, from Eqs. (7) and (9) \\[\n\\kappa_\\text{3D} = \\frac23\\,\\frac{1+\\nu}{1-2\\nu}\\,\\mu.\n\\]\n\n\nConclusion\nIn this instalment, we have defined Lamé’s first and second constants, Young’s modulus, Poisson’s ratio, as well as the (3D) bulk modulus. Expressions relating these various constants have also been derived. In the next instalment of this series, we will discuss the case of 2D (plane strain elasticity).\n\n\nNotes\n\n2023/01/22 – I would like to acknowledge Antonio Rodriguez Ferran from UPC-BarcelonaTech for finding out two typos in this post. Do send your comments and corrections!"
  },
  {
    "objectID": "posts/20200402-What_is_homogenization-01/index.html",
    "href": "posts/20200402-What_is_homogenization-01/index.html",
    "title": "What is homogenization? Part 1: on the separation of scales",
    "section": "",
    "text": "Most of my research activities deal with upscaling the mechanical properties of heterogeneous materials. This is also known as homogenization. So what is homogenization? This series explores this question; it is largely based on the introduction to my Habilitation defense.\nIn order to introduce homogenization, we will draw inspiration from the publishing industry. The following photograph1 was published in Le Journal (a french daily newspaper) from thursday, may 30th, 1935. It illustrates the first cruise of the ocean liner Normandie.\nFrom where you sit, water exhibits nice shades of gray. However, let us take a closer look at the prow:\nIt turns out that the sea has a dotted structure, which is inherent to the so-called halftoning technique itself. Of course, the reason why the resulting picture looks fine is because you are looking at it from far off. Also, the size of the “gray” patches must be large enough for you to get the illusion that it is smoothly shaded. Indeed, if the patch contains only a few dots, the illusion will not take place.\nWe have therefore identified three length-scales\nThese three scales must be well separated for the photograph to appear smoothly shaded. In other words, the macro scale is much larger than the meso scale, which in turn is much larger than the micro scale: \\(L_μ ≪ L_{\\mathrm{m}} ≪ L_{\\mathrm{M}}\\). This is the so-called assumption of separation of scales.\nProvided that separation of scales prevails, homogenization can take place. Homogenization is the process of replacing the complex microstructure with an equivalent, homogeneous mesostructure. By microstructure, we mean both the geometry and physical properties of the microscopic features. In the above example, the microstructure is defined by the size and spacing of the dots (geometry), as well as the color of dots and background (physical properties). The mesostructure on the other hand is a patch with homogeneous, equivalent (in homogenization language, we say effective) properties. In the above example, the effective property is the shade of gray as perceived by the observer."
  },
  {
    "objectID": "posts/20200402-What_is_homogenization-01/index.html#conclusion",
    "href": "posts/20200402-What_is_homogenization-01/index.html#conclusion",
    "title": "What is homogenization? Part 1: on the separation of scales",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we introduced the homogenization concept through a graphical analogy. We explained that the key ingredient for homogenization to be valid is separation of scales.\nIn the next instalment of this series, we will discuss two strategies to carry out homogenization: the bottom-up and top-down approaches."
  },
  {
    "objectID": "posts/20200402-What_is_homogenization-01/index.html#footnotes",
    "href": "posts/20200402-What_is_homogenization-01/index.html#footnotes",
    "title": "What is homogenization? Part 1: on the separation of scales",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe Journal, num. 15565. Image downloaded from Gallica, the digital library BnF (Bibliothèque Nationale de France).↩︎"
  },
  {
    "objectID": "posts/20150529-Orientation_correlations_among_rice_grains-04/index.html",
    "href": "posts/20150529-Orientation_correlations_among_rice_grains-04/index.html",
    "title": "Orientation correlations among rice grains, part 4: defining the ROI",
    "section": "",
    "text": "In the previous instalment of this series, we obtained binned slices of the sample. Fig. 1 below displays a typical example of these binned slices. We now want to segment the rice grains. However, the analysis (in particular, Otsu thresholding) might be perturbed by the fact that the walls of the sample container are visible on the 3D image. In this post, I will show how we can locate these walls. Then, any subsequent analysis will be performed within the Region Of Interest (ROI) thus defined.\n\n\n\n\n\n\nFigure 1: A typical slice of the 3D reconstruction of the sample. The original image has been reduced by 4×4×4 binning; the size of each binned slice is 436×437.\n\n\n\n\nThe circle Hough Transform\nThe sample container is cylindrical; since it was nearly vertical during the tomography experiment, its trace is a circular ring on each slice. We are going to use the Circle Hough Transform in order to locate the inner and outer circular boundaries which define this ring. To do so, we will use python, numpy and scikit-image. We first import these modules, and load the image\nimport os.path\n\nimport numpy as np\n\nfrom skimage.color import gray2rgb\nfrom skimage.draw import circle_perimeter\nfrom skimage.feature import canny\nfrom skimage.io import imread, imsave\nfrom skimage.transform import hough_circle\nfrom skimage.util import img_as_ubyte\n\nroot = '.'\nname = os.path.join(root, 'rice-bin_4x4x4-099.tif')\nimg = imread(name)\n\nprint('Read {}x{} image.'.format(*img.shape))\nRead 437x436 image.\nThen, we locate the edges, by means of a standard Canny edge detector (see also the API docs of scikit-image).\nedges = canny(img, sigma=0.)\nimsave(os.path.join(root, 'rice-bin_4x4x4-edges-099.png'),\n       img_as_ubyte(edges))\nThe resulting image is shown in Fig. 2. It should be noted that due to the preliminary binning (which is nothing but a mean filter), the input image exhibits very little noise. Therefore, sigma=0.0 in the above call to skimage.feature.canny.\n\n\n\n\n\n\nFigure 2: Canny edge detection performed on the initial image shown in Fig. 1.\n\n\n\nWe are now ready to compute the Circle Hough Transform. This transform aims at finding circles within an image. It was proposed by Duda and Hart (1971) (see also Wikipedia). It should be understood as a histogram in parameter space. More precisely, a point \\((x, y)\\) belongs to the circle centered at \\((c_x, c_y)\\) and of radius \\(r\\) if, and only if\n\\[(x-c_x)^2+(y-c_y)^2=r^2.\\]\nThe circle under consideration is parameterized by \\((c_x, c_y, r)\\). Conversely, given a point \\((x, y)\\), the set of circles to which this point belongs is given by the triplet \\((c_x, c_y, r)\\) such that\n\\[(c_x-x)^2+(c_y-y)^2-r^2=0.\\]\nIn the parameter space \\((c_x, c_y, r)\\), the set of circles to which point \\((x, y)\\) belongs is a conical surface. Its apex is \\((x, y, 0)\\), its axis is the \\((0, 0, 1)\\) direction and its aperture is 90°. As we are only interested in real circles, only the \\(r\\geq0\\) half-space should be considered.\nHow is this representation in parameter space to be used? We consider a binary (0/1) image; let \\(\\{(x_i, y_i),i=1,\\ldots,N\\}\\) denote the set of non-null pixels. We define \\(\\mathcal H_i\\) as the 3D, binary image of the cone associated in the sphere parameter space with pixel \\((x_i, y_i)\\). The Hough transform is then the (possibly normalized) sum of all \\(\\mathcal H_i\\)\n\\[\\mathcal H(c_x, c_y, r)=\\sum_i\\mathcal H_i(c_x, c_y, r).\\]\n\\(\\mathcal H\\) should really be understood as a histogram. Indeed, a peak in \\(\\mathcal H\\) indicates that the cones corresponding to many pixels intersect at the same point in parameter space. In other words, many pixels in the original image belong to the same circle. Finding circles in the original image therefore reduces to finding peaks in its Hough transform. That is what we are going to do presently. We must first compute the Hough transform. In order to reduce the CPU cost, we will only consider these circles whose radius is close to that of the sample container. We saw in part 2 of this series that the radius of the sample container is 25 mm, while the voxel size is approximately 0.03 mm; after binning, the voxel size is therefore 0.12 mm, and the radius of the sample container is approx. 25 / 0.12 = 208 px. In the following code, we ask for the circle Hough transform for circles with radii between 190 and 220 px.\nWe first tell Python to ignore all warnings. This is extremely poor practice, but otherwise skimage.io.imsave will complain about low-contrast images (and my version of skimage does not implement the check_contrast keyword argument).\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nradii = np.arange(190, 220)\nh = hough_circle(edges, radii)\nfor i, radius in enumerate(radii):\n    imsave(os.path.join(root,\n                        'rice-bin_4x4x4-hough-099-{}.tif'.format(radius)),\n           h[i, ...])\nThe above code snippet saves a series of images, which is displayed below in 3D as an animated GIF (see Fig. 3). The two bright spots indicate the location of the inner and outer boundaries in the parameter space. We will use a very crude procedure to locate these two peaks (a more elaborate method is not required as we do not seek sub-pixel accuracy).\n\n\n\n\n\n\n\nFigure 3: 3D view of the Hough transform. The two bright spots correspond to the inner and outer boundaries of the sample container.\n\n\n\nThe code snippet below finds the two highest values of the Hough transform. The correct peak (inner boundary) corresponds to the smallest radius. Then, the coordinates of the center of the corresponding circle are found.\nh_max = np.max(h, axis=(1, 2))\nk = np.min(np.argsort(h_max)[-2:])\nradius = radii[k]\nh = h[k, ...]\nrow, col = np.unravel_index(np.argmax(h), h.shape)\n'The inner boundary is centered at ({} px, {} px); its radius is {} px.'.format(row, col, radius)\n'The inner boundary is centered at (219 px, 217 px); its radius is 208 px.'\nThe radius of the inner boundary turns out to be exactly 208 pixels! For visual inspection, this circle is overlaid on top of the original image (adapted from this scikit-image example).\nimg_rgb = gray2rgb(img_as_ubyte(img))\nrows, cols = circle_perimeter(row, col, radius, method='andres')\nimg_rgb[rows, cols] = (255, 0, 0)\nimsave(os.path.join(root, 'rice-bin_4x4x4-boundary-099.png'), img_rgb)\nWhich produces the following image (see Fig. 4).\n\n\n\n\n\n\nFigure 4: The original image overlaid with the identified boundary.\n\n\n\nA closer look (see Fig. 5) shows that we roughly achieved pixel accuracy, which will be sufficient for the analysis to come.\n\n\n\n\n\n\nFigure 5: Close-up of Fig. 4; pixel accuracy was approximately achieved.\n\n\n\n\n\nAnalysis of the whole stack\nWe are now ready to carry out the above analysis on all 172 images of the stack. This is what the script below does (download); in order to check that nothing went wrong, each image with overlaid boundary is saved for visual inspection.\nimport os.path\nimport numpy as np\n\nfrom skimage.color import gray2rgb\nfrom skimage.draw import circle_perimeter\nfrom skimage.feature import canny\nfrom skimage.io import imread, imsave\nfrom skimage.transform import hough_circle\nfrom skimage.util import img_as_ubyte\n\n\ndef find_boundary(img, min_radius, max_radius):\n    edges = canny(img, sigma=0.)\n    radii = np.arange(min_radius, max_radius)\n    h = hough_circle(edges, radii)\n    h_max = np.max(h, axis=(1, 2))\n    k = np.min(np.argsort(h_max)[-2:])\n    radius = radii[k]\n    h = h[k, ...]\n    row, col = np.unravel_index(np.argmax(h), h.shape)\n    return row, col, radius\n\n\ndef draw_boundary(img, row, col, radius):\n    img_rgb = gray2rgb(img_as_ubyte(img))\n    rows, cols = circle_perimeter(row, col, radius, method='andres')\n    img_rgb[rows, cols] = (255, 0, 0)\n    return img_rgb\n\n\nif __name__ == '__main__':\n    root = os.path.join('F:', 'sebastien', 'experimental_data', 'navier', 'riz')\n    input_dir = os.path.join(root, 'bin_4x4x4')\n    output_dir = os.path.join(root, 'boundary')\n    input_name = 'rice-bin_4x4x4-{0:03d}.tif'\n    output_name = 'rice-bin_4x4x4-boundary-{0:03d}.png'\n    num_slices = 172\n    min_radius = 190\n    max_radius = 220\n\n    circle_params = np.zeros((num_slices, 3), dtype=np.uint16)\n    for i in range(num_slices):\n        img = imread(os.path.join(input_dir, input_name.format(i)))\n        circle_params[i] = find_boundary(img, min_radius, max_radius)\n        img = draw_boundary(img, *circle_params[i])\n        imsave(os.path.join(output_dir, output_name.format(i)), img)\n    np.save('./circle_params.npy', circle_params)\nThis script saves the parameters of each circular boundary in an array, which can be restored for further analysis.\na = np.load(os.path.join(root, 'circle_params.npy'))\nprint('avg = {}\\nstd = {}'.format(a.mean(axis=0), a.std(axis=0)))\navg = [218.89534884 216.97674419 207.88372093]\nstd = [0.30610341 0.1507149  0.32055927]\nWhich shows that there is very little variation of the circle parameters across the slices.\n\n\nClosing words\nIn this post, we saw how to define the (cylindrical) ROI on our stack of images. To do so, we used the Circle Hough Transform to find circular edges in the slices. In the next instalment of this series, I will start discussing segmentation per se.\n\n\nSide-note: how to produce animated GIFs\nThe animated GIF in Fig. 3 was produced with ImageJ. The procedure is\n\nImport the image sequence (File → Import → Image Sequence…) called rice-bin_4x4x4-hough-099-*.tif,\nImage → Stacks → 3D Project…\nImage → Lookup Tables → Fire\nFile → Save As → Gif\n\nTo change the frame rate, use Image → Stacks → Tools → Animation Options…"
  },
  {
    "objectID": "posts/20150706-When_a_thin_shell_is_not_so_thin-03/index.html",
    "href": "posts/20150706-When_a_thin_shell_is_not_so_thin-03/index.html",
    "title": "When a thin shell is not so thin, part 3: the thick shell solution",
    "section": "",
    "text": "Finding the stress resultant and stress couple in a spherical pressure vessel seems easy enough. Well, this apparently simple problem allows us to highlight subtle thickness effects within shells. It should be emphasized again that these thickness effects have nothing to do with shear corrections. Indeed, shear stresses are null at any point of the spherical pressure vessel. Rather, the thickness effects we are discussing in this series are due to curvature.\nIn the first instalment of this series, I showed that using Koiter’s thin shell solution leads to a non-null stress couple, which came as quite a surprise. In the second instalment, I used the exact, 3D solution to derive reference values of the stress couple and stress resultant through integration over the thickness of the shell. In particular, I showed that thickness corrections had to be incorporated.\nThis still does not settle the matter, since the results obtained within the framework of Koiter’s thin shell theory (see first instalment) are inconsistent with the reference, 3D elasticity values (see second instalment). To reconcile both approaches (3D elasticity vs. shell theory), we need to use a thick shell theory, as illustrated below.\n\nStrain distribution in the spherical pressure vessel\nThe fundamental assumption of all shell theories is that displacement of any point of the shell is completely defined by the rigid body motion (translation and rotation) of its projection onto the base surface. In the present case, owing to the symmetries of the problem, points of the base surface move along the normal \\(\\mathbf n\\) \\[\n\\mathbf u = w\\mathbf n,\n\\tag{1}\\] where \\(w\\) is the normal displacement, which is constant over the base surface. Since the rotation is null, all points (across the thickness of the shell) have the same normal displacement. Therefore, Eq. (1) defines the 3D displacement field within the shell, seen as a 3D continuum. From this 3D displacement field, we can readily derive the corresponding strain field. We will use a simplified, geometric approach, rather than the general formulas in spherical coordinates. This is possible because there are so many symmetries in the problem at hand!\nThe in-plane strain \\(\\epsilon\\) at the distance \\(r\\) of the center is given by the relative change of length of the equator \\[\n\\epsilon=\\frac{2\\pi\\bigl(r+w\\bigr)-2\\pi r}{2\\pi r}=\\frac wr.\n\\tag{2}\\]\nIn the first instalment, we found \\(\\epsilon=w/R\\), where \\(R\\) is the radius of the midsurface. Eq. (2) therefore incorporates thickness corrections which we previously overlooked.\n\n\nStress distribution in the spherical pressure vessel\nStresses in the spherical pressure vessel are derived from the strains [see Eq. (2)], within the framework of plane stress elasticity \\[\n\\sigma\\_{\\theta\\theta}=\\frac E{1-\\nu^2}\\bigl(\\epsilon\\_{\\theta\\theta}+\\nu\\epsilon\\_{\\phi\\phi}\\bigr)\n\\tag{3}\\] \\[\n\\sigma\\_{\\phi\\phi}=\\frac E{1-\\nu^2}\\bigl(\\epsilon\\_{\\phi\\phi}+\\nu\\epsilon\\_{\\theta\\theta}\\bigr).\n\\tag{4}\\]\nSince the solution is isotropic (\\(\\epsilon\\_{\\theta\\theta}=\\epsilon\\_{\\phi\\phi}=\\epsilon\\) and \\(\\sigma\\_{\\theta\\theta}=\\sigma\\_{\\phi\\phi}=\\sigma\\)), Eqs. (3) and (4) lead to \\[\n\\sigma=\\frac E{1-\\nu}\\epsilon=\\frac E{1-\\nu}\\frac wr.\n\\tag{5}\\]\n\n\nStress resultant and stress couple\nEq. (5) is finally integrated over the thickness of the shell to obtain the stress resultant and stress couple. Integration must include thickness corrections, which amount to a \\(r/R\\) factor within the integral (see previous instalment of this series).\n\\[\nN=\\int\\_{R\\_\\mathrm{int}}^{R\\_\\mathrm{ext}}\\sigma(r)\\,\\frac rR\\,\\mathrm{d}r=\\frac{Eh}{1-\\nu}\\frac wR,\n\\tag{6}\\] \\[\nM=\\int\\_{R\\_\\mathrm{int}}^{R\\_\\mathrm{ext}}-\\bigl(r-R\\bigr)\\sigma(r)\\,\\frac rR\\,\\mathrm{d}r=0.\n\\tag{7}\\]\nNow, things start getting really interesting! Indeed, in the thick shell approach, the stress couple is (as expected) rigorously null! Since \\(M=0\\), it can readily be deduced that \\[\nN=\\frac{pR}2.\n\\] {eq-08}\nIn other words, the classical formula is retrieved (see Wikipedia).\n\n\nConclusion\nIn the present post, we finally resolved all contradictions regarding the computation of stress resultant and stress couple within a spherical pressure vessel. In the discussion below, \\(\\eta\\) denotes the slenderness of the shell, \\(\\eta=h/R\\). Besides, by “k-th order terms”, we mean terms of order \\(\\eta^k\\).\nFour difference approaches can be followed to analyse the equilibrium of a spherical pressure vessel (see table below). In the classical membrane approach, stress couples are overlooked, and the classical formula \\(N=pR/2\\) is obtained.\nIn the thin shell approach, the stress resultant deviates slightly from this classical value (by second order terms) and the stress couple is not null (rather, it is of second order).\nIn the thick shell approach, the stress couple is rigorously null and the classical formula is retrieved for the stress resultant. Thickness corrections appear in two different places\n\nin the strain distribution across the thickness of the shell see Eq. ( 2: the distribution is hyperbolic with respect to the thickness coordinate,\nin the stress-stress resultant and stress-stress couple integral relations see Eqs. ( 6.\n\nIn the 3D approach, the true stress resultant differs from \\(N=pR/2\\) by second order terms, while the true stress couple is of fourth order.\nWhat should we deduce from this study? Obviously, beware thin shell theories! Fortunately, I believe that most FE codes implement the thick shell theory. More fundamentally, I am still trying to understand what these results really imply. Does that mean that the asymptotic convergence (as the thickness tends to zero) of thick shell models is faster than that of thin shell models? That is something I am going to investigate.\nThis closes our series on thick shells. I hope you enjoyed reading it… and maybe learned something! Should you want to dig deeper into various thick shell theories, do start with Leissa (1973), who gives a good overview.\n\n\n\n\n\n\n\n\n\n\nExact 3D theory\nThin shell theory\nThick shell theory\n\n\n\n\nStress resultant (deviation from \\(pR/2\\))\n\\(\\eta^2\\)\n\\(\\eta^2\\)\n\\(0\\)\n\n\nStress couple\n\\(\\eta^4\\)\n\\(\\eta^2\\)\n\\(0\\)"
  },
  {
    "objectID": "posts/20140226-Decomposition_of_transverse_isotropic_fourth-rank_tensors/index.html",
    "href": "posts/20140226-Decomposition_of_transverse_isotropic_fourth-rank_tensors/index.html",
    "title": "Decomposition of transverse isotropic, fourth-rank tensors",
    "section": "",
    "text": "In a previous post, I introduced the fourth-rank spherical and deviatoric projection tensors. Any isotropic fourth-rank tensor is a linear combination of these two tensors; in other words, the space of isotropic fourth-rank tensors (with minor and major symmetries) is of dimension 2. Similarly, it can be shown (Walpole, 1984) that the space of three-dimensional, transverse isotropic fourth-rank tensors (with minor and major symmetries) is of dimension 6. Furthermore; it is possible to produce a convenient basis of this space. This is the topic of the present post, which is mostly based on the paper by Walpole (1984)."
  },
  {
    "objectID": "posts/20140226-Decomposition_of_transverse_isotropic_fourth-rank_tensors/index.html#a-convenient-representation-of-transverse-isotropic-fourth-rank-tensors",
    "href": "posts/20140226-Decomposition_of_transverse_isotropic_fourth-rank_tensors/index.html#a-convenient-representation-of-transverse-isotropic-fourth-rank-tensors",
    "title": "Decomposition of transverse isotropic, fourth-rank tensors",
    "section": "A convenient representation of transverse isotropic, fourth-rank tensors",
    "text": "A convenient representation of transverse isotropic, fourth-rank tensors\nWalpole (1984) proposes a convenient representation of any transverse isotropic tensor \\(\\mathbf T\\), as the triplet \\((A,\nf, g)\\) where \\(A\\) is a 2×2 matrix and \\(f\\) and \\(g\\) are two scalars. This representation should be understood as \\[\n\\mathbf T=a_{11}\\,\\mathbf E_1+a_{22}\\,\\mathbf E_2+a_{12}\\,\\mathbf E_3+a_{21}\\,\\mathbf E_4+f\\,\\mathbf F+g\\,\\mathbf G,\n\\] where \\(a_{ij}\\) are the coefficients of \\(A\\). The condensed notation \\(\\mathbf T=(A,\nf, g)\\) shall be adopted. Using the above multiplication table, it can readily be verified that if \\(\\mathbf T=(A, f, g)\\) and \\(\\mathbf T'=(A', f', g')\\), then \\[\n\\mathbf T:\\mathbf T'=(A\\cdot A', ff', gg').\n\\] This representation is particularly convenient when it comes to inverting transverse isotropic tensors. Indeed, \\[\\mathbf T^{-1}=(A^{-1}, 1/f, 1/g).\n\\] Transposition is also straightforward \\[\n\\mathbf T^{\\mathsf T}=(A^{\\mathsf T}, f, g).\n\\]"
  },
  {
    "objectID": "posts/20200421-What_is_homogenization-03/index.html",
    "href": "posts/20200421-What_is_homogenization-03/index.html",
    "title": "What is homogenization? Part 3: ensemble averages vs. volume averages",
    "section": "",
    "text": "In the previous instalment of this series on homogenization, we discussed homogenization of a distribution of black dots on a white background to a uniform shade of gray. In that example, homogenization boils down to evaluating the fraction of the total area occupied by the dots: this is the so-called rule of mixtures. Of course, in most real-case applications, the homogenization process is much more complex than merely evaluating a surface (or volume) fraction. However, before we move onto such more difficult homogenization processes, we will discuss in more detail volume fractions in the present post, where we will introduce periodic and random homogenization.\nIn the halftoning example that we used previously, computing the effective gray-level was fairly easy owing to the fact that the dots were regularly spaced. The pattern is in fact periodic: the whole plane (or space) can be paved with one single unit-cell (a hexagon in the present case).\nOnce the unit-cell had been identified, the effective gray-level was computed as the following surface fraction\n\\[\n\\text{effective gray level} = \\frac{\\text{surface area of white region}}{\\text{surface area of unit-cell}}.\n\\]\nThis is an example of what is called periodic homogenization, meaning that the heterogeneities are laid out in a periodic pattern. Homogenization in the periodic case is generally a three-step process:\nIn the above example:\nIn reality, most natural and manufactured materials are not as regular as the pattern considered above. They are in fact disordered. For example, the distribution of holes (pores) in the following (manufactured) sponge does not follow a regular pattern.\nSo, how do we move from the simple, periodic case to the more realistic, disordered case? The keyword is: “random process”. We assume that the material at hand is the result of a random process. I must insist, here: this is an assumption, and wording does matter. What we truly have is a disordered material (meaning that it’s all very messy in here). Representing this disordered material as the result of a random process is a modelling assumption. It implies some kind of reproducibility, in the sense that the same random process can be reproduced many times, each time resulting in what we will call a new realization of essentially the same disordered material. The realizations are indeed different, but (very losely speaking) they carry the “same kind of randomness” (they look similar). The important consequence of this assumption is that it is possible to describe the disordered material statistically. This is illustrated below with the sponge shown previously.\nIn the case of the sponge, reproducibility is in fact a highly desirable feature, since the manufacturer wants to insure the quality of his product remains constant. To do so, he keeps the conditions (raw materials, temperature, relative humidity, …) identical. Describing the sponge as a random process is extremely natural in that case.\nIt is time to formalize the above discussion. To do so, we rely on the sponge and make the simplifying assumption that the solid (yellow) phase is homogeneous. Then, the disordered material is fully described by the indicator function \\(\\chi(\\vec x)\\) of the solid phase: \\(\\chi(\\vec x)=1\\) if \\(\\vec x\\) belongs to the solid phase, \\(\\chi(\\vec x)=0\\) otherwise. Of course, the indicator function \\(\\chi\\) is different for each new realization. This is acknowleged by the introduction of a second argument to the function \\(\\chi\\), namely: \\(\\omega.\\) This argument is formal, it refers to the realization (see also the Wikipedia page on random variables). To sum up: the microstructure of the sponge is defined by the function \\(\\chi(\\vec\nx, \\omega)\\), where \\(\\vec x\\) is the observation point and \\(\\omega\\) is the realization. By freezing each of these two parameters in turn, we will define two kinds of averages of \\(\\chi\\).\nLet us assume that you pay a visit to the sponge manufacturer and get permission to look at all sponges that were produced this day. For each of these sponges, you carry out the following experiment: “observe the content (solid or void) at a fixed point (say, the center of the top face)”. In other words, for fixed \\(\\vec x\\), you measure \\(\\chi(\\vec x, \\omega_1), \\ldots, \\chi(\\vec x, \\omega_N)\\), where \\(\\omega_1,\\ldots, \\omega_N\\) denote the sponges under scrutiny. The empirical probability that point \\(\\vec x\\) belongs to the solid phase is\n\\[\nP[\\chi(\\vec x, \\omega)=1]=\\frac1N\\sum_{i=1}^N\\chi(\\vec x, \\omega_i).\n\\]\nThe above probability can also be seen as the expectation of \\(\\chi(\\vec x,\n\\omega)\\), for fixed observation point \\(\\vec x\\)\n\\[\n\\mathbb{E}(\\chi)(\\vec x)=0\\times P[\\chi(\\vec x, \\omega)=0]+1\\times P[\\chi(\\vec x, \\omega)=1],\n\\]\nand it results from the above discussion that \\(\\mathbb E(\\chi)(\\vec x)\\) is the “frequency of occurence” of the solid phase at point \\(\\vec x\\). Note that this ensemble average depends in theory on the observation point \\(\\vec x\\). However, we will only consider in the present series random materials that are statistically homogeneous. For such materials \\(\\mathbb E(\\chi)(\\vec x)\\) is a constant that does not depend on the observation point1. Homogeneity is an important property: it means that, statistically speaking, all points are equivalent (they carry the “same randomness”). For statistically homogeneous materials, we will write \\(\\mathbb E(\\chi)\\) rather than \\(\\mathbb E(\\chi)(\\vec\nx)\\), since the observation point \\(\\vec x\\) is irrelevant.\nThe ensemble average \\(\\mathbb E(\\chi)\\) was obtained above by freezing the first variable \\(\\vec x\\) in \\(\\chi(\\vec x, \\omega)\\). We now freeze the second variable, \\(\\omega.\\) Let us assume that, before taking leave from the manufacturer, you took one sponge with you. Back home from the sponge factory, you decide to observe the sponge at \\(N\\) points \\(\\vec x_1, \\ldots, \\vec x_N\\). These points are regularly spaced on a 3D grid. In other words, you measure \\(\\chi(\\vec x_i,\n\\omega)\\) for \\(i=1, \\ldots, N\\) (\\(N\\) is now the number of points, not the number of samples). The following average\n\\[\\frac 1N\\sum_{i=1}^N\\chi(\\vec x_i, \\omega)\\]\nis an estimate of the fraction of points that are located in the solid phase. In the limit of very dense 3D grids, the above sum converges to an integral\n\\[\\frac 1N\\sum_{i=1}^N\\chi(\\vec x_i, \\omega)\\to\\frac 1V\\int_{\\Omega}\\chi(\\vec x, \\omega)\\,\\mathrm{d} V,\\]\nwhere \\(\\Omega\\) denotes the domain occupied by the sponge, and \\(V\\) its volume. This quantity is the volume average \\(\\langle\\chi\\rangle(\\omega)\\) of \\(\\chi\\)\n\\[\\langle\\chi\\rangle(\\omega)=\\frac1V\\int_{\\Omega}\\chi(\\vec x, \\omega)\\,\\mathrm{d} V.\\]\nThe volume average depends on the realization \\(\\omega\\): in other words, the volume fraction of solid may vary from one sponge to another. However, we do know intuitively that for sufficiently large sponges, the volume average will in fact not depend on the realization. This property is not universal, though. It characterizes so-called ergodic materials. Very roughly speaking, for ergodic materials, volume averages over large domains converge to the ensemble average\n\\[\\lim_{V\\to+\\infty}\\frac1V\\int_{\\Omega}\\chi(\\vec x, \\omega)\\,\\mathrm{d} V\\to\\mathbb E(\\chi).\\]\nThis limit is sometimes called the thermodynamic limit. It will always be assumed in this series that the materials considered are ergodic."
  },
  {
    "objectID": "posts/20200421-What_is_homogenization-03/index.html#conclusion",
    "href": "posts/20200421-What_is_homogenization-03/index.html#conclusion",
    "title": "What is homogenization? Part 3: ensemble averages vs. volume averages",
    "section": "Conclusion",
    "text": "Conclusion\nThis post was a small detour on our way to homogenization. We previously introduced homogenization of a periodic microstructure, while what we really would like to define is homogenization of disordered microstructures. Modelling such disordered microstructures as random processes, we were able to define two kinds of averages of a quantity: the ensemble average over the realizations (the observation point being fixed) and the volume average over the domain (the realization being fixed). For statistically homogeneous materials, the ensemble average does not depend on the observation point. Furthermore, for ergodic materials, the volume average over a large domain coincides with the ensemble average.\nIn the next post, we will consider our first homogenization example."
  },
  {
    "objectID": "posts/20200421-What_is_homogenization-03/index.html#footnotes",
    "href": "posts/20200421-What_is_homogenization-03/index.html#footnotes",
    "title": "What is homogenization? Part 3: ensemble averages vs. volume averages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe material is homogeneous if all its correlation functions of any order \\(n\\) are translation invariant, that is \\(\\mathbb E[\\chi(\\vec x_1+\\vec r)\\cdots\\chi(\\vec x_n+\\vec r)]=\\mathbb E[\\chi(\\vec x_1)\\cdots\\chi(\\vec x_n)]\\) for all observation points \\(\\vec x_1, \\ldots, \\vec x_n\\) and translations \\(\\vec r\\).↩︎"
  },
  {
    "objectID": "posts/20150701-When_a_thin_shell_is_not_so_thin-02/index.html",
    "href": "posts/20150701-When_a_thin_shell_is_not_so_thin-02/index.html",
    "title": "When a thin shell is not so thin, part 2: the 3D, exact solution",
    "section": "",
    "text": "In the previous instalment of this series, we analysed a spherical pressure vessel by means of Koiter’s linear theory of thin shells. We found the somewhat unexpected result that the stress couple was not null. Besides, we also found that the stress resultant was slightly different from the well-known value \\(N=pR/2\\). So what was wrong with the previous analysis? To explore this question, we will make use of the exact solution in 3D elasticity.\n\nThe spherical pressure vessel, exact solution\nFinding the stresses and displacements in a pressure vessel is a classical exercise in 3D linear elasticity. In this post, I will spare you the details of the derivation (which can be found in e.g. Timoshenko and Goodier, Theory of Elasticity, 2nd edition, McGraw-Hill, 1951 art. 121). Instead, I will come straight to the point, and provide you with the exact expression of the stress tensor in spherical coordinates (\\(r\\): distance to the center of the spherical pressure vessel) \\[\n\\sigma_{rr}(r)=A-\\frac{2B}{r^3},\n\\tag{1}\\] \\[\n\\sigma_{\\theta\\theta}(r)=\\sigma_{\\phi\\phi}(r)=A+\\frac{B}{r^3},\n\\tag{2}\\] all other components being null. The integration constants \\(A\\) and \\(B\\) are defined below \\[\nA=-\\frac{p_\\text{ext}R_\\text{ext}^3-p_\\text{int}R_\\text{int}^3}{R_\\text{ext}^3-R_\\text{int}^3},\n\\] \\[\nB=-\\frac12\\frac{\\bigl(p_\\text{ext}-p_\\text{int}\\bigr)R_\\text{int}^3R_\\text{ext}^3}{R_\\text{ext}^3-R_\\text{int}^3},\n\\] where \\(R_\\text{int}=R-h/2\\) and \\(R_\\text{ext}=R+h/2\\) denote the internal and external radii of the spherical pressure vessel (\\(R\\): radius of midsurface, \\(h\\): thickness); \\(p_\\text{int}\\) and \\(p_\\text{ext}\\) denote the internal and external pressures. To make a fair comparison between the shell theory and the 3D exact solution, it is customary to share the load equally between the upper and lower faces (see e.g. Reissner, 1947). In other words, \\[\np_\\text{int}=-p_\\text{ext}=\\frac p2.\n\\]\nIn the remainder of this post, \\(\\sigma\\) will denote the common value of the in-plane stresses \\[\n\\sigma=\\sigma_{\\theta\\theta}=\\sigma_{\\phi\\phi}.\n\\tag{3}\\]\nFrom Eq. (2), we readily find the following expressions of the stress resultant \\(N=N_{\\theta\\theta}=N_{\\phi\\phi}\\) and stress couple \\(M=M_{\\theta\\theta}=M_{\\phi\\phi}\\) \\[\nN=\\int_{R_\\text{int}}^{R_\\text{ext}}\\sigma(r)\\,\\mathrm{d}r=\\frac{pR}2\\frac{1+\\frac{5h^2}{12R^2}}{1+\\frac{h^2}{12R^2}}=\\frac{pR}2\\Bigl(1+\\frac{h^2}{3R^2}\\Bigr)+\\mathcal O\\Bigl(\\frac{h^4}{R^4}\\Bigr),\n\\tag{4}\\] \\[\nM=-\\int_{R_\\text{int}}^{R_\\text{ext}}\\bigl(r-R\\bigr)\\sigma(r)\\,\\mathrm{d}r=\\frac{ph^2}{24}\\frac{1-\\frac{h^2}{4R^2}}{1+\\frac{h^2}{12R^2}}=\\frac{ph^2}{24}\\Bigl(1-\\frac{h^2}{3R^2}\\Bigr)+\\mathcal O\\Bigl(\\frac{h^6}{R^6}\\Bigr).\n\\tag{5}\\]\nComparing with Koiter's solution, it is found that the dominant terms of the stress resultant coincide. This is not true of the stress couple, though. Even worse, the signs differ! While in Koiter’s solution, the stress couple is negative (as expected), integration of the 3D solution leads to a positive stress couple, which is unphysical. Something nasty is definitely taking place, here!\nIn the next section, I will show that Eqs. (4) and (5) are in fact (poor) approximations of the true expression of the stress resultant and couple.\n\n\nStress resultants and stress couples: the correct definition\nStress resultants and stress couples are defined from the internal resultant forces and moments exerted on subdomains of the shell. In this section, I will show how such subsystems are constructed from a closed path drawn on the midsurface.\n\nThe story begins with a shell, seen as a continuum.\n\nWe will focus on the upper and lower faces of the shell, \\(\\Sigma^+\\) and \\(\\Sigma^-\\), as well as the base surface, \\(\\Sigma\\). For homogeneous shells, the base surface usually coincides with the midsurface (in other words, it is equidistant to the upper and lower faces). This is not really required here, as we are only discussing equilibrium issues. However, for the sake of simplicity, we will just assume that the base surface is the midsurface.\n\nTo define a subregion of the shell, we first draw a closed path \\(\\Gamma\\) on the base surface, and define the local basis \\((\\vec\\tau, \\vec n, \\vec\\nu)\\) attached to this curve: \\(\\vec\\tau\\) is the unit tangent, \\(\\vec n\\) is the unit normal to the base surface, and \\(\\vec\\nu=\\vec\\tau\\times\\vec n\\) is the unit in-plane normal to \\(\\Gamma\\).\n\nAs the current point moves along this path, the normal to the base surface sweeps a new surface, which will be the lateral surface of the subregion. It should be noted that, by construction, the lateral surface is a ruled surface. The outer normal to this surface is constant, equal to \\(\\vec\\nu\\) along each of the generating lines.\n\nThe lateral surface intersects the upper and lower faces of the shell…\n\n… thus defining the upper and lower boundaries of the subregion. That’s it! We have defined our subsystem!\nLet us now compute the resultant force \\(\\boldsymbol{\\mathcal R}\\) and moment \\(\\boldsymbol{\\mathcal M}\\) exerted by the remainder of the shell on this subregion. By definition of the Cauchy stress tensor \\(\\boldsymbol{\\sigma}\\), we have \\[\n\\boldsymbol{\\mathcal R}=\\int_{\\mathbf x\\in\\Sigma^\\mathrm{lat}}\\boldsymbol\\sigma\\cdot\\boldsymbol\\nu\\,\\mathrm{d}\\Sigma_{\\mathbf x}^\\mathrm{lat},\n\\tag{6}\\] \\[\n\\boldsymbol{\\mathcal M}=\\int_{\\mathbf x\\in\\Sigma^\\mathrm{lat}}\\mathbf{x}\\times\\bigl(\\boldsymbol\\sigma\\cdot\\boldsymbol\\nu\\bigr)\\mathrm{d}\\Sigma_{\\mathbf x}^\\mathrm{lat},\n\\tag{7}\\] where \\(\\mathbf x\\) denotes the current point on the lateral surface. By definition, the membrane stress resultant \\(\\mathbf{N}\\) (second order tensor), the shear stress resultant \\(\\vec Q\\) (vector) and the stress couple \\(\\mathbf{M}\\) (second order tensor) allow the reduction of the above surface integrals to contour integrals \\[\n\\boldsymbol{\\mathcal R}=\\int_{\\mathbf x\\in\\Gamma}\\bigl[\\mathbf N\\cdot\\boldsymbol\\nu+\\bigl(\\mathbf Q\\cdot\\boldsymbol\\nu\\bigr)\\mathbf n\\bigr]\\mathrm{d}s,\n\\tag{8}\\] \\[\n\\boldsymbol{\\mathcal M}=\\int_{\\mathbf x\\in\\Gamma}\\mathbf x\\times\\bigl[\\mathbf N\\cdot\\boldsymbol\\nu+\\bigl(\\mathbf Q\\cdot\\boldsymbol\\nu\\bigr)\\mathbf n\\bigr]\\mathrm{d}s-\\int_{\\mathbf x\\in\\Gamma}\\mathbf n\\times\\bigl(\\mathbf M\\cdot\\boldsymbol\\nu\\bigr)\\mathrm ds.\n\\tag{9}\\]\nThis definition will be used in the next section to compute the stress resultant and couple in the spherical pressure vessel.\n\n\nStress resultant and couple in the spherical pressure vessel\n\nIn order to compute \\(N\\) and \\(M\\) from the stress distribution in the spherical pressure vessel, we consider a subdomain obtained by taking the equator as closed path \\(\\Gamma\\). Then, the lateral surface \\(\\Sigma^\\mathrm{lat}\\) is an annulus, and the outer normal \\(\\boldsymbol\\nu\\) is constant, vertical. Points on the lateral surface are specified by their radial distance \\(r\\) and polar angle \\(\\phi\\).\nWe first use Eq. (6) to compute the resultant internal force \\(\\boldsymbol{\\mathcal R}\\). The surface element \\(\\mathrm{d}\\Sigma^\\mathrm{lat}\\) reads \\[\n\\mathrm{d}\\Sigma^\\mathrm{lat}=r\\,\\mathrm{d}r\\,\\mathrm{d}\\phi=\\frac rR\\,\\mathrm{d}r\\,\\mathrm{d}s,\n\\] where it is observed that \\(\\mathrm{d}s=R\\mathrm{d}\\phi\\) (\\(s\\): arc-length measured on \\(\\Gamma\\)). Furthermore, from Eq. (3), we have \\(\\boldsymbol\\sigma\\cdot\\boldsymbol\\nu=\\sigma(r)\\,\\boldsymbol\\nu\\). Eq. (6) then reads \\[\n\\boldsymbol{\\mathcal R}=\\int_\\Gamma\\Bigl[\\int_{R_\\mathrm{int}}^{R_\\mathrm{ext}}\\sigma(r)\\,\\frac rR\\,\\mathrm{d}r\\Bigr]\\boldsymbol\\nu\\,\\mathrm{d}s,\n\\tag{10}\\] where we have used the fact that \\(\\boldsymbol\\nu\\) is constant along \\(\\Gamma\\). Turning now to Eq. (8), and recalling that \\(N_{\\theta\\theta}=N_{\\phi\\phi}=N\\) and \\(\\mathbf Q=\\mathbf 0\\), we find \\[\n\\boldsymbol{\\mathcal R}=\\int_{\\Gamma}N\\,\\boldsymbol\\nu\\mathrm{d}s.\n\\tag{11}\\]\nUpon identification of Eqs. (10) and (11), we finally find the following expression of the stress resultant \\(N\\) \\[\nN=\\int_{R_\\mathrm{int}}^{R_\\mathrm{ext}}\\sigma(r)\\,{\\color{red}\\frac rR}\\,\\mathrm{d}r,\n\\tag{12}\\] while a similar calculation delivers the stress couple \\(M\\) \\[\nM=\\int_{R_\\mathrm{int}}^{R_\\mathrm{ext}}-\\bigl(r-R\\bigr)\\sigma(r)\\,{\\color{red}\\frac rR}\\,\\mathrm{d}r.\n\\tag{13}\\]\nComparing Eqs. (12) and (13) with Eqs. (4) and (5), we observe that we forgot the Jacobian \\(r/R\\)! For thin shells, we have \\(r\\simeq R\\) and this correction is usually neglected.\nIn the present case, using Eq. (2), we find \\[\nN=\\frac{pR}2\\bigl(1+\\frac{h^2}{4R^2}\\bigr),\n\\tag{14}\\] \\[\nM=-\\frac{ph^2}{30}\\,\\frac{h^2}{R^2}+\\mathcal O\\bigl(\\frac{h^6}{R^6}\\bigr).\n\\tag{15}\\]\nComparing Eqs. (14) and (15) with Eqs. (4) and (5), we see that the results are dramatically different! Indeed, the stress couple has a different sign, and is two order of magnitude smaller (with respect to the thickness of the shell)! Clearly, the thin shell approximation is questionable in the present case.\n\n\nConclusion\nIn this post, we used the exact stress distribution within the spherical vessel to compute the stress resultant and stress couple. We showed that the thin shell approximation, which amounts to neglecting the jacobian in a surface integral, results in poor estimates in this case. Exact integration delivers much more convincing results. However, we still have not completely solved the problem. Indeed, comparing Eqs. (14) and (15) with Eqs. (17) and (18) in the previous instalment of this series, we still observe major differences: the two values of the stress couple have the same sign, but they differ by two orders of magnitude (with respect to the thickness of the shell).\nIn the next instalment of this series, we will go back to Koiter’s shell model and use constitutive equations for thick shells to finally resolve the apparent contradiction.\nFigures in this post were generated with the nice PyX library."
  },
  {
    "objectID": "posts/20131229-Elastic_constants_of_an_isotropic_material-02/index.html",
    "href": "posts/20131229-Elastic_constants_of_an_isotropic_material-02/index.html",
    "title": "Elastic constants of an isotropic material, part 2: plane strain elasticity",
    "section": "",
    "text": "In the previous instalment of this series, I introduced the constitutive law of an isotropically elastic material, and the related material constants, within the framework of 3D elasticity. I will now address the case of plane strain elasticity.\nProblems of plane strain elasticity are defined as problems where the following components of the strain tensor are null \\[\n\\varepsilon_{31} = \\varepsilon_{23} = \\varepsilon_{33} = 0.\n\\tag{1}\\]\nThis is typically true of problems for which the geometry and the loading are invariant along the third direction \\(\\vec e_3\\). In what follows, it will be covenient to adopt the following classical notation\nIn both cases, Einstein’s convention applies; in other words, \\(\\varepsilon_{kk}\\) stands for \\[\n\\sum_{k=1}^3\\varepsilon_{kk},\n\\] while \\(\\varepsilon_{\\gamma\\gamma}\\) stands for \\[\n\\sum_{\\gamma=1}^2\\varepsilon_{\\gamma\\gamma}.\n\\]\nAs in the previous instalment, the constitutive laws in isotropic, plane strain elasticity will be derived using various sets of material constants, starting with the bulk modulus \\(E\\) and the Poisso ratio \\(\\nu\\)."
  },
  {
    "objectID": "posts/20131229-Elastic_constants_of_an_isotropic_material-02/index.html#conclusion",
    "href": "posts/20131229-Elastic_constants_of_an_isotropic_material-02/index.html#conclusion",
    "title": "Elastic constants of an isotropic material, part 2: plane strain elasticity",
    "section": "Conclusion",
    "text": "Conclusion\nIn this instalment, we have seen how the plane strain asumption affects the constitutive law of isotropic, linear and elastic materials. In particular, the bulk modulus which is the ratio of the average stress to the relative surface change appears to be dimension dependent. In the next instalment, we will reconcile the 3D and 2D points of view."
  },
  {
    "objectID": "posts/20201208-What_is_homogenization-04/index.html",
    "href": "posts/20201208-What_is_homogenization-04/index.html",
    "title": "What is homogenization? Part 4: a first example",
    "section": "",
    "text": "In the previous instalment of this series on homogenization, we discussed volume and ensemble averages for random heterogeneous materials. In view of introducing statistical and representative volume elements, we will introduce in this post our first homogenization example, namely a two-dimensional, rectangular mesh of springs that is loaded in its plane only. We will show that this system can be homogenized as a plate, the extensional stiffnesses of which we will derive in closed-form.\nNote that this example is fully deterministic and in fact, periodic. Periodic homogenization provides a rigorous framework for the derivation of its effective properties. The derivation presented here is more heuristic and does not rely on this framework.\nThe figure below shows the spring mesh considered in this post; \\(\\ell\\) is the length of the diagonal springs. These springs make an angle \\(\\theta\\) with the \\(x\\)-axis. The grid spacing is therefore \\(\\Delta x=\\ell\\cos\\theta\\) along the \\(x\\)-axis and \\(\\Delta y=\\ell\\sin\\theta\\) along the \\(y\\)-axis. The stiffness of the diagonal springs is \\(k\\); the stiffnesses of the horizontal and vertical springs are \\(\\chi_x\\,k\\) and \\(\\chi_y\\,k\\), respectively (\\(\\chi_x\\), \\(\\chi_y\\): dimensionless numbers).\nIt will be convenient to introduce the radius-vector of the mesh nodes\n\\[\n\\vec x_{ij}=i\\Delta x\\,\\vec e_x+j\\Delta y\\,\\vec e_y.\n\\]\nSimilarly, we introduce the mid-points \\(\\vec x_{i+1/2, j}\\), \\(\\vec x_{i,\nj+1/2}\\) and \\(\\vec x_{i+1/2, j+1/2}\\).\nSeen from far away, this mesh behaves as a plate that would be loaded in its plane only. In particular, we will show that when \\(\\theta=\\pi/4\\) (square mesh) and \\(\\chi_x=\\chi_y=2\\), the homogenized plate is isotropic, with Poisson ratio \\(\\nu=1/3\\) and membrane stiffness\n\\[\nA=\\frac{Eh}{1-\\nu^2}=3k.\n\\]"
  },
  {
    "objectID": "posts/20201208-What_is_homogenization-04/index.html#outline-of-the-homogenization-strategy",
    "href": "posts/20201208-What_is_homogenization-04/index.html#outline-of-the-homogenization-strategy",
    "title": "What is homogenization? Part 4: a first example",
    "section": "Outline of the homogenization strategy",
    "text": "Outline of the homogenization strategy\nOur strategy relies on the approximation of the elastic energy of the spring mesh. It is recalled that the elastic energy of a spring is fully defined by the displacements of the end-points. In the present case, the end-points are the vertices \\(\\vec x_{ij}\\) of the grid, with displacement \\(\\vec\nu_{ij}\\). Our aim is to replace the discrete set of springs with a continuous structure. It is natural to assume that the nodal displacements \\(\\vec u_{ij}\\) are the trace of a smooth displacement field, \\(\\vec u\\): \\(\\vec u_{ij}\\simeq\\vec\nu(\\vec x_{ij})\\).\nOwing to the separation of scales, we will also assume that the typical size of the microstructure (namely, the size \\(\\ell\\) of a spring) is small, compared to the typical length scale over which the smooth displacement field \\(\\vec u\\) varies. The first element of our strategy is to perform Taylor expansions of \\(\\vec u\\) with respect to the powers of \\(\\ell\\).\nThe second element of our strategy is the fact that the elastic energy of the mesh is additive. More precisely, it is the sum of the energies of each spring\n\\[W=\\sum_{i, j}\\bigl(W_{i+1/2, j}+W_{i, j+1/2}+W_{i+1/2, j+1/2}\\bigr),\\]\nwhere \\(W_{i+1/2, j}\\) (resp. \\(W_{i, j+1/2}\\), \\(W_{i+1/2, j+1/2}\\)) denote the elastic energy of the horizontal (resp. vertical, diagonal) spring centered at \\(\\vec x_{i, j+1/2}\\) (resp. \\(\\vec x_{i, j+1/2}\\), \\(\\vec x_{i+1/2,\nj+1/2}\\)). Note that \\(W_{i+1/2, j+1/2}\\) is the energy of two diagonal springs.\nEach spring of a specific type (horizontal, vertical or diagonal) covers a rectangular “influence zone”. For the horizontal spring centered at \\(\\vec\nx_{i+1/2, j}\\), the influence zone is the area: \\(i\\Delta x\\leq\nx\\leq\\bigl(i+1\\bigr)\\Delta x\\) and \\(\\bigl(j-1/2\\bigr)\\Delta y\\leq\ny\\leq\\bigl(j+1/2\\bigr)\\Delta y\\)\n\n\n\n“Influence zone” of horizontal springs\n\n\nFor the vertical spring centered at \\(\\vec x_{i, j+1/2}\\), the influence zone is the area: \\(\\bigl(i-1/2\\bigr)\\Delta x\\leq x\\leq\\bigl(i+1/2\\bigr)\\Delta x\\) and \\(j\\Delta y\\leq y\\leq\\bigl(j+1\\bigr)\\Delta y\\)\n\n\n\n“Influence zone” of vertical springs\n\n\nFinally, for the diagonal springs centered at \\(\\vec x_{i+1/2, j+1/2}\\), the influence zone is the area: \\(i\\Delta x\\leq x\\leq\\bigl(i+1\\bigr)\\Delta x\\) and \\(j\\Delta y\\leq y\\leq\\bigl(j+1\\bigr)\\Delta y\\)\n\n\n\n“Influence zone” of vertical springs\n\n\nIn all three cases, the “influence zone” has the same area, \\(\\Delta x\\,\\Delta\ny=\\ell^2\\cos\\theta\\sin\\theta\\). We write the elastic energy\n\\[W=\\sum_{i, j}\\bigl(\\frac{W_{i+1/2, j}}{\\ell^2\\cos\\theta\\sin\\theta}+\\frac{W_{i, j+1/2}}{\\ell^2\\cos\\theta\\sin\\theta}+\\frac{W_{i+1/2, j+1/2}}{\\ell^2\\cos\\theta\\sin\\theta}\\bigr)\\Delta x\\,\\Delta y,\\]\nwith \\(\\Delta x=\\ell\\cos\\theta\\) and \\(\\Delta y=\\ell\\sin\\theta\\).\nWe will show that, when the size of the springs \\(\\ell\\) tends to zero, the various terms of this sum have a limit\n\\[\\frac{W_{i+1/2, j}}{\\ell^2\\cos\\theta\\sin\\theta}\n\\to w_x[\\boldsymbol{\\varepsilon}(\\vec x_{i+1/2, j})],\n\\quad\\frac{W_{i, j+1/2}}{\\ell^2\\cos\\theta\\sin\\theta}\n\\to w_y[\\boldsymbol{\\varepsilon}(\\vec x_{i, j+1/2})]\\] and \\[\\frac{W_{i+1/2, j+1/2}}{\\ell^2\\cos\\theta\\sin\\theta}\\to w_{xy}[\\boldsymbol{\\varepsilon}(\\vec x_{i+1/2, j+1/2})],\\]\nwhere it is noted that the various \\(w_\\star\\) are functions of \\(\\boldsymbol{\\varepsilon}=\\operatorname{\\mathbf{sym}}\\operatorname{\\mathbf{grad}}\\vec u\\). The elastic energy of the spring then reads\n\\[W=\\sum_{i, j}\\bigl\\{w_x[\\boldsymbol{\\varepsilon}(\\vec x_{i+1/2, j})]+w_y[\\boldsymbol{\\varepsilon}(\\vec x_{i, j+1/2})]+w_{xy}[\\boldsymbol{\\varepsilon}(\\vec x_{i+1/2, j+1/2})]\\bigr\\}\\Delta x\\,\\Delta y,\\]\nwhich can be interpreted as a Riemann sum\n\\[W=\\int\\bigl\\{w_x[\\boldsymbol{\\varepsilon}(\\vec x)]+w_y[\\boldsymbol{\\varepsilon}(\\vec x)]+w_{xy}[\\boldsymbol{\\varepsilon}(\\vec x)]\\bigr\\}\\mathrm{d} x\\,\\mathrm{d} y.\\]\nIn other words, homogenization of the spring mesh leads to a continuous mechanical system with elastic energy density \\(w=w_x+w_y+w_{xy}\\). Note that \\(w\\) is a function of the strain tensor \\(\\boldsymbol{\\varepsilon}\\). Therefore, the homogenized spring mesh behaves as a plate that deforms in its plane only. The expression of the plate effective stiffness will be discussed in the next section."
  },
  {
    "objectID": "posts/20201208-What_is_homogenization-04/index.html#elastic-energy-of-the-mesh",
    "href": "posts/20201208-What_is_homogenization-04/index.html#elastic-energy-of-the-mesh",
    "title": "What is homogenization? Part 4: a first example",
    "section": "Elastic energy of the mesh",
    "text": "Elastic energy of the mesh\nIt is shown in the appendix below that the elastic energy densities of each type of springs have the following expressions\n\\[w_x=\\tfrac12k\\,\\chi_x \\operatorname{cotan}\\theta\\,\\varepsilon_{xx}^2,\n\\quad w_y=\\tfrac12k\\,\\chi_y\\tan\\theta\\,\\varepsilon_{yy}^2\\]\nand\n\\[\\begin{aligned}w_{xy}={}&\\tfrac12k\\operatorname{cotan}\\theta\\bigl(1+\\cos2\\theta\\bigr)\\varepsilon_{xx}^2+\\tfrac12k\\tan\\theta\\bigl(1-\\cos2\\theta\\bigr)\\,\\varepsilon_{yy}^2\\\\&+k\\sin2\\theta\\bigl(\\varepsilon_{xx}\\,\\varepsilon_{yy}+2\\,\\varepsilon_{xy}^2\\bigr).\\end{aligned}\\]\nSumming all three contributions, we find the strain energy density of an orthotropic plate that is loaded in its plane only, namely\n\\[w=\\tfrac12A_x\\,\\varepsilon_{xx}^2+\\tfrac12A_y\\,\\varepsilon_{yy}^2+\\tfrac12\\bigl(\\nu_{xy}\\,A_y+\\nu_{yx}\\,A_x\\bigr)\\varepsilon_{xx}\\,\\varepsilon_{yy}+A_{xy}\\varepsilon_{xy}^2,\\]\nwith\n\\[A_x=k\\operatorname{cotan}\\theta\\bigl(1+\\cos2\\theta+\\chi_x\\bigr),\\] \\[A_y=k\\tan\\theta\\bigl(1-\\cos2\\theta+\\chi_y\\bigr),\\] \\[\\nu_{xy}\\,A_y=\\nu_{yx}\\,A_x=k\\sin2\\theta,\\] \\[A_{xy}=2k\\sin2\\theta.\\]\nThe Poisson ratios can be expressed as follows \\[\\nu_{xy}=\\frac{1+\\cos2\\theta}{1-\\cos2\\theta+\\chi_y}\n\\quad\\text{and}\\quad\n\\nu_{yx}=\\frac{1-\\cos2\\theta}{1+\\cos2\\theta+\\chi_x}.\\]\nIt is interesting to find the conditions under which the above equivalent membrane is isotropic. We must have\n\\[A=A_x=A_y,\\quad\\nu=\\nu_{xy}=\\nu_{yx}\\quad\\text{and}\\quad A_{xy}=\\bigl(1-\\nu\\bigr)A,\\]\nwhere \\(\\nu\\) is the unique Poisson ratio and \\(A=Eh/(1-\\nu^2)\\) is the classical membrane stiffness. Since \\(A_{xy}=2\\nu_{xy}\\,A_y=2\\nu_{yx}\\,A_x\\), the third identity leads to \\(\\nu=1/3\\). From the expressions of the Poisson ratios, we deduce that\n\\[\\chi_x=2-4\\cos2\\theta\\quad\\text{and}\\quad\\chi_y=2+4\\cos2\\theta.\\]\nPlugging into the expressions of \\(A_x\\) and \\(A_y\\), we find\n\\[A=A_x=A_y=3k\\sin2\\theta.\\]\nFor a square mesh, \\(\\theta=\\pi/4\\), and isotropy requires that \\(\\chi_x=\\chi_y=2\\). In other words, if the horizontal and vertical springs are twice as stiff as the diagonal springs, then the mesh behaves as an isotropic plane membrane, with membrane stiffness \\(A=3k\\) and Poisson ratio \\(\\nu=1/3\\)."
  },
  {
    "objectID": "posts/20201208-What_is_homogenization-04/index.html#conclusion",
    "href": "posts/20201208-What_is_homogenization-04/index.html#conclusion",
    "title": "What is homogenization? Part 4: a first example",
    "section": "Conclusion",
    "text": "Conclusion\nWe have encountered our first homogenization example. A rectangular mesh of springs can be homogenized as a continuous plate loaded in its plane only. We saw the conditions on the geometry of the mesh and the stiffnesses of the springs for the homogenized plate to behave isotropically.\nIn the next instalment of this series, we will discuss size effects in a deterministic setting."
  },
  {
    "objectID": "posts/20201208-What_is_homogenization-04/index.html#sec-20240323142428",
    "href": "posts/20201208-What_is_homogenization-04/index.html#sec-20240323142428",
    "title": "What is homogenization? Part 4: a first example",
    "section": "Appendix: derivation of the effective elastic energy",
    "text": "Appendix: derivation of the effective elastic energy\nIn this appendix, we derive the expression of the effective elastic energy of the mesh of springs. We first express the elastic energy of one spring as a function of the strain \\(\\boldsymbol{\\varepsilon}\\) (assuming that the homogenized displacement field \\(\\vec u\\) is smooth enough to allow for Taylor expansions).\nThen, the general expression of the elastic energy is specialized to each type of springs (horizontal, vertical and diagonal). In all three cases, it is shown that the energy per unit area does not depend on the size \\(\\ell\\) of the spring, which makes evaluation of the limit when \\(\\ell\\to0\\) straightforward.\n\nContribution of one spring\nWe consider one of the springs of the mesh, located between the end-points \\(A\\) and \\(B\\), with radius-vectors \\(\\vec x_A\\) and \\(\\vec x_B\\). We introduce the radius-vector \\(\\vec x_{AB}\\) of the mid-point\n\\[\\vec x_{AB}=\\tfrac12\\bigl(\\vec x_A+\\vec x_B\\bigr)\\]\nand we have\n\\[\\vec x_A=\\vec x_{AB}-\\tfrac12\\ell_{AB}\\,\\vec n_{AB}\n\\quad\\text{and}\\quad\n\\vec x_B=\\vec x_{AB}+\\tfrac12\\ell_{AB}\\,\\vec n_{AB},\\]\nwhere \\(\\ell_{AB}\\) and \\(\\vec n_{AB}\\) are the length at rest of the spring and unit-vector that orients the spring, respectively. It is recalled (see this post, with slightly different notation) that the elastic energy of the spring is given by the formula\n\\[W_{AB}=\\tfrac12k_{AB}\\bigl[\\vec n_{AB}\\cdot\\bigl(\\vec u_B-\\vec u_A\\bigr)\\bigr]^2,\\]\nwhere \\(k_{AB}\\) denotes the stiffness of the spring and \\(\\vec u_A\\) and \\(\\vec\nu_B\\) are the displacements of the two end-points. We assume here that these displacements are given by a smooth map \\(\\vec u(\\vec x)\\). Then\n\\[\\vec u_B-\\vec u_A\n=\\vec u(\\vec x_{AB}+\\tfrac12\\ell_{AB}\\,\\vec n_{AB})\n-\\vec u(\\vec x_{AB}-\\tfrac12\\ell_{AB}\\,\\vec n_{AB}).\\]\nWithin the framework of homogenization, we assumed that \\(\\vec u(\\vec x)\\) is “smooth”, in the sense that the typical length-scale over which this field varies is large, compared to the typical length-scale of the microstructure. In other words, the variations of \\(\\vec u\\) between points \\(A\\) and \\(B\\) are small, and we can expand the above expression to first order in \\(\\ell_{AB}\\)\n\\[\\vec u_B-\\vec u_A=\\ell_{AB}\\operatorname{\\mathbf{grad}}\\vec u(\\vec x_{AB})\\cdot\\vec n_{AB}+\\mathcal O(\\ell_{AB}^2).\\]\nTo lowest order, the elastic energy of the spring therefore reads\n\\[W_{AB}=\\tfrac12k_{AB}\\ell_{AB}^2\\bigl[\\vec n_{AB}\\cdot\\operatorname{\\mathbf{grad}}\\vec u(\\vec x_{AB})\\cdot\\vec n_{AB}\\bigr]^2.\\]\nThe above tensor product involves only the symmetric part of the gradient of \\(\\vec u\\), that we will call (surprise, surprise) \\(\\boldsymbol{\\varepsilon}\\)\n\\[\\boldsymbol{\\varepsilon}(\\vec x)=\\operatorname{\\mathbf{sym}} \\operatorname{\\mathbf{grad}}\\vec u(\\vec x).\\]\nThen\n\\[W_{AB}=\\tfrac12k_{AB}\\ell_{AB}^2\\bigl[\\vec n_{AB}\\cdot\\boldsymbol{\\varepsilon}(\\vec x_{AB})\\cdot\\vec n_{AB}\\bigr]^2.\\]\nThis expression can be specialized for all four types of springs that are present in the mesh considered here.\n\n\nContribution of the horizontal and vertical springs\nFor a horizontal spring centered at \\(\\vec x_{i+1/2, j}\\), we have \\(\\ell_{AB}=\\ell\\cos\\theta\\) and \\(\\vec n_{AB}=\\vec e_x\\). Therefore, the elastic energy of one horizontal spring reads\n\\[W_{i+1/2, j}=\\tfrac12\\chi_xk\\ell^2\\cos^2\\theta\\bigl[\\varepsilon_{xx}(\\vec x_{i+1/2, j})\\bigr]^2\\]\nand, dividing by the area \\(\\ell\\cos\\theta\\times\\ell\\sin\\theta\\) of a cell, we find the elastic energy density\n\\[w_x=\\tfrac12k\\chi_x\\operatorname{cotan}\\theta\\,\\varepsilon_{xx}^2.\\]\nFor the vertical springs, we would find similarly\n\\[w_y=\\tfrac12k\\chi_y\\tan\\theta\\,\\varepsilon_{yy}^2.\\]\n\n\nContribution of the diagonal springs\nFor the diagonal springs centered at \\(\\vec x_{i+1/2, j+1/2}\\), we have\n\\[\\vec n_{AB}=\\zeta\\,\\cos\\theta\\,\\vec e_x+\\sin\\theta\\,\\vec e_y\\quad\\text{and}\\quad\\ell_{AB}=\\ell,\\]\nwhere \\(\\zeta=+1\\) (south-west to north-east spring) or \\(\\zeta=-1\\) (south-east to north-west spring). Therefore, the energy of the diagonal spring\n\\[\n\\begin{aligned}\nW_{i+1/2, j+1/2}={}\n&\\tfrac12k\\ell^2\\bigl[\\bigl(\\zeta\\,\\cos\\theta\\,\\vec e_x+\\sin\\theta\\,\\vec e_y\\bigr)\\cdot\\boldsymbol{\\varepsilon}\\cdot\\bigl(\\zeta\\,\\cos\\theta\\,\\vec e_x+\\sin\\theta\\,\\vec e_y\\bigr)\\bigr]^2\\\\\n={}&\\tfrac12k\\ell^2\\bigl(\\cos^2\\theta\\,\\varepsilon_{xx}+\\sin^2\\theta\\,\\varepsilon_{yy}+\\zeta\\sin2\\theta\\,\\varepsilon_{xy}\\bigr)^2,\n\\end{aligned}\n\\]\nwhere it is understood that \\(\\boldsymbol{\\varepsilon}\\), \\(\\varepsilon_{xx}\\), \\(\\varepsilon_{yy}\\) and \\(\\varepsilon_{xy}\\) are evaluated at \\(\\vec x_{i+1/2,\nj+1/2}\\). Using the identity \\((a+b)^2+(a-b)^2=2(a^2+b^2)\\), we find the total energy of the two diagonal springs centered at the same point \\(\\vec x_{i+1/2,\nj+1/2}\\)\n\\[\n\\begin{aligned}\nW_{xy}\n&=k\\ell^2\\bigl[\\bigl(\\cos^2\\theta\\,\\varepsilon_{xx}+\\sin^2\\theta\\,\\varepsilon_{yy}\\bigr)^2+\\sin^22\\theta\\,\\varepsilon_{xy}^2\\bigr]\\\\\n&=k\\ell^2\\bigl[\\cos^4\\theta\\,\\varepsilon_{xx}^2+\\sin^4\\theta\\,\\varepsilon_{yy}^2+\\sin^22\\theta\\bigl(\\tfrac12\\varepsilon_{xx}\\,\\varepsilon_{yy}+\\varepsilon_{xy}^2\\bigr)\\bigr],\n\\end{aligned}\n\\]\nfrom which we deduce the contribution to the elastic energy density\n\\[\n\\begin{aligned}\nw_{xy}={}&k\\ell^2\\biggl[\\frac{\\cos^3\\theta}{\\sin\\theta}\\varepsilon_{xx}^2+\\frac{\\sin^3\\theta}{\\cos\\theta}\\varepsilon_{yy}^2+\\sin2\\theta\\bigl(\\varepsilon_{xx}\\,\\varepsilon_{yy}+2\\,\\varepsilon_{xy}^2\\bigr)\\biggr]\\\\\n={}&\\tfrac12k\\ell^2\\bigl[\\operatorname{cotan}\\theta\\bigl(1+\\cos2\\theta\\bigr)\\varepsilon_{xx}^2+\\tan\\theta\\bigl(1-\\cos2\\theta\\bigr)\\varepsilon_{yy}^2\\\\\n&+2\\sin2\\theta\\bigl(\\varepsilon_{xx}\\,\\varepsilon_{yy}+2\\,\\varepsilon_{xy}^2\\bigr)\\bigr].\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html",
    "href": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html",
    "title": "Orientation correlations among rice grains, part 5: thresholding",
    "section": "",
    "text": "In the previous instalment of this series, we used the circle Hough transform to find the boundary of the sample and define the circular ROI. Within this ROI, we now need to segment the rice grains. In other words, starting from a gray-level image (Fig. 1, left), we want to produce a binary image, where all pixels that we believe belong to rice grains are white, and all background pixels are black (Fig. 1, right). This is the topic of the present post, where we will use Otsu’s automated threshold selection. I will first discuss Otsu’s method, and propose what I believe is a new interpretation of this rather old technique. Then, I will apply this method to the 3D image of rice grains, using scikit-image."
  },
  {
    "objectID": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html#sec-01",
    "href": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html#sec-01",
    "title": "Orientation correlations among rice grains, part 5: thresholding",
    "section": "Proof of assertion (1)",
    "text": "Proof of assertion (1)\nThis assertion is proved by contradiction. Let us assume that there exists two pixels \\(x\\) and \\(y\\) (\\(x\\neq y\\)) with same value in the original image [\\(f(x)=f(y)\\)] and different values in the binary approximation [\\(g(x)\\neq\ng(y)\\)]. We select \\(g_2\\in\\{g(x),g(y)\\}=\\{g_0, g_1\\}\\) so that \\[\n\\begin{aligned}\n\\bigl(f(x)-g_2\\bigr)^2\n&=\\bigl(f(y)-g_2\\bigr)^2\\\\\n&=\\min\\bigl(\\bigl[f(x)-g(x)\\bigr]^2, \\bigl[f(y)-g(y)\\bigr]^2\\bigr),\n\\end{aligned}\n\\] and \\[\n\\bigl[f(x)-g_2\\bigr]^2+\\bigl[f(y)-g_2\\bigr]^2&lt;\\bigl[f(x)-g(x)\\bigr]^2+\\bigl[f(y)-g(y)\\bigr]^2,\n\\tag{17}\\] since \\(g(x)\\neq g(y)\\). It should be noted that the above inequality is strict. We then define \\(\\tilde g\\colon E\\to\\{g_0,g_1\\}\\) as follows:\n\n\\(\\tilde g(x)=g_2\\),\n\\(\\tilde g(y)=g_2\\),\n\\(\\tilde g(z)=g(z)\\) if \\(z\\neq x\\) and \\(z\\neq y\\).\n\nThen, simple algebra leads to \\[\nd(f,\\tilde g)^2-d(f,g)^2=\\bigl[f(x)-g_2\\bigr]^2+\\bigl[f(y)-g_2\\bigr]^2-\\bigl[f(x)-g(x)\\bigr]^2-\\bigl[f(y)-g(y)\\bigr]^2.\n\\]\nFrom Eq. (17), we then find \\(d(f,\\tilde g)^2 &lt; d(f,g)^2\\), which leads to a contradiction, since \\(g\\) optimizes the distance to \\(f\\). Thus, assertion (1) is proved."
  },
  {
    "objectID": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html#sec-02",
    "href": "posts/20150709-Orientation_correlations_among_rice_grains-05/index.html#sec-02",
    "title": "Orientation correlations among rice grains, part 5: thresholding",
    "section": "Proof of assertion (2)",
    "text": "Proof of assertion (2)\nThis assertion is again proved by contradiction. Let us assume that there exists \\(x, y\\in E\\) such that \\(f(x) &lt; f(y)\\) and \\(g(x) &gt; g(y)\\). Then, simple algebra shows that \\[\n\\begin{multline}\n\\bigl[f(x)-g(y)\\bigr]^2+\\bigl[f(y)-g(x)\\bigr]^2=\\bigl[f(x)-g(x)\\bigr]^2+\\bigl[f(y)-g(y)\\bigr]^2\\\\\n+2\\bigl[f(y)-f(x)\\bigr]\\bigl[g(y)-g(x)\\bigr],\n\\end{multline}\n\\] and the last term is negative. Proceeding as above, we then build \\(\\tilde g\\) as follows:\n\n\\(\\tilde{g}(x)=g(y)\\),\n\\(\\tilde{g}(y)=g(x)\\),\n\\(\\tilde{g}(z)=g(z)\\) if \\(z\\neq x\\) and \\(z\\neq y\\).\n\nThen \\[\nd(f, \\tilde g)^2-d(f,g)^2=\\bigl[f(x)-g(y)\\bigr]^2+\\bigl[f(y)-g(x)\\bigr]^2\n-\\bigl[f(x)-g(x)\\bigr]^2-\\bigl[f(y)-g(y)\\bigr]^2,\n\\] which is negative. Contradiction!"
  },
  {
    "objectID": "posts/20180226-On_the_periodic-plus-smooth_decomposition_of_an_image-03/index.html",
    "href": "posts/20180226-On_the_periodic-plus-smooth_decomposition_of_an_image-03/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 3: the energy as a quadratic form",
    "section": "",
    "text": "In the previous instalment of this series, we introduced the periodic-plus-smooth decomposition of an image as a pair of images which minimizes an energy functional. Observing that this energy is a quadratic form, the purpose of this post is to derive closed form expressions of the underlying linear operators. These expressions will then be combined in the next instalments to a conjugate gradient algorithm in order to minimize the energy of the periodic-plus-smooth decomposition.\nThis post is the third instalment of a series in seven parts:\n\nIntroduction\nDefining the decomposition\nThe energy as a quadratic form\nImplementing the linear operators\nMinimizing the energy, the clumsy way\nMinimizing the energy, the clever way\nImproved implementation of Moisan’s algorithm\n\nThe code discussed in this series is available as a Python module on GitHub.\nIn this post, it will be convenient to regard images as vectors. Given two \\(m\\times n\\) images \\(u\\) and \\(v\\), the scalar product \\(\\langle u, v\\rangle\\) is then defined as\n\\[\\langle u, v\\rangle=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{ij}v_{ij}.\\]\nLikewise, a linear operator \\(A\\) over the space of \\(m\\times n\\) images is defined as follows\n\\[v=A\\cdot u,\\quad\\text{with}\\quad v_{ij}=\\sum_{k=0}^{m-1}\\sum_{l=0}^{n-1}A_{ij,kl}u_{kl}.\\]\nAccording to Moisan (2011), the total energy \\(E(p, s)\\) of the periodic-plus-smooth decomposition of an image \\(u=p+s\\) is defined as the sum \\(E(p, s)=E_\\mathrm p(p)+E_\\mathrm s(s)\\) (see previous instalment), and the smooth component \\(s\\) is the solution to the following minimization problem\n\\[s=\\operatorname*{arg\\,min}_v F(v, u),\\]\nwith\n\\[F(v, u)=E_\\mathrm p(u-v)+E_\\mathrm s(v)+(\\operatorname{mean}v)^2.\\]\nIntroducing the linear operators \\(Q_1\\) and \\(Q\\) such that\n\\[\\langle v, Q_1\\cdot v\\rangle=E_\\mathrm p(v)\n\\quad\\text{and}\\quad\n\\langle v, Q\\cdot v\\rangle\n=E_\\mathrm p(v)+E_\\mathrm s(v)+(\\operatorname{mean}v)^2,\\]\nit is readily found that\n\\[F(v, u)=\\langle v, Q\\cdot v\\rangle-2\\langle v, Q_1\\cdot u\\rangle\n+\\langle u, Q_1\\cdot u\\rangle.\\]\nThe closed-form expression of \\(Q_1\\) is derived in the first part of this post. Then, operator \\(Q\\) is derived in the second part of this post.\n\nDerivation of the Q1 operator\nThe contribution to the total energy of the periodic component \\(p\\) is defined by Moisan (2011) as follows (see also previous post)\n\\[\nE_\\mathrm p(p)=2\\sum_{i=0}^{m-1}(p_{i, n-1}-p_{i, 0})^2\n+2\\sum_{j=0}^{n-1}(p_{m-1, j}-p_{0, j})^2.\n\\tag{1}\\]\nIn order to transform the first term, we observe that, \\(u\\) and \\(v\\) being two \\(m\\times n\\) images\n\\[\n\\begin{gathered}\n\\sum_{i=0}^{m-1}(u_{i, n-1}-u_{i, 0})(v_{i, n-1}-v_{i, 0})\\\\\n=\\sum_{i=0}^{m-1}u_{i, 0}(v_{i, 0}-v_{i, n-1})\n+\\sum_{i=0}^{m-1}u_{i, n-1}(v_{i, n-1}-v_{i, 0})\\\\\n=\\tfrac12\\langle u, Q_1^\\mathrm h\\cdot v\\rangle,\n\\end{gathered}\n\\tag{2}\\]\nwhere we have introduced the linear operator \\(Q_1^\\mathrm h\\) defined as follows\n\\[\n\\tfrac12(Q_1^\\mathrm h\\cdot u)_{ij}=\n\\begin{cases}\nu_{i, 0}-u_{i, n-1} & \\text{if }j=0,\\\\\nu_{i, n-1}-u_{i, 0} & \\text{if }j=n-1,\\\\\n0                   & \\text{otherwise}.\n\\end{cases}\n\\tag{3}\\]\nFrom the left-hand side of Eq. (2), the linear operator \\(Q_1^\\mathrm h\\) thus defined is obviously symmetric and positive. Besides, the first term in Eq. (1) reads\n\\[\n2\\sum_{i=0}^{m-1}(p_{i, n-1}-p_{i, 0})^2=\\langle p, Q_1^\\mathrm h\\cdot p\\rangle.\n\\]\nTurning now to the second term in Eq. (1), we introduce the symmetric, positive linear operator \\(Q_1^\\mathrm v\\) defined by\n\\[\n\\tfrac12(Q_1^\\mathrm v\\cdot u)_{ij}=\n\\begin{cases}\nu_{0, j}-u_{m-1, j} & \\text{if }i=0,\\\\\nu_{m-1, j}-u_{0, j} & \\text{if }i=m-1,\\\\\n0                   & \\text{otherwise},\n\\end{cases}\n\\tag{4}\\]\nso that\n\\[\n2\\sum_{j=0}^{n-1}(p_{m-1, j}-p_{0, j})^2=\\langle p, Q_1^\\mathrm v\\cdot p\\rangle.\n\\]\nGathering the above results and introducing the symmetric operator \\(Q_1=Q_1^\\mathrm h+Q_1^\\mathrm v\\), we finally find that \\(E_\\mathrm p(p)=\\langle\np, Q_1\\cdot p\\rangle\\).\n\n\nDerivation of the Q operator\nThe contribution to the total energy of the smooth component \\(s\\) is defined by Moisan (2011) as follows (see also previous post)\n\\[\nE_\\mathrm s(s)=2\\sum_{i=0}^{m-2}\\sum_{j=0}^{n-1}(s_{i+1, j}-s_{i, j})^2\n+2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-2}(s_{i, j+1}-s_{i, j})^2.\n\\tag{5}\\]\nIn the present section, all \\(m\\times n\\) images \\(v\\) will be extended by periodicity as follows\n\\[\nv_{i, -1}=v_{i, n-1}, \\quad\nv_{i, n}=v_{0, n}, \\quad\nv_{-1, j}=v_{m-1, j}\\quad\\text{and}\\quad\nv_{m, j}=v_{0, j}.\n\\tag{6}\\]\nCombining Eqs. (1) and (5), it is found that\n\\[\nE_\\mathrm p(v)+E_\\mathrm s(v)\n=2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}(v_{i+1, j}-v_{i, j})^2\n+2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}(v_{i, j+1}-v_{i, j})^2,\n\\tag{7}\\]\nIn order to transform the first term in Eq. (7), we observe that, \\(u\\) and \\(v\\) being two \\(m\\times n\\) images that are both extended according to Eq. (6)\n\\[\n\\begin{gathered}\n\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}(u_{i+1, j}-u_{i, j})(v_{i+1, j}-v_{i, j})\\\\\n=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i+1, j}(v_{i+1, j}-v_{i, j})\n-\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i, j}(v_{i+1, j}-v_{i, j})\\\\\n=\\sum_{i=1}^m\\sum_{j=0}^{n-1}u_{i, j}(v_{i, j}-v_{i-1, j})\n-\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i, j}(v_{i+1, j}-v_{i, j})\\\\\n=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i, j}(v_{i, j}-v_{i-1, j})-\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i, j}(v_{i+1, j}-v_{i, j})\\\\\n=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i, j}(2v_{i, j}-v_{i-1, j}-v_{i+1,j})\\\\\n=\\tfrac12\\langle u, Q^\\mathrm h\\cdot v\\rangle,\n\\end{gathered}\n\\tag{8}\\]\nwhere we have introduced the linear operator \\(Q^\\mathrm h\\) defined as follows, see Eq. (6)\n\\[\n\\tfrac12(Q^\\mathrm h\\cdot u)_{i,j}=2u_{i, j}-u_{i-1, j}-u_{i+1,j}.\n\\tag{9}\\]\nFrom the left-hand side of Eq. (7), the linear operator \\(Q^\\mathrm h\\) thus defined is obviously symmetric and positive. Besides, the first term in Eq. (7) reads\n\\[2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}(v_{i+1, j}-v_{i, j})^2\n=\\langle v, Q^\\mathrm h\\cdot v\\rangle.\\]\nTurning now to the second term in Eq. (5), we introduce the symmetric, positive linear operator \\(Q^\\mathrm v\\) defined by\n\\[\n\\tfrac12(Q^\\mathrm v\\cdot u)_{i,j}=2u_{i, j}-u_{i, j-1}-u_{i,j+1},\n\\tag{10}\\]\nso that\n\\[\n2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}(v_{i, j+1}-v_{i, j})^2=\\langle v, Q^\\mathrm v\\cdot v\\rangle.\n\\]\nFinally\n\\[\n\\begin{gathered}\n(\\operatorname{mean}u)(\\operatorname{mean}v)=\\frac{\\operatorname{mean}v}{mn}\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i,j}\\\\\n=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{i,j}\\times\\frac{\\operatorname{mean}v}{mn}=\\langle u, Q^\\mathrm m\\cdot v\\rangle,\n\\end{gathered}\n\\tag{11}\\]\nwhere we have introduced the symmetric, positive operator \\(Q^\\mathrm m\\) defined as follows\n\\[\n(Q^\\mathrm m\\cdot v)_{i,j}=\\frac{\\operatorname{mean} v}{mn}=\\frac1{m^2n^2}\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}v_{i,j}.\n\\tag{12}\\]\nGathering the above results and introducing the symmetric, positive operator \\(Q=Q^\\mathrm h+Q^\\mathrm v+Q^\\mathrm m\\), we finally find that \\(E_\\mathrm\np(v)+E_\\mathrm s(v)+(\\operatorname{mean} v)^2 =\\langle s, Q\\cdot s\\rangle\\).\n\n\nConclusion\nIn this post, we have defined two linear operators, namely \\(Q_1\\) and \\(Q\\), that operate on the space of \\(m\\times n\\) images, and such that\n\\[F(v, u)=\\langle v, Q\\cdot v\\rangle-2\\langle v, Q_1\\cdot u\\rangle+\\langle u, Q_1\\cdot u\\rangle,\\]\nwhere the minimizer of \\(F\\) with respect to its first argument \\(v\\) is the smooth component \\(s\\) of \\(u\\) (the periodic component \\(p\\) is then obtained from \\(p=u-s\\)). In the next instalment of this series, we will proceed to implement \\(Q_1\\) and \\(Q\\) in Python. To do so, we will adopt a matrix-free approach."
  },
  {
    "objectID": "posts/20210513-Numerical_analysis_of_a_spring_mesh/index.html",
    "href": "posts/20210513-Numerical_analysis_of_a_spring_mesh/index.html",
    "title": "Numerical analysis of a spring mesh",
    "section": "",
    "text": "In this post, we compute numeric values of the apparent stiffness introduced in this post. Our goal is to find the solution to the general problem depicted below.\n\n\n\nThe problem considered here\n\n\nWe use a numeric approach that is akin to the finite element method. More precisely, we minimize the total potential energy of the spring with respect to the nodal displacements.\nThis time, we will use the Julia programming language.\n\nusing DelimitedFiles\nusing LinearAlgebra\nusing Plots\nusing Test\n\nWe first define a function that returns the stiffness matrix ox a single spring, according to this post.\n\n\"\"\"spring_stiffness_matrix(k, nx, ny)\n\nReturn the stiffness matrix of the spring with stiffness `k` and direction `(nx, ny)`.\n\nThe direction must be a unit vector (`nx² + ny² == 1`).\n\nThe degrees of freedom of the spring are ordered as follows:\n\n1. horizontal displacement of node 1,\n2. vertical displacement of node 1,\n3. horizontal displacement of node 2,\n4. vertical displacement of node 2.\n\"\"\"\nfunction spring_stiffness_matrix(k, nx, ny)\n    kxx = k * nx * nx\n    kyy = k * ny * ny\n    kxy = k * nx * ny\n    return [\n        kxx kxy -kxx -kxy;\n        kxy kyy -kxy -kyy;\n        -kxx -kxy kxx kxy;\n        -kxy -kyy kxy kyy]\nend\n\nWe then define a structure that holds the description of the mesh. See this post for a description of the various symbols. Note that for the sake of simplicity, it is assumed that the number of cells is identical in both directions.\n\nstruct SpringMesh\n    χx::Float64\n    χy::Float64\n    θ::Float64\n    ncells::Int\n    ndofs::Int\n    SpringMesh(χx, χy, θ, ncells) = new(χx, χy, θ, ncells, 2 * (ncells+1)^2)\nend\n\nWe define a function that computes the linear index of the node located at (i⋅Δx, j⋅Δy). It would probably have been better to use CartesianIndices for this purpose.\n\n\"\"\"node_at(i, j, mesh)\n\nReturn the linear indnex of the node located at `(i, j)` in the mesh.\n\nNote that `i` and `j` are zero-based, while the returned index in one-based.\n\"\"\"\nfunction node_at(i, j, mesh)\n    (mesh.ncells+1)*j+i+1\nend\n\nTo assemble the global stiffness matrix, we add block-wise the element stiffness matrix of each spring.\n\n\"\"\"\nadd_spring_stiffness_matrix!(K, i1, j1, i2, j2, mesh, Ke)\n\nAdd to the global stiffness matrix `K` the element stiffness matrix `Ke`.\n\nThe spring connects nodes `(i1, j1)` and `(i2, j2)` (0-based indices).\n\"\"\"\nfunction add_spring_stiffness_matrix!(K, i1, j1, i2, j2, mesh, Ke)\n    n1 = node_at(i1, j1, mesh)\n    n2 = node_at(i2, j2, mesh)\n    index = [2n1-1, 2n1, 2n2-1, 2n2]\n    for i = 1:4\n        for j = 1:4\n            K[index[i], index[j]] += Ke[i, j]\n        end\n    end\nend\n\n\n\"\"\"Return the stiffness matrix\"\"\"\nfunction global_stiffness_matrix(mesh)\n    K = zeros(mesh.ndofs, mesh.ndofs)\n    c = cos(mesh.θ)\n    s = sin(mesh.θ)\n    K_h = spring_stiffness_matrix(mesh.χx, 1., 0.)\n    K_v = spring_stiffness_matrix(mesh.χy, 0., 1.)\n    K_d1 = spring_stiffness_matrix(1., c, s)\n    K_d2 = spring_stiffness_matrix(1., -c, s)\n    for i = 0:mesh.ncells\n        for j = 0:mesh.ncells\n            if i &lt; mesh.ncells\n                add_spring_stiffness_matrix!(K, i, j, i + 1, j, mesh, K_h)\n            end\n            if j &lt; mesh.ncells\n                add_spring_stiffness_matrix!(K, i, j, i, j + 1, mesh, K_v)\n            end\n            if (i &lt; mesh.ncells) && (j &lt; mesh.ncells)\n                add_spring_stiffness_matrix!(K, i, j, i + 1, j + 1, mesh, K_d1)\n                add_spring_stiffness_matrix!(K, i + 1, j, i, j + 1, mesh, K_d2)\n            end\n        end\n    end\n    return K\nend\n\nThe forces are applied only on the left and right boundaries. Assembly of the vector of nodal forces is done below.\n\n\"\"\"nodal_forces(mesh)\n\nReturn the vector of nodal forces.\n\nThe total force applied on each side is 1.\n\"\"\"\nfunction nodal_forces(mesh)\n    F = zeros(mesh.ndofs)\n    f = 1. / mesh.ncells\n    for j=1:mesh.ncells-1\n        F[2 * node_at(0, j, mesh)-1] = -f\n        F[2 * node_at(mesh.ncells, j, mesh)-1] = f\n    end\n    F[2 * node_at(0, 0, mesh)-1] = -0.5 * f\n    F[2 * node_at(0, mesh.ncells, mesh)-1] = -0.5 * f\n    F[2 * node_at(mesh.ncells, 0, mesh)-1] = 0.5 * f\n    F[2 * node_at(mesh.ncells, mesh.ncells, mesh)-1] = 0.5 * f\n    return F        \nend\n\nWe need to account for the boundary conditions that will prevent rigid body motion. We first define a general function that modifies the linear system to account for a fixed dof.\n\n\"\"\"apply_bc!(K, F, fixed_dof, mesh)\n\nModify the stiffness matrix and vector of nodal forces to account for a fixed dof.\n\"\"\"\nfunction apply_bc!(K, F, fixed_dof, mesh)\n    for dof = 1:mesh.ndofs\n        K[fixed_dof, dof] = 0.\n        K[dof, fixed_dof] = 0.\n    end\n    K[fixed_dof, fixed_dof] = 1.\n    F[fixed_dof] = 0.\nend\n\nThe above function is then used to pin the lower-left corner and prevent vertical displacements of the lower-right corner as well as horizontal displacements of the upper-left corner.\n\nfunction apply_bcs!(K, F, mesh)\n    n0 = node_at(0, 0, mesh)\n    apply_bc!(K, F, 2n0-1, mesh)\n    apply_bc!(K, F, 2n0, mesh)\n    \n    n1 = node_at(mesh.ncells, 0, mesh)\n    apply_bc!(K, F, 2n1, mesh)\n    \n    n2 = node_at(0, mesh.ncells, mesh)\n    apply_bc!(K, F, 2n2-1, mesh)\nend\n\nFinally, the apparent stiffness is computed according to this post.\n\nfunction apparent_stiffness(mesh)\n    K = global_stiffness_matrix(mesh)\n    F = nodal_forces(mesh)\n    apply_bcs!(K, F, mesh)\n    u = K\\F\n    elongation = 0.\n    for j = 0:mesh.ncells\n        left = 2 * node_at(0, j, mesh)-1\n        right = 2 * node_at(mesh.ncells, j, mesh)-1\n        weight = (j == 0) || (j == mesh.ncells) ? 0.5 : 1.0\n        elongation += weight * (u[right] - u[left])\n    end\n    elongation /= mesh.ncells\n    return 1. / elongation\nend\n\nWe use the symbolic expressions derived in this post to test our implementation.\n\nactual_stiffness(χ, n) = apparent_stiffness(SpringMesh(χ, χ, π/4, n))\n\neffective_stiffness(χ) = χ*(χ+2)/(χ+1)\nexpected_stiffness_1x1(χ) = 4χ*(χ+1)/(2χ+1)\nexpected_stiffness_2x2(χ) = 8χ*(1+χ)*(2+χ)/(2χ+3)/(3χ+2)\nexpected_stiffness_3x3(χ) = 144χ*(χ+1)*(4*χ^4+24χ^3+41χ^2+24χ+4)/(480χ^5+2888χ^4+5616χ^3+4771χ^2+1800χ+236)\n\n@testset \"Apparent stiffness\" begin\n    χ = 2.0 .^ LinRange(-7, 7, 13)\n\n    @test actual_stiffness.(χ, 1) ≈ expected_stiffness_1x1.(χ)\n    @test actual_stiffness.(χ, 2) ≈ expected_stiffness_2x2.(χ)\n    @test actual_stiffness.(χ, 3) ≈ expected_stiffness_3x3.(χ)\nend;\n\nTest Summary:      | Pass  Total  Time\nApparent stiffness |    3      3  1.4s\n\n\nWe then are ready to produce the figures that were used in this post.\n\nχ = 2.\nχx = χ\nχy = χ\nθ = π / 4.\nnpoints = 7\nncells = 1 .&lt;&lt; (0:(npoints-1))\nA_app = zeros(npoints)\nfor i = 1:npoints\n    print(\"$(ncells[i]), \")\n    mesh = SpringMesh(χx, χy, θ, ncells[i])\n    A_app[i] = apparent_stiffness(mesh)\n    println(A_app[i])\nend\n\n\nAx = cot(θ)*(1+cos(2θ)+χx)\nAy = tan(θ)*(1-cos(2θ)+χy)\nAxy = sin(2θ)\n\nA_eff = Ax - Axy^2 / Ay\n\n\nerr = (A_app[:] .- A_eff) / A_eff\nplot(ncells, 100*err, \n     axis=:log,\n     marker=:circle, \n     label=\"\", \n     xlabel=\"Number of cells\", \n     ylabel=\"Relative error [%]\", \n     title=\"Relative error on effective stiffness\")\n\n\ndir = joinpath(\"..\", \"What_is_homogenization-files\")\nbasename = \"apparent_stiffness_vs_number_of_cells\"\nsavefig(joinpath(dir, basename * \".png\"))\n# savefig(basename * \".pdf\")\n\n\nopen(joinpath(dir, basename * \".csv\"), \"w\") do io\n    write(io, \"# Apparent, uniaxial stiffness vs. number of cells\\n\")\n    write(io, \"# chi_x = $χx\\n\")\n    write(io, \"# chi_y = $χy\\n\")\n    write(io, \"# theta = $θ rad\\n\")\n    writedlm(io, [ncells A_app], \",\")\nend\n\n\nχ = 10.0 .^ LinRange(-2, 2, 41)\neff = effective_stiffness.(χ)\nplot(χ, (expected_stiffness_1x1.(χ).-eff)./eff, label=\"1×1\", \n     xaxis=:log, xlabel=\"Stiffness ratio, χ\", ylabel=\"Relative error\")\nplot!(χ, (expected_stiffness_2x2.(χ).-eff)./eff, label=\"2×2\")\nplot!(χ, (expected_stiffness_3x3.(χ).-eff)./eff, label=\"3×3\")\n\n\nbasename = \"apparent_stiffness_vs_chi\"\nsavefig(joinpath(dir, basename * \".png\"))"
  },
  {
    "objectID": "posts/20150223-Orientation_correlations_among_rice_grains-01/index.html",
    "href": "posts/20150223-Orientation_correlations_among_rice_grains-01/index.html",
    "title": "Orientation correlations among rice grains, part 1: introduction",
    "section": "",
    "text": "In this series, I will explore the notion of orientational order in random packings of anisotropic (flat or elongated), hard particles. By orientational order, I mean that particles which are close to each other tend to adopt the same orientation. This leads to strong local anisotropy, while the packing may well be globally isotropic; in particular, all orientations of single grains are equiprobable. Local orientational order is stronger when the volume fraction of particles, or their aspect ratio increases.\nLocal orientational order will be illustrated on a “real” packing, and I chose rice grains for this demo. Analysis of orientation correlations requires to go through the following steps\n\nacquisition of a 3D image of the packing through X-ray microtomography,\nsegmentation of the 3D image (each grain must be labelled individually) by means of the Population C++ library,\ncomputation of the orientation of each rice grain, using the scipy.ndimage Python module,\ncomputation of the orientation correlations.\n\nBefore we proceed, I would like to clarify the notion of local orientational order through images of synthetic packings of 10000 hard (flat) spheroids. The aspect ratio (ratio of polar to equatorial radii) of the (flat) spheroids is 0.125. The images below (click to enlarge) are three realizations of random packing of spheroids, at 40% (left), 50% (middle) and 60% (right) volume fraction. The color of each particle is chosen according to its orientation, so that particles with similar colors have similar orientations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt should be mentioned that generating such compact assemblies is no trivial task. The event-driven molecular dynamics algorithm proposed by Donev, Torquato and Stillinger (2005, 2005a) is an attractive option: it is both very general and versatile. It is however a bit complex, and I adopted a different approach, which we published a while ago with Pierre Levitz (Brisard and Levitz, 2013). In a nutshell, the microstructures presented above are the result of a kind of Reverse Monte-Carlo simulation with a non-physical pairwise potential. The interaction potential is zero when the spheroids do not intersect, and repulsive when they do.\nIt is observed that, as the volume fraction of particles increases, so does the size of the color patches. In other words, to pack the particles closely, you need to stack them! Mathematically speaking, the orientations of particles exhibit long-range correlations. In the next instalments of this series, I will show how these correlations can be quantified, both on synthetic and \"real-life\" samples.\nSee part 2 of this series."
  },
  {
    "objectID": "posts/20180312-On_the_periodic-plus-smooth_decomposition_of_an_image-05/index.html",
    "href": "posts/20180312-On_the_periodic-plus-smooth_decomposition_of_an_image-05/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 5: minimizing the energy, the clumsy way",
    "section": "",
    "text": "In this post, we will compute Moisan’s (2011) periodic-plus-smooth decomposition of an image by direct minimization of the energy introduced in the second instalment of this series. More precisely, \\(u\\) being a \\(m\\times n\\) image, we will minimize the function \\(F(v, u)\\) over the space of \\(m\\times n\\) images \\(v\\). The minimizer, \\(s\\), is the smooth component of \\(u\\), while its complement \\(p=u-s\\) is the periodic component of \\(u\\). This post is the fifth instalment of a series in seven parts:\n\nIntroduction\nDefining the decomposition\nThe energy as a quadratic form\nImplementing the linear operators\nMinimizing the energy, the clumsy way\nMinimizing the energy, the clever way\nImproved implementation of Moisan’s algorithm\n\nThe code discussed in this series is available as a Python module on GitHub.\nWe showed in part 3 that \\(F\\) was in fact a quadratic form, and expressed the underlying linear operators, which were subsequently implemented in part 4. It is recalled (see part 3) that\n\\[F(v, u)=\\langle v, Q\\cdot v\\rangle-2\\langle v, Q_1\\cdot u\\rangle+\\langle u, Q_1\\cdot u\\rangle,\\]\nwhere \\(Q\\) and \\(Q_1\\) are symmetric, positive linear operators. Minimizing \\(F\\) with respect to \\(v\\) therefore amounts to solving the linear system: \\(Q\\cdot\ns=Q_1\\cdot u\\). It can in fact be shown that \\(Q\\) is positive definite, therefore the solution to this linear system is unique: \\(s=Q^{-1}\\cdot Q_1\\cdot u\\). It can be computed by means of the conjugate gradient method, as illustrated below.\nLet us start by loading up some modules and the input image to be periodized (see Fig. 1).\nimport numpy as np\n\nfrom scipy.sparse.linalg import cg\nfrom skimage.io import imread, imsave\n\nu = imread(DATA_DIR+'hut-648x364.png')\nu = u.astype(np.float64)\n\n\n\n\n\n\nFigure 1: The initial image to be periodized.\n\n\n\nWe then create the operators \\(Q_1\\) and \\(Q\\) that were implemented in the previous instalment of this series.\nQ1 = OperatorQ1(u.shape)\nQ = OperatorQ(u.shape)\nWe then compute the right-hand side of the system, namely \\(Q_1\\cdot\nu\\). Attention must be paid to the fact that \\(u\\) must be flattened to a 1D array.\nm, n = u.shape\nQ1u = Q1@u.reshape((m*n,))\nWe then use the scipy.sparse.linalg.cg function (see documentation) to solve the linear system\nx, info = cg(Q, Q1u)\nif info == 0:\n    print('success!')\nelse:\n    print(info)\ns = x.reshape(u.shape)\np = u-s\nWe can now save the results (for future reference).\ndef to_uint8(v):\n    m, n = v.shape\n    v_min = v.min()\n    v_max = v.max()\n    return (255.0*(v-v_min)/(v_max-v_min)).astype(np.uint8)\n\nimsave(DATA_DIR+'hut-648x364-smooth-cg.png', to_uint8(s))\nimsave(DATA_DIR+'hut-648x364-periodic-cg.png', to_uint8(p))\nimsave(DATA_DIR+'hut-648x364-periodic-cg-fftshift.png',\n       to_uint8(np.fft.fftshift(p)))\nAgain, periodization is best observed by swapping the quadrants (see Fig. 2).\n\n\n\n\n\n\nFigure 2: The periodic component of the initial image shown in Fig. 1, resulting from conjugate gradient minimization of Moisan’s energy.\n\n\n\nEt voilà…\nIn this fairly quick post, we derived a reference periodic-plus-smooth decomposition of a specific image. The conjugate gradient iterations are highly inefficient, and we will show in the next instalment of this series that a very efficient alternative, based on the fast Fourier transform, was proposed by Moisan (2011). The decomposition that we obtained in the present post will then be used as a reference for testing our implementation of Moisan’s algorithm."
  },
  {
    "objectID": "posts/20140131-The_elastic_acoustic_tensor_and_its_inverse/index.html",
    "href": "posts/20140131-The_elastic_acoustic_tensor_and_its_inverse/index.html",
    "title": "The elastic acoustic tensor and its inverse",
    "section": "",
    "text": "In this post, I will introduce the acoustic tensor of linearly elastic materials. Closed-form expressions of the inverse of this tensor can be derived in the case of isotropic materials. This will later come in handy to derive closed-form expressions of the periodic Green operator for strains.\nWe consider a linearly elastic material with stiffness \\(\\mathbf C\\). For any wave-vector \\(\\vec k\\), the elastic acoustic tensor \\(\\mathbf A(\\vec k)\\) is defined as follows \\[\n\\mathbf A(\\vec k)\n=\\vec k\\cdot\\mathbf C\\cdot\\vec k\n=k^2\\,\\vec n\\cdot\\mathbf C\\cdot\\vec n,\n\\tag{1}\\] where \\(k\\) is the amplitude of the wave-vector \\(\\vec k\\), \\(k=\\sqrt{\\vec k\\cdot\\vec\nk}\\), and \\(\\vec n\\) is its direction (\\(\\vec k=k\\,\\vec n\\)). The acoustic tensor is used to assess material stability (Bigoni and Zaccaria, European Journal of Mechanics- A/Solids 13(5), pp. 621–638, 1994) and study the propagation of waves (Gentile and Straughan, 2013). As far as we are concerned, the derivation of the periodic Green operator for strains will require the expressions of the inverse of the acoustic tensor. This is the topic of the present post, which is restricted to isotropic materials: the stiffness tensor \\(\\mathbf C\\) of isotropic materials is therefore a linear combination of the isotropic projection tensors \\(\\mathbf J\\), and \\(\\mathbf K\\) \\[\n\\mathbf C=d\\,\\kappa\\,\\mathbf J+2\\mu\\,\\mathbf K.\n\\tag{2}\\]\nTo compute the elastic acoustic tensor, we therefore need to find the expressions of \\(\\vec n\\cdot\\mathbf J\\cdot\\vec n\\) and \\(\\vec n\\cdot\\mathbf K\\cdot\\vec\nn\\), for any unit vector \\(\\vec n\\). We start with the computation of \\(\\vec\nn\\cdot\\mathbf I\\cdot\\vec n\\), where \\(\\mathbf I\\) denotes the fourth-rank identity tensor. We have \\[\n\\bigl(\\vec n\\cdot\\mathbf I\\cdot\\vec n\\bigr)_{jk}\n=n_i\\,I_{ijkl}\\,n_l\n=n_i\\,n_l\\,\\frac12\\bigl(\\delta_{il}\\,\\delta_{jk}+\\delta_{jl}\\,\\delta_{ik}\\bigr)\n=\\frac12\\bigl(n_i\\,n_i\\delta_{jk}+n_j\\,n_k\\bigr).\n\\]\nSince \\(\\vec n\\) is a unit vector, we have \\(n_i\\,n_i=1\\), and \\[\n\\vec n\\cdot\\mathbf I\\cdot\\vec n=\\frac12\\bigl(\\boldsymbol\\delta+\\vec n\\otimes\\vec n\\bigr),\n\\] where \\(\\boldsymbol\\delta\\) denotes the second-rank identity tensor. It will be convenient to introduce the projectors \\(\\mathbf p\\) and \\(\\mathbf q\\), defined as follows \\[\n\\mathbf p=\\vec n\\otimes\\vec n\n\\quad\\text{and}\\quad\n\\mathbf q=\\boldsymbol\\delta-\\mathbf p,\n\\] or, using indices \\[\np_{ij}=n_i\\,n_j\n\\quad\\text{and}\\quad\nq_{ij}=\\delta_{ij}-n_i\\,n_j.\n\\]\nIt can readily be verified that \\[\n\\mathbf p\\cdot\\mathbf p=\\mathbf p,\\quad\n\\mathbf q\\cdot\\mathbf q=\\mathbf q\n\\quad\\text{and}\\quad\n\\mathbf p\\cdot\\mathbf q=\\mathbf q\\cdot\\mathbf p=\\mathbf0,\n\\tag{3}\\] and \\[\n\\vec n\\cdot\\mathbf I\\cdot\\vec n=\\mathbf p+\\frac12\\mathbf q.\n\\tag{4}\\]\nSimilarly \\[\n\\vec n\\cdot\\mathbf J\\cdot\\vec n\n=\\frac1d\\,\\vec n\\cdot\\bigl(\\mathbf\\delta\\otimes\\mathbf\\delta\\bigr)\\cdot\\vec n\n=\\frac1d\\,\\vec n\\otimes\\vec n\n=\\frac1d\\,\\mathbf p.\n\\tag{5}\\]\nFinally, combining identity \\(\\mathbf K=\\mathbf I-\\mathbf J\\) with Eqs. (4) and (5) \\[\n\\vec n\\cdot\\mathbf K\\cdot\\vec n=\\frac{d-1}d\\mathbf p+\\frac12\\mathbf q.\n\\tag{6}\\]\nThe acoustic tensor of an elastic, linear, isotropic material is obtained from Eqs. (1), (2), (5) and (6) \\[\n\\mathbf A(\\vec n)=\\Bigl(\\kappa+2\\mu\\frac{d-1}d\\Bigr)\\mathbf p+\\mu\\,\\mathbf q.\n\\]\nFrom this post, it can readily be verified that \\[\n\\kappa+2\\mu\\frac{d-1}d=2\\mu\\frac{1-\\nu}{1-2\\nu},\n\\] this identity being true in both 3D and plane strain elasticity. The acoustic tensor therefore reads \\[\n\\mathbf A(\\vec k)=k^2\\mu\\Bigl[\\frac{2\\bigl(1-\\nu\\bigr)}{1-2\\nu}\\mathbf p+\\mathbf q\\Bigr].\n\\]\nFinally, using the properties of the projectors \\(\\mathbf p\\) and \\(\\mathbf q\\) [see Eq. (3)], the inverse of the acoustic tensor can be derived \\[\n\\mathbf A^{-1}(\\vec k)=\\frac1{k^2\\mu}\\Bigl[\\frac{1-2\\nu}{2\\bigl(1-\\nu\\bigr)}\\mathbf p+\\mathbf q\\Bigr].\n\\]"
  },
  {
    "objectID": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html",
    "href": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 7: improved implementation of Moisan’s algorithm",
    "section": "",
    "text": "In the previous instalment of this series, we implemented Moisan’s (2011) efficient algorithm to compute the periodic-plus-smooth decomposition of an image. This algorithm relies heavily on the discrete Fourier transform, and already improves quite a lot over our previous conjugate gradient-based implementation. In the present post, we will show that performance of the implementation can be slightly improved with very little effort. This post is the seventh in a series in seven parts:\nThe code discussed in this series is available as a Python module on GitHub."
  },
  {
    "objectID": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html#moisanss-algorithm-for-real-images",
    "href": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html#moisanss-algorithm-for-real-images",
    "title": "On the periodic-plus-smooth decomposition of an image, part 7: improved implementation of Moisan’s algorithm",
    "section": "Moisans’s algorithm for real images",
    "text": "Moisans’s algorithm for real images\nIn our previous implementation, we have overlooked an important fact: \\(u\\) is (often) a real image. Its DFT ought to be computed through the numpy.fft.rfft2 function (documentation) rather than numpy.fft.fft2 (documentation). This is what is done below.\ndef rper(u, inverse_dft=True):\n    \"\"\"Compute the periodic component of the 2D, real image u.\n\n    This function returns the periodic-plus-smooth decomposition of\n    the 2D array-like u. The image must be real.\n\n    If inverse_dft is True, then the pair (p, s) is returned\n    (p: periodic component; s: smooth component).\n\n    If inverse_dft is False, then the pair\n\n        (numpy.fft.rfft2(p), numpy.fft.rfft2(s))\n\n    is returned.\n\n    This function implements Algorithm 1.\n    \"\"\"\n    u = np.asarray(u, dtype=np.float64)\n    m, n = u.shape\n\n    arg = 2.*np.pi*np.fft.fftfreq(m, 1.)\n    cos_m, sin_m = np.cos(arg), np.sin(arg)\n    one_minus_exp_m = 1.0-cos_m-1j*sin_m\n\n    arg = 2.*np.pi*np.fft.rfftfreq(n, 1.)\n    cos_n, sin_n = np.cos(arg), np.sin(arg)\n    one_minus_exp_n = 1.0-cos_n-1j*sin_n\n\n    w1 = u[:, -1]-u[:, 0]\n    w1_dft = np.fft.fft(w1)\n    # Use complex fft because irfft2 needs all modes in the first direction\n    v1_dft = w1_dft[:, None]*one_minus_exp_n[None, :]\n\n    w2 = u[-1, :]-u[0, :]\n    w2_dft = np.fft.rfft(w2)\n    v2_dft = one_minus_exp_m[:, None]*w2_dft[None, :]\n\n    k_dft = 2.0*(cos_m[:, None]+cos_n[None, :]-2.0)\n    k_dft[0, 0] = 1.0\n    s_dft = (v1_dft+v2_dft)/k_dft\n    s_dft[0, 0] = 0.0\n\n    if inverse_dft:\n        s = np.fft.irfft2(s_dft, u.shape)\n        return u-s, s\n    else:\n        u_dft = np.fft.rfft2(u)\n        return u_dft-s_dft, s_dft\nAnd we can again test this new implementation\np_act, s_act = rper(u, inverse_dft=True)\n\nprint('Error in L2-norm:')\nprint('  - on p: {}'.format(np.linalg.norm(p_act-p_exp)))\nprint('  - on s: {}'.format(np.linalg.norm(s_act-s_exp)))\nprint()\nprint('Maximum absolute error')\nprint('  - on p: {}'.format(np.max(np.abs(p_act-p_exp))))\nprint('  - on s: {}'.format(np.max(np.abs(s_act-s_exp))))\nprint()\nprint('Maximum relative error')\nprint('  - on p: {}'.format(np.max(np.abs(2*(p_act-p_exp)/(p_act+p_exp)))))\nprint('  - on s: {}'.format(np.max(np.abs(2*(s_act-s_exp)/(s_act+s_exp)))))\nError in L2-norm:\n  - on p: 5.810100441650991e-10\n  - on s: 5.809921679853175e-10\n\nMaximum absolute error\n  - on p: 4.1807243312143156e-12\n  - on s: 4.181406578613701e-12\n\nMaximum relative error\n  - on p: 8.68682621178305e-11\n  - on s: 7.30527816192651e-08\nWhich is again quite satisfactory! Let us time the new implementation.\nt3 = timeit.timeit('p, s = rper(u, inverse_dft=True)',\nnumber=100, globals=globals())\nprint('Timings:')\nprint('  - _per : {}'.format(t1))\nprint('  - per  : {}'.format(t2))\nprint('  - rper : {}'.format(t3))\nprint('Ratios:')\nprint('  - _per/per  : {}'.format(t1/t2))\nprint('  - _per/rper : {}'.format(t1/t3))\nTimings:\n  - _per : 4.946549984680452\n  - per  : 3.9524611252226656\n  - rper : 2.1560062129698423\nRatios:\n  - _per/per  : 1.2515113565859002\n  - _per/rper : 2.2943115631687854\n… and we are now about 2.3× faster!"
  },
  {
    "objectID": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html#conclusion",
    "href": "posts/20180326-On_the_periodic-plus-smooth_decomposition_of_an_image-07/index.html#conclusion",
    "title": "On the periodic-plus-smooth decomposition of an image, part 7: improved implementation of Moisan’s algorithm",
    "section": "Conclusion",
    "text": "Conclusion\nThis is the end of the story. We now have a good implementation of Moisan’s algorithm. We have optimized its implementation, but the code did not lose in clarity.\nIf you are interested by my implementation of Moisan’s algorithm, go to the GitHub repository of the moisan2011 Python module!"
  },
  {
    "objectID": "posts/20180319-On_the_periodic-plus-smooth_decomposition_of_an_image-06/index.html",
    "href": "posts/20180319-On_the_periodic-plus-smooth_decomposition_of_an_image-06/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 6: minimizing the energy, the clever way",
    "section": "",
    "text": "In the previous instalment of this series, we computed Moisan’s (2011) periodic-plus-smooth decomposition of an image by means of the conjugate gradient method. This worked like a charm, but was fairly inefficient, owing to the iterative nature of the method. Moisan actually showed that the whole decomposition could be computed explicitly in Fourier space. This will be discussed in the present post, which is the sixth in a series in seven parts:\n\nIntroduction\nDefining the decomposition\nThe energy as a quadratic form\nImplementing the linear operators\nMinimizing the energy, the clumsy way\nMinimizing the energy, the clever way\nImproved implementation of Moisan’s algorithm\n\nThe code discussed in this series is available as a Python module on GitHub.\nBefore we proceed, let us recall how the discrete Fourier transform \\(\\hat{u}\\) of the \\(m\\times n\\) image \\(u\\) is defined as follows \\[\n\\hat{u}_{\\alpha\\beta}=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}u_{ij}\\exp\\Bigl[-2\\pi\\mathrm i\\Bigl(\\frac{\\alpha i}m+\\frac{\\beta j}n\\Bigr)\\Bigr],\n\\] for \\(\\alpha=0, \\ldots, m-1\\) and \\(\\beta=0, \\ldots, n-1\\). We have the well-known inversion formula \\[\nu_{ij}=\\frac1{mn}\\sum_{\\alpha=0}^{m-1}\\sum_{\\beta=0}^{n-1}\\hat{u}_{\\alpha\\beta}\\exp\\Bigl[2\\pi\\mathrm i\\Bigl(\\frac{\\alpha i}m+\\frac{\\beta j}n\\Bigr)\\Bigr].\n\\]\nThe remainder of this post is organized as follows. We will first introduce Moisan’s algorithm (2011). Then a first implementation of this algorithm will be proposed and tested. Improved implementations will be discussed in the next instalment of this series.\n\nMoisan’s algorithm\nIt is recalled (see previous post) that the smooth component \\(s\\) of a \\(m\\times n\\) image \\(u\\) is found from the solution to the following linear system \\[\nQ\\cdot s=Q_1\\cdot u,\n\\tag{1}\\] where \\(Q\\) and \\(Q_1\\) are symmetric, positive linear operators defined in part 3 of this series (\\(Q\\) is actually positive definite). As observed in part 4 of this series, operator \\(Q\\) is in fact the sum of the periodic convolution operator with the following kernel \\[\n\\begin{bmatrix}\n0 & -2 & 0\\\\\n-2 & 8 & -2\\\\\n0 & -2 & 0\n\\end{bmatrix}\n\\] and the operator that maps any image \\(u\\) onto the constant image equal to \\(\\operatorname{mean}u/mn\\). It then results from the circular convolution theorem that \\[\n(\\widehat{Q\\cdot s})_{\\alpha\\beta}\n=\\begin{cases}\nm^{-2}n^{-2}\\hat{s}_{00} & \\text{if }(\\alpha, \\beta) = (0, 0),\\\\\n\\bigl(8-4\\cos\\frac{2\\pi\\alpha}m-4\\cos\\frac{2\\pi\\beta}n\\bigr)\\hat{s}_{\\alpha\\beta} & \\text{otherwise}.\n\\end{cases}\n\\tag{2}\\]\nCombining Eqs. (1) and (2), we find the following expression of the discrete Fourier transform of the smooth component \\(s\\) \\[\n\\hat{s}_{\\alpha\\beta}=\\frac{\\hat{v}_{\\alpha\\beta}}{2\\cos\\frac{2\\pi\\alpha}m+2\\cos\\frac{2\\pi\\beta}n-4}\\quad\\text{for}\\quad(\\alpha, \\beta)\\neq(0, 0),\n\\tag{3}\\] where we have introduced \\(v=-\\frac12Q_1\\cdot u\\). Since \\(\\operatorname{mean}s=0\\), we also have \\(\\hat{s}_{00}=0\\). From the definition of \\(Q_1\\) (see part 3 of this series), we have \\(v=v^\\mathrm h+v^\\mathrm v\\), with \\[\nv^\\mathrm h_{ij}=\n\\begin{cases}\nu_{i, n-1}-u_{i, 0} & \\text{if }j=0,\\\\\nu_{i, 0}-u_{i, n-1} & \\text{if }j=n-1,\\\\\n0                   & \\text{otherwise},\n\\end{cases}\n\\tag{4}\\] and \\[v^\\mathrm v_{ij}=\n\\begin{cases}\nu_{m-1, j}-u_{0, j} & \\text{if }i=0,\\\\\nu_{0, j}-u_{m-1, j} & \\text{if }i=m-1,\\\\\n0                   & \\text{otherwise}.\n\\end{cases}\n\\tag{5}\\]\nMoisan’s algorithm (2011) readily follows from this analysis\n\ncompute \\(v\\) – use Eqs. (4) and (5),\ncompute its discrete Fourier transform \\(\\hat{v}\\),\ncompute \\(\\hat{s}\\) – use Eq. (3),\ncompute its inverse discrete Fourier transform \\(s\\),\ncompute \\(p=u-s\\).\n\nOf course, the fast Fourier transform will be used for steps 2 and 4.\n\n\nA first implementation of Moisan’s algorithm\nReference implementation of Moisan’s algorithm results directly from the above analysis.\ndef _per(u, inverse_dft=True):\n    \"\"\"Compute the periodic component of the 2D image u.\n\n    This function returns the periodic-plus-smooth decomposition of\n    the 2D array-like u.\n\n    If inverse_dft is True, then the pair (p, s) is returned\n    (p: periodic component; s: smooth component).\n\n    If inverse_dft is False, then the pair\n\n        (numpy.fft.fft2(p), numpy.fft.fft2(s))\n\n    is returned.\n\n    This is a reference (unoptimized) implementation of Algorithm 1.\n    \"\"\"\n    u = np.asarray(u, dtype=np.float64)\n\n    v = np.zeros_like(u)\n    du = u[-1, :]-u[0, :]\n    v[0, :] = du\n    v[-1, :] = -du\n\n    du = u[:, -1]-u[:, 0]\n    v[:, 0] += du\n    v[:, -1] -= du\n\n    v_dft = np.fft.fft2(v)\n\n    m, n = u.shape\n    cos_m = np.cos(2.*np.pi*np.fft.fftfreq(m, 1.))\n    cos_n = np.cos(2.*np.pi*np.fft.fftfreq(n, 1.))\n\n    k_dft = 2.0*(cos_m[:, None]+cos_n[None, :]-2.0)\n    k_dft[0, 0] = 1.0\n    s_dft = v_dft/k_dft\n    s_dft[0, 0] = 0.0\n\n    if inverse_dft:\n        s = np.fft.ifft2(s_dft)\n        return u-s, s\n    else:\n        u_dft = np.fft.fft2(u)\n        return u_dft-s_dft, s_dft\nWhich can be applied to the following image.\nimport numpy as np\n\nfrom skimage.io import imread, imsave\n\nu = imread(DATA_DIR+'hut-648x364.png')\nu = u.astype(np.float64)\n\nThe periodic-plus-smooth decomposition is then computed as follows.\np, s = _per(u, inverse_dft=True)\n\nimsave(DATA_DIR+'hut-648x364-periodic-_per-fftshift.png',\n       np.fft.fftshift(p.real).astype(np.uint8))\nWhich results in the following image (\\(p\\) has been FFT-shifted, in order to demonstrate the effect of periodization).\n\nIt should be noted that the resulting decomposition is a pair of complex images (since we used the complex DFT to perform the decomposition). We ought to check that the imaginary parts of \\(p\\) and \\(s\\) are indeed nearly null\nprint('Imaginary part of')\nprint('  p: min = {}, max = {}'.format(p.imag.min(), p.imag.max()))\nprint('  s: min = {}, max = {}'.format(s.imag.min(), s.imag.max()))\nImaginary part of\n  p: min = -2.6931883320843306e-12, max = 4.161745834921434e-12\n  s: min = -4.161745834921434e-12, max = 2.6931883320843306e-12\nWe can then readily set \\(p\\) and \\(s\\) to their real parts\np_act = p.real\ns_act = s.real\n\n\nTesting our implementation\nIn the previous instalment of this series, we computed a reference periodic-plus-smooth decomposition by means of the conjugate gradient method. Let’s do that again.\nfrom scipy.sparse.linalg import cg\n\ntol = 1E-8\nQ1 = OperatorQ1(u.shape)\nQ = OperatorQ(u.shape)\nm, n = u.shape\nb = Q1@u.reshape((m*n,))\nx_exp, info = cg(Q, b, tol=tol)\nif info == 0:\n    res_exp = np.linalg.norm(b-Q@x_exp)\n    print('Residual: {}'.format(res_exp))\nelse:\n    print(info)\ns_exp = x_exp.reshape(u.shape)\np_exp = u-s_exp\nResidual: 3.9422689362828e-05\nWe can then compute the norm of the difference\nabs_err = np.linalg.norm(s_act-s_exp)\nrel_err = abs_err/np.linalg.norm(0.5*(s_act+s_exp))\nprint('Error in L2-norm:')\nprint('  - absolute: {}'.format(abs_err))\nprint('  - relative: {}'.format(rel_err))\nError in L2-norm:\n  - absolute: 0.004504952971826568\n  - relative: 1.3139651711483983e-06\nThis is already quite satisfactory. We can also compute the residual with the value of \\(s\\) found through the DFT approach\nx_act = s_act.reshape((m*n,))\nres_act = np.linalg.norm(b-Q@x_act)\nprint('Residual: {}'.format(res_act))\nResidual: 1.8964547594731774e-11\nWhich is much smaller than the residual obtained through conjugate gradient iterations! Surely, our implementation delivers the correct periodic-plus-smooth decomposition!\n\n\nConclusion\nIn the present post, we have implemented Moisans’s algorithm (2011) for computing the periodic-plus-smooth decomposition of an image. This algorithm is much faster than our previous implementation, relying on the conjugate gradient method. We will show in the next instalment of this series that we can do slightly better, though."
  },
  {
    "objectID": "posts/20200408-What_is_homogenization-02/index.html",
    "href": "posts/20200408-What_is_homogenization-02/index.html",
    "title": "What is homogenization? Part 2: experimental vs. theoretical homogenization",
    "section": "",
    "text": "In the previous instalment of this series, we introduced homogenization and the separation of scales. In the present post, we will discuss two strategies to carry out homogenization: the experimental and the theoretical approaches. To do so, we will again use the analogy with the halftoning technique.\nRemember that we considered the following picture, reproduced from Le Journal (thursday, may 30th, 1935).\nTaking a closer look at the prow:\nwe realized that what looked like shades of gray in the photograph was actually a dotted structure. This dotted structure will be called the microstructure; its typical length-scale is the microscopic length-scale \\(L_μ\\) that was introduced before.\nNow, let us imagine what happened when this photograph was actually printed alongside the article about the launch of the ocean liner Normandie. The printer was handed out the original photograph (which is indeed made of shades of grays, not black dots) and had to pick the dot pattern(s) that would result in the best halftone reproduction of the photograph. To do so, he needed a rule that relates the dot pattern to the resulting shade of gray.\nThis is what homogenization is really about: homogenization provides a mapping from the microstructure to the effective properties.\nOur friend the printer first performed the required homogenization step experimentally. As the problem at hand is about human perception, he asked his apprentice to be the subject of his experiment. He handed out a set of cards, uniformly coloured with various shades of gray, to the apprentice. Then, he presented him with various dot patterns. For each of these patterns, the printer asked the apprentice to pick the card that was closest to how he perceived the pattern. The printer was then able to build a chart that related pattern to shade of gray (and vice-versa).\nBut then, the printer realized that this experiment is fundamentally subjective. In order to be statistically representative, he needed to repeat this experiment with many subjects, and compute some kind of average. He thought that this was quite tedious, and maybe there was another strategy.\nIn fact, there is another strategy, which is called upscaling. In this approach, the effective properties are inferred (through a mathematical model) from the microstructure. In the case of halftoning, the mathematical model is rather simple, as it boils down to a simple average. More precisely, we first need to realize that the dot pattern is periodic: it is the result of paving the plane with a single unit-cell, a hexagon in the present case (see figure below, where the unit-cell is shown in gray).\nThe total surface area of the unit-cell is \\(A\\), and the surface area covered by the black dot(s) is \\(A_{\\mathrm{b}}\\). The surface area \\(A_{\\mathrm{w}} = A - A_{\\mathrm{b}}\\) remains white. Then, the upscaling rule reads\n\\[\nG^{\\mathrm{eff}} = \\frac{A_{\\mathrm{w}}}{A},\n\\]\nwhere \\(0 ≤ G^{\\mathrm{eff}} ≤ 1\\) denotes the effective gray level (\\(G^{\\mathrm{eff}}=0\\): black; \\(G^{\\mathrm{eff}}=1\\): white). The above upscaling rule can be seen as a form of rule of mixtures. Indeed, let \\(G_{\\mathrm{b}} = 0\\) and \\(G_{\\mathrm{w}}=1\\) denote the gray levels of black and white, respectively. Then, the effective gray level is expressed as the following weighted average of the local gray levels\n\\[\nG = \\frac{A_{\\mathrm{b}}}{A} G_{\\mathrm{b}} + \\frac{A_{\\mathrm{w}}}{A} G_{\\mathrm{w}},\n\\]\nwhere the weights are the surface fractions. This is in fact a rare example where the rule of mixtures gives the correct answer! It is time to wrap up."
  },
  {
    "objectID": "posts/20200408-What_is_homogenization-02/index.html#conclusion",
    "href": "posts/20200408-What_is_homogenization-02/index.html#conclusion",
    "title": "What is homogenization? Part 2: experimental vs. theoretical homogenization",
    "section": "Conclusion",
    "text": "Conclusion\nHomogenization is the process that relates the microstructure to the macroscopic properties. This relationship can be established experimentally or theoretically. These two strategies should not be seen as competing, but rather as complementary approaches to the same problem.\nOn the one hand, provided that the experiments are performed correctly, the experimental approach always delivers the “correct” answer. However, a new experiment is required for each new microstructure.\nOn the other hand, theoretical (upscaling) approaches have the ability to be predictive: given the microstructure, the effective properties can be computed with no need to actually build the microstructure. This is particularly desirable in an industrial context, where numerical modelling is gradually supplanting physical testing. The downside is that all the relevant physics must be accounted for at the scale of the microstructure. While this is relatively easy in the case of e.g. linear elasticity of composites, it is a much more difficult task in the case of e.g. linear elasticity of unsaturated porous media, where we need to account for all menisci.\nIn my research, I preferably resort to theoretical homogenization, to which the remainder of this series will be devoted. In the next instalment, we will discuss periodic vs. random homogenization."
  },
  {
    "objectID": "posts/20180305-On_the_periodic-plus-smooth_decomposition_of_an_image-04/index.html",
    "href": "posts/20180305-On_the_periodic-plus-smooth_decomposition_of_an_image-04/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 4: implementing the linear operators",
    "section": "",
    "text": "In the previous instalment of this series, we introduced the linear operators \\(Q_1\\) and \\(Q\\) that allow to define Moisan’s (2011) periodic-plus-smooth decomposition \\((p, s)\\) of an image \\(u\\) as follows\n\\[s=\\operatorname*{arg\\,min}_v F(v, u)\\quad\\text{and}\\quad p=u-s,\\]\nwith\n\\[F(v, u)=\\langle v, Q\\cdot v\\rangle-2\\langle v, Q_1\\cdot u\\rangle+\\langle u, Q_1\\cdot u\\rangle.\\]\nIn theory, the linear operators \\(Q_1\\) and \\(Q\\) are matrices. However, for \\(m\\times n\\) images, these matrices would be unnecessarily large: \\(mn\\times mn\\)! We will therefore adopt here a matrix-free approach for the Python implementation of these operators. The remainder of this post is organized as follows. We will first discuss linear operators in the scipy.sparse.linalg sense. Then, we will implement the \\(Q_1\\) operator and the \\(Q\\) operator. Finally, we will test our implementation.\nThis post is the fourth instalment of a series in seven parts:\nThe code discussed in this series is available as a Python module on GitHub."
  },
  {
    "objectID": "posts/20180305-On_the_periodic-plus-smooth_decomposition_of_an_image-04/index.html#conclusion",
    "href": "posts/20180305-On_the_periodic-plus-smooth_decomposition_of_an_image-04/index.html#conclusion",
    "title": "On the periodic-plus-smooth decomposition of an image, part 4: implementing the linear operators",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we have implemented the linear operators \\(Q_1\\) and \\(Q\\). We are now in a position to (at last!) compute the periodic-plus-smooth decomposition of an image. This will be done in the next instalment of this series"
  },
  {
    "objectID": "posts/20160627-Orientation_correlations_among_rice_grains-08/index.html",
    "href": "posts/20160627-Orientation_correlations_among_rice_grains-08/index.html",
    "title": "Orientation correlations among rice grains, part 8: estimating the correlations",
    "section": "",
    "text": "In the previous instalment of this series, we have analyzed the morphology of the rice grains. In particular, we have defined their orientation as that of the major axis of inertia. We are now in a position to quantify the statistics of the orientations. We will first discuss one-point statistics (each grain is considered individually), then two-point statistics (mutual orientations of pairs of grains are considered). Finally, we will try to quantify how the wall of the sample container influences the orientation of the rice grains."
  },
  {
    "objectID": "posts/20160627-Orientation_correlations_among_rice_grains-08/index.html#conclusion",
    "href": "posts/20160627-Orientation_correlations_among_rice_grains-08/index.html#conclusion",
    "title": "Orientation correlations among rice grains, part 8: estimating the correlations",
    "section": "Conclusion",
    "text": "Conclusion\nThis was the last post of this series on Orientation correlations among rice grains. This post was dedicated to the quantification of orientation correlations. To do so, we have recalled the definition of several statistical descriptors. These descriptors were then evaluated on the sample.\nThe resulting values indeed indicate the existence of orientation correlations. However, further investigations should be carried out in order to draw reliable conclusions. In particular, the descriptors plotted in Figs. 1 and 2 are histograms, and filtering of some sort should be used to smooth the curves. Besides, the analysis of the first section shows that the sample is globally anisotropic. This global anisotropy should be accounted for (“subtracted”) while analyzing local anisotropy. In short, the present post should be considered as a mere introduction to the matter and the relevant tools.\nWell, I hope you enjoyed this series! We initially set out to quantify orientation correlations in an assembly of rice grains. To do so, a fair amount of image analysis was required. We introduced binning, the Hough transform, Otsu’s method, a dedicated seeding technique for the watershed transform and the quantification of the morphology of the grains. All these techniques have a wide range of applications, which goes far beyond the analysis of rice grains!"
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html",
    "href": "posts/20210509-What_is_homogenization-05/index.html",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "",
    "text": "In the previous instalment of this series on homogenization, we derived the homogenized properties of a rectangular spring mesh. Our goal in this post is to analyse the “convergence” towards the homogenized stiffness; meanwhile, we will discuss the size of the so-called representative volume element (RVE)."
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html#in-the-previous-episode",
    "href": "posts/20210509-What_is_homogenization-05/index.html#in-the-previous-episode",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "In the previous episode…",
    "text": "In the previous episode…\nThe system considered in this post is shown below. The length of the diagonal springs is \\(\\ell\\); they make an angle \\(θ\\) with the \\(x\\)-axis (\\(Δx = \\ell \\cosθ\\), \\(Δy = \\ell \\sinθ\\): grid spacing along the \\(x\\) and \\(y\\) axes). The stiffness of the diagonal springs is \\(k\\); the stiffnesses of the horizontal and vertical springs are \\(χ_x \\, k\\) and \\(χ_y \\, k\\), respectively.\n\n\n\nThe spring mesh considered here\n\n\nWe showed that, in the homogenization limit, this spring mesh behaves as a plate loaded in its plane only. The effective constitutive law of the equivalent plate reads\n\\[N_{xx}=A_x^\\text{eff}ε_{xx}+ν_{xy}^\\text{eff}A_y^\\text{eff}ε_{yy},\\] \\[N_{yy}=A_y^\\text{eff}ε_{yy}+ν_{yx}^\\text{eff}A_x^\\text{eff}ε_{xx},\\] \\[N_{xy}=A_{xy}^\\text{eff}ε_{xy},\\]\nwhere \\(N_{xx}\\), \\(N_{yy}\\) and \\(N_{xy}\\) are the membrane stresses (these are internal forces per unit-length). The effective stiffnesses \\(A_x^\\text{eff}\\), \\(A_y^\\text{eff}\\) and \\(A_{xy}^\\text{eff}\\) are given by the following expressions\n\\[A_x^\\text{eff}=k\\operatorname{cotan}θ\\bigl(1+\\cos2θ+χ_x\\bigr),\\] \\[A_y^\\text{eff}=k\\tanθ\\bigl(1-\\cos2θ+χ_y\\bigr),\\] \\[A_{xy}^\\text{eff}=2ν_{xy}^\\text{eff}A_y^\\text{eff}\n=2ν_{yx}^\\text{eff}A_x^\\text{eff}=2k\\sin2θ.\\]\nIn the present post, we will show through numerical experiments that, for sufficiently large meshes, the set of springs indeed behaves as a continuous flat membrane."
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html#a-uniaxial-tension-experiment",
    "href": "posts/20210509-What_is_homogenization-05/index.html#a-uniaxial-tension-experiment",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "A uniaxial tension experiment",
    "text": "A uniaxial tension experiment\nWe consider a simple uniaxial tension experiment (see below). The system is a \\(\\mathcal N_x×\\mathcal N_y\\) grid. Except for corner nodes, nodes that are located on the vertical boundaries are subjected to horizontal forces \\(Q\\) (on the right-hand side) and \\(-Q\\) (on the left-hand side). For large systems, this is equivalent to a uniformly distributed load \\(q=Q/Δy\\). Corner nodes pick only the load applied to half the \\(y\\)-spacing: therefore, they are subjected to \\(±Q/2\\).\n\n\n\nThe uniaxial tension experiment\n\n\nIn the homogenization limit, the system should behave as a plate under uniaxial tension, for which we should have \\(N_{xx}=q\\), \\(N_{yy}=0\\) and \\(N_{xy}=0\\). Plugging into the constitutive equations, we find that \\(N_{xx}=\\tilde{A}_x^\\text{eff}ε_{xx}\\), where the uniaxial stiffness \\(\\tilde{A}_x^\\text{eff}\\) is defined as follows\n\\[\\tilde{A}_x^\\text{eff}\n=A_x^\\text{eff}\\bigl(1-ν_{xy}^\\text{eff} \\, ν_{yx}^\\text{eff}\\bigr).\\]\nFor “large” (but finite) spring models, we therefore expect the average strain \\(⟨ε_{xx}⟩\\) to be related to \\(q\\) through the following formula: \\(q=\\tilde{A}_x^\\text{eff}⟨ε_{xx}⟩\\).\nIn order to assess the validity of the above approximation, we need to evaluate the average strain \\(⟨ε_{xx}⟩\\) in the spring model. To do so, we draw inspiration from the following formula that relates (for continuous systems) the average strain \\(⟨\\boldsymbol{ε}⟩\\) in \\(Ω\\) to a boundary integral of the displacement \\(\\vec u\\)\n\\[⟨\\boldsymbol{ε}⟩ =\\frac1V∫_{∂Ω}\\tfrac12\\bigl(\\vec{u} ⊗ \\vec{n} + \\vec{n} ⊗ \\vec{u} \\bigr),\\]\nwhere \\(\\vec n\\) denotes the outer normal to \\(∂Ω\\). In the present case, \\(\\vec\ne_x⋅\\vec n=0\\) on the top and bottom boundaries. On the left and right boundaries, the integrals are discretized as follows\n\\[⟨ε_{xx}⟩ \\simeq \\frac{1}{\\mathcal N_x \\, \\mathcal N_y \\, Δx}\n\\sum_{j=0}^{\\mathcal N_y} \\, w_j \\, \\vec e_x\n⋅\\bigl(\\vec u_{\\mathcal N_x,j}-\\vec u_{0, j}\\bigr),\\]\nwhere \\(\\vec u_{i,j}\\) denotes the displacement of the \\((i, j)\\) node, located at \\(x=i \\, Δx\\), \\(y=j \\, Δy\\). In the above formula, the weights \\(w_j\\) are \\(w_j=1\\) for off-corner nodes and \\(w_j=\\frac12\\) for corner nodes.\nThe average strain \\(⟨ε_{xx}⟩\\) being defined, we introduce the apparent uniaxial stiffness \\(\\tilde{A}_{x}^{\\text{app}}=q/⟨ε_{xx}⟩\\) and check that \\(\\tilde{A}_{x}^{\\text{app}}→\\tilde{A}_x^{\\text{eff}}\\) as the size of the system grows to infinity.\nNow that the stage is set, let us look at the results. In the remainder of this post, we will consider the following simple case: \\(θ=π/4\\) (square cells), \\(χ_x=χ_y=χ\\) (horizontal and vertical springs are identical), \\(\\mathcal\nN_x=\\mathcal N_y=\\mathcal N\\) (square mesh). From the general expressions of the effective stiffnesses, we find in that case\n\\[A_x^\\text{eff}=A_y^\\text{eff}=k\\bigl(1+χ\\bigr),\\quad\nν_{xy}=ν_{yx}=\\frac1{1+χ}\\]\nand\n\\[\\frac{\\tilde{A}_x^\\text{eff}}{k}=\\frac{χ\\bigl(χ+2\\bigr)}{χ+1}.\\]"
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html#apparent-stiffness-of-a-small-system",
    "href": "posts/20210509-What_is_homogenization-05/index.html#apparent-stiffness-of-a-small-system",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "Apparent stiffness of a small system",
    "text": "Apparent stiffness of a small system\nFor small systems, the apparent stiffness can be computed analytically. More details can be found in a companion post on the symbolic analysis of a spring mesh. We find, for a 1×1 system:\n\\[\\frac{\\tilde{A}_x^\\text{app}}k=\\frac{4χ\\bigl(χ+1\\bigr)}{2χ+1},\\]\nthen, for a 2×2 system:\n\\[\\frac{\\tilde{A}_x^\\text{app}}k\n=\\frac{8χ\\bigl(χ+1\\bigr)\\bigl(χ+2\\bigr)}{\\bigl(2χ+3\\bigr)\\bigl(3χ+2\\bigr)},\\]\nfinally, for a 3×3 system:\n\\[\\frac{\\tilde{A}_x^\\text{app}}k\n=\\frac{144χ\\bigl(χ+1\\bigr)\\bigl(4χ^4+24χ^3+41χ^2+24χ+4\\bigr)}\n{480χ^5+2888χ^4+5616χ^3+4771χ^2+1800χ+236}.\\]\nThe above expressions of the apparent stiffnesses are plotted below. More precisely, we plot the relative error\n\\[\\frac{\\tilde{A}_x^\\text{app}-\\tilde{A}_x^\\text{eff}}{\\tilde{A}_x^\\text{eff}}\\]\nagainst the stiffness ratio \\(\\chi\\).\n\n\n\nApparent stiffness vs. χ\n\n\nIt is observed that, for a given value of \\(\\chi\\), the error tends to decrease with the size of the system. However, even for 3×3 systems, the difference between apparent and effective siffnesses (about 20%) remains too high to conclude about convergence. This means that we need to explore larger systems."
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html#apparent-stiffness-of-larger-systems",
    "href": "posts/20210509-What_is_homogenization-05/index.html#apparent-stiffness-of-larger-systems",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "Apparent stiffness of larger systems",
    "text": "Apparent stiffness of larger systems\nFor larger systems, it is no longer practical to establish closed-form expressions of the apparent stiffness. We must resort to numerical simulations, that are presented in a companion post.\nThe simulations are carried out for the set of parameters for which an isotropic effective behavior is expected, namely \\(χ_x=χ_y=2\\) and \\(θ=π/4\\). Then \\(A_x^\\text{eff}=A_y^\\text{eff}=3k\\) and \\(A_{xy}^\\text{eff}=2k\\). Therefore, \\(\\tilde{A}_x^\\text{eff}=\\frac83k\\).\nIn the figure below, we plot in log-log scale the relative error on the effective stiffness as a function of the size of the system.\n\n\n\nApparent stiffness vs. system size\n\n\nFrom this plot, convergence (as a power of the system size) is quite clear. In other words, for large enough systems, the network of springs indeed behaves as a continuous membrane.\nConvergence is quite slow, though: for the apparent stiffness to be within 1% of the effective stiffness, we need a 64×64 system."
  },
  {
    "objectID": "posts/20210509-What_is_homogenization-05/index.html#conclusion",
    "href": "posts/20210509-What_is_homogenization-05/index.html#conclusion",
    "title": "What is homogenization? Part 5: introducing the representative volume element",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we have verified (for a specific loading) that the homogenization procedure developed in the previous post was indeed correct.\nWe have shown that the size of the system under consideration is important: remember that, for homogenization to be meaningful, scales must be separated.\nThe convergence plot presented above can be used to introduce what is commonly –but somewhat confusingly– called the representative volume element (RVE). A system can be considered as a RVE if the relative error between the apparent and effective values of a specific property are below a given tolerance (Kanit et al., 2003).\nFrom the above definition, it should be clear that there is no such thing as the RVE. At best, it is possible to define a RVE, for a specific quantity of interest (in the present case, the homogenized stiffness) and a user-specified tolerance.\nIn the next instalment of this series, we will introduce a little bit of randomness."
  },
  {
    "objectID": "posts/20180219-On_the_periodic-plus-smooth_decomposition_of_an_image-02/index.html",
    "href": "posts/20180219-On_the_periodic-plus-smooth_decomposition_of_an_image-02/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 2: defining the decomposition",
    "section": "",
    "text": "In the previous instalment of this series, we discussed the need for periodic images. Although not all images are periodic, some image analysis techniques are best performed in Fourier space (using the fast Fourier transform). Applying Fourier-based techniques to images that are not periodic (as is often the case) generates artifacts. In order to reduce these artifacts, Moisan (2011) proposed to construct a periodic image that is as close as possible to the original image. For reasons that will become clearer in the remainder of this post, he called the resulting construction the “periodic-plus-smooth decomposition”. We will define this decomposition in the remainder of this post, which is the second in a series in seven parts:\n\nIntroduction\nDefining the decomposition\nThe energy as a quadratic form\nImplementing the linear operators\nMinimizing the energy, the clumsy way\nMinimizing the energy, the clever way\nImproved implementation of Moisan’s algorithm\n\nThe code discussed in this series is available as a Python module on GitHub.\nAs an appetizer, Fig. 1 shows the original image (left) and its periodic (middle) and smooth components (right). Gray levels of the smooth component have been rescaled so as to fit between 0 and 255. Most of this image is grayish, meaning it is zero almost everywhere, except at the boundaries, where it corrects the jumps induced by the lack of periodicity of the initial image.\n\n\n\n\n\n\nFigure 1: Illustration of the periodic-plus-smooth decomposition of an image. The original image (left), its periodic component (middle) and its smooth (rescaled) component (right).\n\n\n\n\nThe decomposition as a minimization problem\nLet \\(u\\) be a \\(m\\times n\\) image. We want to find two images \\(p\\) (“periodic” component) and \\(s\\) (“smooth” component), such that \\(u=p+s\\) and\n\n\\(p\\) minimizes jumps across boundaries (periodicity),\n\\(s\\) minimizes jumps between neighbor pixels (smoothness),\n\\(p\\) and \\(u\\) have same mean value (conservation of brigthness).\n\nIn Moisan’s work, neighbor pixels refer to the 4-connectivity. Furthermore, we define\n\ndirect neighbors, that are adjacent to the pixel under consideration\nindirect neighbors, that are periodic images of these neigbors that would normally fall outside the image.\n\nFig. 2 illustrates direct and indirect neighbors. It shows that\n\ncorner pixels have 2 direct neighbors and 2 indirect neighbors,\noff-corner, boundary pixels have 3 direct neighbors and 1 indirect neighbor,\noff-boundary (inner) pixels have 4 direct neighbors.\n\n\n\n\n\n\n\nFigure 2: Direct (blue) and indirect (green) neighbors of corner pixels (orange, top row), off-corner, boundary pixels (orange, middle row) and off-boundary pixels (orange, bottom row).\n\n\n\nNow, we need to quantify how periodic is \\(p\\), and how smooth is \\(s\\). To do so, we will define two energy functions: \\(E_\\mathrm p\\) and \\(E_\\mathrm s\\) that penalize lack of periodicity and smoothness, respectively. More precisely, \\(E_\\mathrm p\\) (resp. \\(E_\\mathrm s\\)) is greater for less periodic (resp. less smooth) \\(p\\) (resp. \\(s\\)). The periodic-plus-smooth decomposition of an image \\(u\\) is then defined as the pair of images \\((p, s)\\) that minimize the total energy \\(E(p, s)=E_\\mathrm p(p)+E_\\mathrm s(s)\\) under the constraints \\(u=p+s\\) and \\(\\operatorname{mean}(s)=0\\). The remainder of this post is dedicated to defining the energies \\(E_\\mathrm p\\) and \\(E_\\mathrm s\\).\n\n\nHow to penalize lack of periodicity?\nFor each pixel located at the boundary of an image, we compute the sum of squared differences (SSD) with indirect neighbors. The sum of all these SSDs is the energy of the periodic component. Note that direct neighbors are excluded from this sum, as we focus here on the jumps across image boundaries. This leads to the following expression\n\\[E_\\mathrm p(p)=\\underbrace{(p_{m-1, 0}-p_{0, 0})^2+(p_{0, n-1}-p_{0, 0})^2}_\\text{top-left corner}\\] \\[+\\underbrace{(p_{0, 0}-p_{0, n-1})^2+(p_{m-1, n-1}-p_{0, n-1})^2}_\\text{top-right corner}\\] \\[+\\underbrace{(p_{0, 0}-p_{m-1, 0})^2+(p_{m-1, n-1}-p_{m-1, 0})^2}_\\text{bottom-left corner}\\] \\[+\\underbrace{(p_{0, n-1}-p_{m-1, n-1})^2+(p_{m-1, 0}-p_{m-1, n-1})^2}_\\text{bottom-right corner}\\] \\[+\\underbrace{\\sum_{i=1}^{m-2}(p_{i, n-1}-p_{i, 0})^2}_\\text{left column}+\\underbrace{\\sum_{i=1}^{m-2}(p_{i, 0}-p_{i, n-1})^2}_\\text{right column}\\] \\[+\\underbrace{\\sum_{j=1}^{n-2}(p_{m-1, j}-p_{0, j})^2}_\\text{top row}+\\underbrace{\\sum_{j=1}^{n-2}(p_{0, j}-p_{m-1, j})^2}_\\text{bottom row},\\]\nwhich reduces to\n\\[E_\\mathrm p(p)=2\\sum_{i=0}^{m-1}(p_{i, n-1}-p_{i, 0})^2+2\\sum_{j=0}^{n-1}(p_{m-1, j}-p_{0, j})^2.\\]\n\n\nHow to penalize lack of smoothness?\nAt this point, you might have guessed that smoothness is measured through the sum of squared differences between direct neighbors\n\\[E_\\mathrm s(s)=\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-1}\\bigl[(s_{i, j-1}-s_{i, j})^2+(s_{i, j+1}-s_{i, j})^2+(s_{i-1, j}-s_{i, j})^2+(s_{i+1, j}-s_{i, j})^2\\bigr],\\]\nwhere we have defined the following ghost cells\n\\[s_{i, -1}=s_{i, 0}, \\quad s_{i, n}=s_{i, n-1}, \\quad s_{-1, j}=s_{0, j}\n\\quad\\text{and}\\quad s_{m, j}=s_{m-1, j},\\]\nin order to make sure that indirect neighbors are indeed excluded. It is readily observed that in the above sum, each pair of direct neighbors appears exactly twice. In other words,\n\\[E_\\mathrm s(s)=2\\sum_{i=0}^{m-2}\\sum_{j=0}^{n-1}(s_{i+1, j}-s_{i, j})^2\n+2\\sum_{i=0}^{m-1}\\sum_{j=0}^{n-2}(s_{i, j+1}-s_{i, j})^2.\\]\n\n\nPython implementation\nImplementation of the total energy \\(E(p, s)=E_\\mathrm p(p)+E_\\mathrm s(s)\\) is fairly trivial (note the use of the broadcast_arrays function).\ndef ssd(a, b):\n    \"\"\"Sum of squared differences.\"\"\"\n    delta2 = b-a\n    delta2 *= delta2\n    return np.sum(delta2)\n\n\ndef energy(p, s):\n    \"\"\"Return the total energy of the periodic-plus-smooth decomposition.\n\n    The periodic and smooth components p and s are 2D arrays of\n    float64. They should have the same shape, although this is not\n    required by this function.  2D arrays.\n\n    The energy is defined in Moisan (2011), Theorem 1. The\n    contribution of the periodic component is\n\n        E_p(p) = sum sum [p(x)-p(y)]**2,\n                  x   y\n\n    where the first sum is carried over all boundary pixels x, and the\n    second sum is carried over the indirect neighbors y of x. The\n    contribution of the smooth component is\n\n        E_s(s) = sum sum [s(x)-s(y)]**2,\n                  x   y\n\n    where the first sum is carried over all pixels x, and the second\n    sum is carried over the direct neighbors y of x. The total energy\n    is then defined as\n\n        E(p, s) = E_p(p) + E_s(s).\n    \"\"\"\n    p, s = np.broadcast_arrays(p, s)\n    return 2*(ssd(p[:, 0], p[:, -1]) +\n              ssd(p[0, :], p[-1, :]) +\n              ssd(s[:-1, :], s[1:, :]) +\n              ssd(s[:, :-1], s[:, 1:]))\n\n\nAn equivalent, unconstrained minimization problem\nThe periodic-plus-smooth decomposition \\((p, s)\\) of an image \\(u\\) is defined as the minimizer of the above defined energy \\(E(p, s)\\), under the constraints: \\(u=p+s\\) and \\(\\operatorname{mean}s=0\\). Moisan (2011) reformulates this constrained minimization problem as the following unconstrained minimization problem\n\\[s=\\operatorname*{arg\\,min}_v F(v, u),\n\\quad\\text{with}\\quad\nF(s, u)=E_\\mathrm p(u-s)+E_\\mathrm s(s)+(\\operatorname{mean}s)^2,\\]\nand the periodic component \\(p\\) reads: \\(p=u-s\\). This is the minimization problem that we will eventually solve.\n\n\nConclusion\nIn the present post, we have defined the periodic-plus-smooth decomposition as the minimizer of Moisan’s energy, under the constraint that the average gray level of the periodic component is equal to the average gray level of the initial image.\nMoisan (2011) showed that this minimizer is explicit in Fourier space. In the next instalment of this series, we will however temporarily ignore this result, and optimize the total energy in the real space, using standard iterative techniques. This will allow us to generate reference decompositions that will eventually be used to set up unit tests in order to check our implementation of Moisan’s method."
  },
  {
    "objectID": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html",
    "href": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html",
    "title": "Orientation correlations among rice grains, part 2: acquisition of tomography images",
    "section": "",
    "text": "In the first instalment of this series, I briefly introduced orientational order in assemblies of anisotropic particles, and proposed an illustration based on synthetic microstructures. But what I really intend to do in this series is to show how orientational order can be quantified in a “real-life” sample, namely a packing of rice grains. This of course requires a 3D image of the packing. Fortunately, my lab (Laboratoire Navier) is the proud host of a collaborative microtomography platform and my former colleague Nicolas Lenoir – who was in charge of this instrument – gave me the opportunity to scan my toy sample in december 2013.\nThe sample preparation is rather crude. Ordinary, long-grain rice is poured in a plastic container (see picture below), 50mm in diameter. The average length of the grains is about 6.5mm as the image analysis to come will show. Therefore, strong boundary effects are to be expected. This is no big issue for the present study, which is carried out for illustrative purposes only.\nTwo X-ray sources are available at Laboratoire Navier. For the present experiment, we used the Hamamatsu L10801 X-ray source (maximum voltage: 230V, maximum current: 1mA). Combined with the the Paxscan Varian 2520V flat-panel X-ray imager (1536x1920 pixels, pixel pitch 127µm), this setup leads to a voxel size of approx. 0.030mm. The specimen was scanned at 100kV and 300µA with an imager frame-rate of 6 images per second. To reduce noise, 12 radiographs were averaged to produce one projection; the total number of projections was 1440 (see below a typical projection).\n3D reconstruction was carried out using standard tools developed by RX Solutions France. Contrast, resolution and signal-to-noise ratio were all excellent, so that the most basic reconstruction procedure resulted in very high quality 3D images (see three orthogonal slices below).\nThe reconstruction is highly contrasted, so that simple thresholding should produce a very convincing segmentation. This will be the topic of the next instalments. But we first take a break to discuss binning of the images."
  },
  {
    "objectID": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html#acknowledgements",
    "href": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html#acknowledgements",
    "title": "Orientation correlations among rice grains, part 2: acquisition of tomography images",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe present series would not exist without the help of my former colleague Nicolas Lenoir, now research engineer at PLACAMAT. His dedication and excellent temper made 3D imaging at Laboratoire Navier a real delight. He also kindly agreed to review this post, which I am grateful for, since he spotted some rather crude mistakes!\nParaview was used to produce the last image of this post."
  },
  {
    "objectID": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html#update-2017-05-25",
    "href": "posts/20150310-Orientation_correlations_among_rice_grains-02/index.html#update-2017-05-25",
    "title": "Orientation correlations among rice grains, part 2: acquisition of tomography images",
    "section": "Update (2017-05-25)",
    "text": "Update (2017-05-25)\nThe 3D reconstruction is now available from the Zenodo platform as a set of 689 TIFF images, 1747×1751 pixels, under a CC BY 4.0 license (10.5281/zenodo.582636)."
  },
  {
    "objectID": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html",
    "href": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html",
    "title": "Elastic constants of an isotropic material, part 3: putting it all together",
    "section": "",
    "text": "In the previous instalments of this series (see Part 1 and Part 2), I have shown that regardless of the dimensionality (3D or plane strain elasticity), the constitutive law of an isotropically elastic material reads \\[\n\\sigma_{ij}=\\kappa\\,\\varepsilon_{kk}\\,\\delta_{ij}+2\\mu\\,\\left(\\varepsilon_{ij}-\\frac{\\varepsilon_{kk}}d\\,\\delta_{ij}\\right),\n\\tag{1}\\] where \\(d\\) is the dimension of the physical space (\\(d=3\\) for 3D elasticity, \\(d=2\\) for plane strain elasticity), \\(\\mu\\) is the shear modulus, and \\(\\kappa\\) is the bulk modulus, whose expression depends on \\(d\\) \\[\n\\kappa=\\frac23\\frac{1+\\nu}{1-2\\nu}\\,\\mu\\qquad(d=3),\n\\tag{2}\\] \\[\n\\kappa=\\frac\\mu{1-2\\nu}\\qquad(d=2).\n\\tag{3}\\]\nIn this instalment, I am going to introduce some classical isotropic, fourth-rank tensors which will prove extremely useful and will allow us to cast Eq. (1) in an intrinsic (component-free) form. It should be noted that the following developments are restricted to fourth-rank tensors \\(\\mathbf T\\) with both minor symmetries \\[\nT_{ijkl}=T_{jikl}=T_{ijlk},\n\\] and major symmetry \\[\nT_{ijkl}=T_{klij}.\n\\]"
  },
  {
    "objectID": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-identity-tensor",
    "href": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-identity-tensor",
    "title": "Elastic constants of an isotropic material, part 3: putting it all together",
    "section": "Fourth-rank identity tensor",
    "text": "Fourth-rank identity tensor\nThe fourth-rank identity tensor \\(\\mathbf{I}\\) maps any second-rank, symmetric tensor \\(\\mathbf u\\) onto itself \\[\n\\mathbf I:\\mathbf u=\\mathbf u.\n\\]\nIt is straightforward to work out the components of \\(\\mathbf I\\) (accounting for minor symmetries) \\[\nI_{ijkl}=\\frac12\\left(\\delta_{ik}\\,\\delta_{jl}+\\delta_{il}\\,\\delta_{jk}\\right).\n\\]"
  },
  {
    "objectID": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-spherical-projection-tensor",
    "href": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-spherical-projection-tensor",
    "title": "Elastic constants of an isotropic material, part 3: putting it all together",
    "section": "Fourth-rank spherical projection tensor",
    "text": "Fourth-rank spherical projection tensor\nThe fourth-rank spherical projection tensor \\(\\mathbf J\\) extracts the spherical part of any symmetric, second-rank tensor \\(\\mathbf u\\) \\[\n\\mathbf J:\\mathbf u=\\frac1d\\operatorname{tr}(\\mathbf u)\\,\\boldsymbol\\delta,\n\\] where \\(\\boldsymbol\\delta\\) is the second-rank identity tensor (with components \\(\\delta_{ij}\\)). In particular, \\(\\mathbf\nJ:\\boldsymbol\\delta=\\boldsymbol\\delta\\). In intrinsic form, \\(\\mathbf J\\) reads \\[\n\\mathbf J=\\frac1d\\mathbf\\delta\\otimes\\mathbf\\delta,\n\\] where \\(\\otimes\\) denotes the tensor product. The components of \\(\\mathbf J\\) are \\[\nJ_{ijkl} = \\frac1d\\,\\delta_{ij}\\,\\delta_{kl}.\n\\]"
  },
  {
    "objectID": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-deviatoric-projection-tensor",
    "href": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#fourth-rank-deviatoric-projection-tensor",
    "title": "Elastic constants of an isotropic material, part 3: putting it all together",
    "section": "Fourth-rank deviatoric projection tensor",
    "text": "Fourth-rank deviatoric projection tensor\nThe fourth-rank deviatoric projection tensor \\(\\mathbf K\\) extracts the deviatoric part of any symmetric, second-rank tensor \\(\\mathbf u\\) \\[\n\\mathbf K:\\mathbf u=\\mathbf u-\\frac1d\\,\\operatorname{tr}(\\mathbf u)\\,\\boldsymbol{\\delta}\n=\\mathbf u-\\mathbf J:\\mathbf u,\n\\] from which it results that \\[\n\\mathbf K=\\mathbf I-\\mathbf J.\n\\]"
  },
  {
    "objectID": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#algebra-of-the-mathbfj-and-mathbfk-tensors",
    "href": "posts/20140112-Elastic_constants_of_an_isotropic_material-03/index.html#algebra-of-the-mathbfj-and-mathbfk-tensors",
    "title": "Elastic constants of an isotropic material, part 3: putting it all together",
    "section": "Algebra of the \\(\\mathbf{J}\\) and \\(\\mathbf{K}\\) tensors",
    "text": "Algebra of the \\(\\mathbf{J}\\) and \\(\\mathbf{K}\\) tensors\nIt can readily be verified that \\[\n\\mathbf J:\\mathbf J=\\mathbf J,\\quad\n\\mathbf K:\\mathbf K=\\mathbf K\n\\quad\\text{and}\\quad\n\\mathbf K:\\mathbf J=\\mathbf J:\\mathbf K=\\mathbf0.\n\\]\nTherefore, multiplication of two isotropic tensors \\(\\mathbf T_i=a_i\\,\\mathbf{J}+b_i\\,\\mathbf{K}\\) (\\(i=1,2\\)) is trivial \\[\n\\mathbf T_1:\\mathbf T_2=a_1\\,a_2\\,\\mathbf J+b_1\\,b_2\\,\\mathbf K.\n\\]\nAlso, inversion of an isotropic tensor \\(\\mathbf T=a\\,\\mathbf{J}+b\\,\\mathbf{K}\\) is straightforward \\[\n\\mathbf T^{-1}=\\frac1a\\,\\mathbf J+\\frac1b\\,\\mathbf K.\n\\]\nAll these expressions will prove extremely useful in due time."
  },
  {
    "objectID": "posts/20180212-On_the_periodic-plus-smooth_decomposition_of_an_image-01/index.html",
    "href": "posts/20180212-On_the_periodic-plus-smooth_decomposition_of_an_image-01/index.html",
    "title": "On the periodic-plus-smooth decomposition of an image, part 1: introduction",
    "section": "",
    "text": "In this new series, we will explore the so-called periodic-plus-smooth decomposition of an image, introduced by Moisan in 2011. This series is largely based on Moisan’s paper, called Periodic plus Smooth Image Decomposition (the author’s version can be found on HAL). Besides introducing a quite smart technique (that I do use for real materials science applications), this series will be an opportunity to discuss an important topic: how to test the implementation of an algorithm, and be confident that the test actually validates the implementation.\nTo do so, we will first define the periodic-plus-smooth decomposition as a minimization problem. This will lead to a first implementation of this decomposition: the objective function is quadratic, and the minimization problem therefore merely reduces to a linear system. However, this system is large (the number of unknowns is the number of pixels!). We will therefore use matrix-free techniques.\nThis first – quite inefficient – implementation will then serve as a reference implementation of the decomposition, for testing purposes. Indeed, Moisan showed that the minimization problem he introduced could in fact be explicitely solved in Fourier space. He proposed two efficient algorithms to compute the decomposition. Both rely, of course, on the FFT. We will implement one of these and test it against the reference implementation.\nThis is a series in seven parts, organized as follows:\n\nIntroduction\nDefining the decomposition\nThe energy as a quadratic form\nImplementing the linear operators\nMinimizing the energy, the clumsy way\nMinimizing the energy, the clever way\nImproved implementation of Moisan’s algorithm\n\nThe code discussed in this series is available as a Python module on GitHub.\nThat’s a lot of work! So, without further ado, let’s start introducing this decomposition!\n\nThe need for periodic images\nLet us start by briefly discussing what is a periodic image, and why we would ever need one. Loosely speaking, an image is periodic if placing copies of the same image on a 2×2 grid can be done (almost) seamlessly. Remember that an image is defined for a discrete set of pixels, and that the pixel values themselves are also discrete. Therefore, it is not possible to refer to the continuity of an image, which explains why it is difficult to define periodic images more precisely.\nIt is actually easier to verify that an image is not periodic. Let us consider the following image as an example (see Fig. 1).\n\n\n\n\n\n\nFigure 1: The original image\n\n\n\nInstead of putting aside 4 copies of the same image, we can simply swap the quadrants, as shown in Fig. 2. Alternatively, you could also ask my three-year old daughter if her hut is periodic ;-). In Fig. 2, the four corners certainly do not join seamlessly at the center, which is a sure indication that the image is not periodic.\n\n\n\n\n\n\nFigure 2: The original image shown in Fig. 1, with swapped quadrants.\n\n\n\nIt should be noted that the image shown in Fig. 2 is readily produced with the numpy.fft.fftshift function, as illustrated by the following code snippet\nimport numpy as np\n\nfrom skimage.io import imread, imsave\n\nDATA_DIR = \"./\"\n\nu = imread(DATA_DIR+'hut-648x364.png')\nimsave(DATA_DIR+'hut-648x364-fftshift.png', np.fft.fftshift(u))\nWhy would this lack of periodicity be a problem? Well, many image analysis techniques rely on the fast Fourier transform (FFT) for efficiency. In turn, the discrete Fourier transform implicitely assumes that the data is periodic; otherwise, artifacts can result. An archetypal example is the power spectrum of an image (we shall come back to this specific issue in a dedicated series). The power spectrum of Fig. 1 is displayed in Fig. 3 below; the following code snippet was executed to produce this image.\nu_dft = np.fft.fft2(u)\nu_ps = np.abs(np.fft.fftshift(u_dft))**2\na = np.log10(u_ps)\na_min, a_max = np.min(a), np.max(a)\na = 255*(a-a_min)/(a_max-a_min)\n\nimsave(DATA_DIR+'hut-648x364-power_spectrum.png', a.astype(np.uint8))\n\n\n\n\n\n\nFigure 3: The power spectrum of the image shown in Fig. 1.\n\n\n\nIn Fig. 3, the bright cross at the center is the signature of the jumps across the boundaries of the image. Indeed, remember that discontinuities at large correlation lengths translate to oscillations at low frequencies (the center of the power spectrum image).\n\n\nPeriodization by symmetrization\nOf course, it is possible to enforce periodicity by tiling together 4 mirror images of the same initial image as follows (see Fig. ?@fig-04)\nm, n = u.shape\nleft, right = slice(0, m), slice(2*m-1, m-1, -1)\ntop, bottom = slice(0, n), slice(2*n-1, n-1, -1)\nu_mirrored = np.zeros((2*m, 2*n), dtype=u.dtype)\nu_mirrored[left, bottom] = u\nu_mirrored[right, bottom] = u\nu_mirrored[left, top] = u\nu_mirrored[right, top] = u\nimsave(DATA_DIR+'hut-648x364-mirrored.png', u_mirrored)\n \nThe resulting power spectrum (computed with the code snippet below) is shown in Fig. ?@fig-05. It is observed that symmetrization does not remove entirely the cross at the center of the power spectrum. Worse, “it makes the DFT symmetric and real-valued, which can be dramatic if the phase component of the Fourier transform has to be analyzed, or if orientation issues are concerned” (Moisan, 2011). This led Moisan to introduce the periodic-plus-smooth decomposition.\na = np.abs(np.fft.fftshift(np.fft.fft2(u_mirrored)))**2\na[a==0.0]=1.0\na = np.log10(a)\na_min, a_max = np.min(a), np.max(a)\na = 255*(a-a_min)/(a_max-a_min)\n\nimsave(DATA_DIR+'hut-648x364-mirrored-power_spectrum.png', a.astype(np.uint8))\n \n\n\nConclusion\nIn this post, we set the stage for the subsequent instalments of this series, arguing that it is sometimes desirable that an image should be periodic. In the next instalment of this series, we will define the periodic-plus-smooth decomposition of Moisan (2011). We will then turn to the implementation of this decomposition."
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "",
    "text": "In the previous instalment of this series, we have segmented the 3D image of the assembly of rice grains. In other words, each voxel of the image is attributed the label of the grain to which it belongs. Remember the initial goal of this series: we want to quantify orientation correlations between grains. To do so, we must analyse the orientation of each individual grain. This is the topic of the present post.\nIt is customary to define the orientation of an elongated object by means of the eigenvectors of the tensor of second moments, defined as follows \\[\nJ_{ij} = \\int_\\text{Grain}\\bigl(x_i-X_i\\bigr)\\bigl(x_j-X_j\\bigr)\\mathrm{d} x_1\\,\\mathrm{d} x_2\\,\\mathrm{d} x_3,\n\\tag{1}\\] where the integral is carried out over the grain, and \\(X_i\\) denotes the \\(i\\)-th coordinate of the grain’s center of mass \\[\nX_i = \\frac1V\\int_\\text{Grain}x_i\\,\\mathrm{d} x_1\\,\\mathrm{d}x_2\\,\\mathrm{d}x_3\n\\] (\\(V\\): volume of the grain). In coordinate-free form, Eq. (1) reads \\[\n\\mathbf{J}=\\int_\\text{Grain}\\bigl(\\vec x-\\vec X\\bigr)\\otimes\\bigl(\\vec x-\\vec X\\bigr)\\mathrm{d}^3\\vec{x}.\n\\]\nThe above defined tensor of second moments is related to the inertia tensor \\(\\mathbf{I}\\) \\[\n\\mathbf{I}=\\operatorname{tr}\\mathbf{J}\\,\\boldsymbol{\\delta}-\\mathbf{J},\n\\tag{2}\\] where \\(\\mathbf{I}\\) is defined as follows \\[\n\\mathbf{I}=\\int_\\text{Grain}\\bigl[\\bigl(\\vec x-\\vec X\\bigr)\\cdot\\bigl(\\vec x-\\vec X\\bigr)\\boldsymbol{\\delta}-\\bigl(\\vec x-\\vec X\\bigr)\\otimes\\bigl(\\vec x-\\vec X\\bigr)\\bigr]\\mathrm{d}^3\\vec{x}.\n\\]\nBeing symmetric, the tensor \\(\\mathbf{J}\\) of second moments is diagonalizable, and we compute its eigenvalues \\(J_a\\), \\(J_b\\) and \\(J_c\\), and the associated eigenvectors \\(\\vec v_a\\), \\(\\vec v_b\\) and \\(\\vec v_c\\) \\[\n\\mathbf{J}\\cdot\\vec v_\\alpha=J_\\alpha\\vec v_\\alpha,\n\\] where \\(\\alpha=a, b, c\\). In the present post, we define the orientation of the grain as the eigenvector associated to the largest eigenvalue. We can further define the equivalent ellipsoid as the ellipsoid with same volume and principal second moments. It can readily be verified that the volume and principal second moments of an ellipsoid are \\[\nV=\\frac{4\\pi}3 abc,\\quad J_a=\\frac{Va^2}5,\\quad J_b=\\frac{Vb^2}5,\\quad J_c=\\frac{Vc^2}5,\n\\] where \\(a\\), \\(b\\) and \\(c\\) are the radii of the ellipsoid. The above expressions can be retrieved from Wikipedia and Eq. (2). For example \\[\nJ_a = \\frac12\\bigl(I_b+I_c-I_a\\bigr).\n\\]\nThen, the radii of the equivalent ellipsoid are retrieved as follows from the volume \\(V\\) and the principal second moments \\(J_a\\), \\(J_b\\) and \\(J_c\\) of the grain \\[\na=\\sqrt{\\frac{5I_a}V},\\quad b=\\sqrt{\\frac{5I_b}V},\\quad c=\\sqrt{\\frac{5I_c}V}.\n\\]\nThe radii of the equivalent ellipsoid can be used to characterize the size of the grains. In the present post, we compute for each grain: the volume, the center of mass, the tensor of second moments, the orientation and the radii of the equivalent ellipsoid. We will then perform rudimentary analysis of these morphological parameters.\nAs usual, we will use Python to carry out the dirty work. We will start with a very naive approach and present a nearly loop-free approach using the clever scipy.ndimage.sum function. We start with loading the segmented images."
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#direct-computation-of-the-morphological-parameters-of-grain-42",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#direct-computation-of-the-morphological-parameters-of-grain-42",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "Direct computation of the morphological parameters of grain 42",
    "text": "Direct computation of the morphological parameters of grain 42\nThe direct (naive) approach presented in this section will serve as a reference for a better approach presented in the next section. It will be illustrated on one grain only (namely grain 42), which we first locate. The remainder of the analysis is then restricted to a ROI surrounding the selected grain.\nindex = 42\nslices = scipy.ndimage.find_objects(labels)[index-1]\nroi = labels[slices]\nThe grain shape is then defined by mask, an array of booleans, where all voxels of the ROI that belong to the grain are set to True.\nmask = roi == index\nThe volume (in voxels) of the grain is the sum of the above array\nvol_ref = mask.sum()\nprint('Volume of grain {} = {} vox^3.'.format(index, vol_ref))\nVolume of grain 42 = 7087 vox^3.\nTo compute the center of mass and inertia of the grain, we must define the coordinates of each voxel of the grain. To do so, we use the mgrid function\ncoords = np.mgrid[slices].astype(np.float64)\nThe center of mass of the grain is the sum of these coordinates divided by the total volume\ncom_ref = np.sum(mask*coords, axis=(-1, -2, -3))/vol_ref\nprint('Center of mass of grain {} = {} vox'.format(index, com_ref))\nCenter of mass of grain 42 = [  4.92069987 191.41597291 103.69183011] vox\nNote that we pre-multiplied coords by mask in order to keep only those voxels that belong to the grain. To compute the inertia of the grain, we first subtract the coordinates of the center of mass from the voxel coordinates.\ncoords -= com_ref[:, None, None, None]\nWe then compute the array of coordinates cross-products coords_xprod defined as follows\ncoords_xprod[m, n, i, j, k] = coords[m, i, j, k]*coords[n, i, j, k]\n(i, j, k: voxel indices; m, n: coordinates indices). The coords_xprod array is produced by the following line of code\ncoords_xprod = coords[None, ...]*coords[:, None, ...]\nand we find\nmoments2_ref = np.sum(mask*coords_xprod, axis=(-1, -2,-3))\nprint('Moments of inertia of grain {} (vox^5)'.format(index))\nprint(moments2_ref)\nMoments of inertia of grain 42 (vox^5)\n[[ 71603.43332863 -45107.22322562 -71060.19147735]\n [-45107.22322562 426435.7118668  181708.48483138]\n [-71060.19147735 181708.48483138 880736.95696345]]\nThis is a bit tedious, isn’t it? Besides, we should normally loop over the grains in order to carry out the analysis for all grains. Comes the wonderful scipy.ndimage.sum function to the rescue!"
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#using-the-scipy.ndimage.sum-function",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#using-the-scipy.ndimage.sum-function",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "Using the scipy.ndimage.sum function",
    "text": "Using the scipy.ndimage.sum function\nThis function will allow us to carry out the analysis over all grains simultaneously. We start with the volume, which is seen as \\[\nV=\\sum_\\text{Grain} 1,\n\\] where the sum is carried over all voxels of each grain.\nones = np.ones_like(labels, dtype=np.float64)\nvol = scipy.ndimage.sum(ones, labels, indices)\nAnd we can check that the value we found for grain 42 is correct\nprint('Volume of grain {}'.format(index))\nprint('    expected   = {}'.format(vol_ref))\nprint('    actual     = {}'.format(vol[index-1]))\nVolume of grain 42\n    expected   = 7087\n    actual     = 7087.0\nFor the center of mass, we will use the center_of_mass function rather than the sum function.\ncom = np.asarray(scipy.ndimage.center_of_mass(ones, labels, indices))\nprint('Center of mass of grain {}'.format(index))\nprint('    expected   = {}'.format(com_ref))\nprint('    actual     = {}'.format(com[index-1]))\nCenter of mass of grain 42\n    expected   = [  4.92069987 191.41597291 103.69183011]\n    actual     = [  4.92069987 191.41597291 103.69183011]\nFinally, the second moments are seen as the following sum \\[\nJ_{ij}=\\sum_\\text{Grain}(x_i-X_i)(x_j-X_j)=\\sum_\\text{Grain}x_ix_j-VX_iX_j,\n\\] where the last identity is known as the parallel axis theorem. Implementation of this formulation is straightforward, starting from the construction of the array of voxel coordinates coords.\ncoords = np.mgrid[[slice(n) for n in labels.shape]]\nmoments2 = np.empty((indices.size, 3, 3), dtype=np.float64)\n\nfor i in range(3):\n    for j in range(3):\n        xi, xj = coords[(i, j), :]\n        moments2[:, i, j] = (scipy.ndimage.sum(xi*xj, labels, indices) -\n                             vol*com[:, i]*com[:, j])\nNota: I could not find a pythonic way to get rid of this uggly nested loop…\nWe can again check that the result is correct for grain 42.\nprint('Second moments of grain {}'.format(index))\nprint('    expected =')\nprint(moments2_ref)\nprint('    actual =')\nprint(moments2[index-1])\nSecond moments of grain 42\n    expected =\n[[ 71603.43332863 -45107.22322562 -71060.19147735]\n [-45107.22322562 426435.7118668  181708.48483138]\n [-71060.19147735 181708.48483138 880736.95696345]]\n    actual =\n[[ 71603.43332863 -45107.22322562 -71060.19147735]\n [-45107.22322562 426435.7118668  181708.48483139]\n [-71060.19147735 181708.48483139 880736.95696346]]\nThat’s it! We have computed the second moments of each grain. See how this sum function is convenient? We are now ready to compute the orientation of each grain, as well as the radii of the equivalent ellipsoid. We first compute the eigenvalues and eigenvectors of the tensors of second moments.\nmoments2_eigvals, moments2_eigvecs = np.linalg.eig(moments2)\nThe orientation \\(\\vec n\\) of the grain is defined as the eigenvector associated with the largest principal second moment.\ni = np.argmax(moments2_eigvals, axis=1)\nrows = moments2.shape[0]\nn = moments2_eigvecs[np.arange(rows), 0:3, i]\nprint(n)\n[[ 0.01955891  0.05286465 -0.99841012]\n [-0.17300079 -0.67355818 -0.71860288]\n [-0.49498664 -0.84077194  0.21929608]\n ...\n [-0.14766036  0.2963219  -0.94360466]\n [ 0.          1.          0.        ]\n [-0.1722074   0.98321974  0.06019601]]\nThe following code snippet computes the radii of each grain, and sorts them in ascending order.\nradius = np.sort(np.sqrt(5*moments2_eigvals/vol[:, None]))\nWe can now proceed with the analysis of the results. This will be done more thoroughly in the next instalment of this series. The present post will be restricted to basic analyses. But first of all, it is time to save our results!\nwith h5py.File(filename, 'r+') as f:\n    f['volume'] = vol\n    f['center_of_mass'] = com\n    f['radii'] = radius\n    f['orientation'] = n"
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#volume-of-grains",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#volume-of-grains",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "Volume of grains",
    "text": "Volume of grains\nfig = mpl.figure.Figure(figsize=(8, 3))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel(u'V (vox³)')\nax.set_ylabel('Number')\nax.hist(vol, range=(0, 12000), bins=30, linewidth=0)\nfig.tight_layout()\nfig.savefig('./volume_histogram.png', transparent=True)\n\n\n\nVolume of grains\n\n\nMost grains have a volume comprised between 6000 and 8000 vox³. It is observed that a significant number of grains are very small. There are two possible explanations for this\n\nsome grains where broken in smaller pieces,\nour segmentation was not perfect (over-segmentation might have occured).\n\nMy guess is that it is in fact a little bit of both. One possible remedy would be to filter out those grains that are too small in the subsequent analysis. We will not go into such degree of refinment."
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#size-of-the-grains",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#size-of-the-grains",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "Size of the grains",
    "text": "Size of the grains\nIn this section we visualize the radii of the equivalent ellipsoids\nfig = mpl.figure.Figure(figsize=(8, 3))\nax = fig.add_subplot(1, 1, 1)\nax.hist(radius[:, -1], range=(0, 40), bins=40, linewidth=0)\nax.set_xlabel('a (vox)')\nax.set_ylabel('Number')\nfig.tight_layout()\nfig.savefig('radius_a_histogram.png', transparent=True)\n\nfig = mpl.figure.Figure(figsize=(8, 3))\nax = fig.add_subplot(1, 1, 1)\nax.hist((radius[:, -2], radius[:-1]), range=(0, 20), bins=20, linewidth=0)\nax.set_xlabel('b, c (vox)')\nax.set_ylabel('Number')\nfig.tight_layout()\nfig.savefig('radii_b_c_histogram.png', transparent=True)\n\n\nThe length of most grains is about 2×27=54 pixels (about 6.5 mm). Also, the grains are not spheroids: indeed \\(b\\neq c\\)."
  },
  {
    "objectID": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#orientation-of-grains",
    "href": "posts/20160219-Orientation_correlations_among_rice_grains-07/index.html#orientation-of-grains",
    "title": "Orientation correlations among rice grains, part 7: analysis of the shape of the grains",
    "section": "Orientation of grains",
    "text": "Orientation of grains\nThis will be the topic of the next instalment of this series. We will only check for possible anisotropy by analysing the following second-order orientation tensor: \\(\\langle\\vec n\\otimes\\vec n\\rangle\\), where angle brackets stand for ensemble average. It can readily be verified that for isotropic distributions, this tensor is diagonal \\[\n\\langle\\vec n\\otimes\\vec n\\rangle=\n\\frac 13\n\\begin{bmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0 & 0 & 1\n\\end{bmatrix}.\n\\]\nAny deviation from this diagonal tensor indicates anisotropy (the converse is not true!). Computation of this orientation tensor is easy\nnn = n[:, None, :]*n[:, :, None]\nnn_avg = nn.mean(axis=0)\nprint(nn_avg)\n[[ 0.27082401  0.02535001 -0.02444013]\n [ 0.02535001  0.34864242 -0.00637534]\n [-0.02444013 -0.00637534  0.38053357]]\nWhich shows that the distribution of grains is not isotropic. Analysis of the eigenvalues of the orientation tensor would show that the vertical direction is in fact a direction of anisotropy (which should not come as a surprise)… but we will leave it like that for now!"
  },
  {
    "objectID": "posts/20150930-Orientation_correlations_among_rice_grains-06/index.html",
    "href": "posts/20150930-Orientation_correlations_among_rice_grains-06/index.html",
    "title": "Orientation correlations among rice grains, part 6: segmentation",
    "section": "",
    "text": "In the previous instalment of this series, I showed that a convincing binary image could be produced from the gray level 3D reconstruction of the assembly of rice grains, using Otsu’s threshold. However, I intend to carry out statistical analyses of the grains themselves in the subsequent instalments. Therefore, instead of a binary image of the rice grains, what is really needed is a labelled image, where all voxels which are thought to belong to the same rice grain are tagged with the same label. This is called segmentation, which is the topic of the present post. I will first show that the most basic segmentation technique (namely, detecting connected components in the image) fails in the present case. This calls for a more elaborate strategy, based on the widely popular watershed method. However, blind application of the standard watershed strategy leads to over-segmentation. This post will therefore close on a problem-dependent strategy better suited to the present case.\nBefore we start, let me mention a book-keeping issue. Up to the previous post, 2D slices of the 3D image were stored in separate *.tif files, which is rather tedious to load and solve. From now on, I will store all analyses in a *.hdf5 file. I am by no means an expert on this great file format (see website), but what I like about it is\nThe following code snippet (download) converts the binary *.tif images into a single *.hdf5 file. It uses the h5py library; PyTables is another option.\nNow, on to segmentation!"
  },
  {
    "objectID": "posts/20150930-Orientation_correlations_among_rice_grains-06/index.html#conclusion",
    "href": "posts/20150930-Orientation_correlations_among_rice_grains-06/index.html#conclusion",
    "title": "Orientation correlations among rice grains, part 6: segmentation",
    "section": "Conclusion",
    "text": "Conclusion\nIn an image analysis pipeline, segmentation is notoriously the critical step of the process. Watershed is a very efficient technique, which requires careful seeding. For anisotropic object, ad-hoc techniques have to be adopted. In the present blog, I showed how some simple mathematical morphology operations could be used to produce a satisfactory set of seeds. It should be noted however that the reason why the proposed approach works so well is that rice grains are nearly spheroidal. In other words, correctly seeding the watershed process is highly problem dependent!\nIn the next instalment of this series, I will show how to analyse the shape and orientation of each individual grain."
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html",
    "title": "Symbolic analysis of a spring mesh",
    "section": "",
    "text": "In this post, we compute symbolic expressions of the apparent stiffness introduced in this post. Our goal is to find the solution to the general problem depicted below."
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#strain-energy",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#strain-energy",
    "title": "Symbolic analysis of a spring mesh",
    "section": "1.1 Strain energy",
    "text": "1.1 Strain energy\nIn a previous post, we derived the stiffness matrix of a linear spring. This expression is used in the present post to evaluate the strain energy \\(\\mathcal U\\) as the sum of the contributions of all springs\n\\[\n\\mathcal U=\\sum_{i, j, k, l}\\tfrac{1}{2} \\, k_{ij,kl}\\bigl[\\bigl(\\vec u_{ij}-\\vec u_{kl}\\bigr)\\cdot\\vec n_{ij,kl}\\bigr]^2,\\]\nwhere the sum runs over all pairs of nodes \\((i, j)\\) and \\((k, l)\\) that are connected by a spring, \\(k_{ij, kl}\\) is the stiffness of the spring that connects node \\((i, j)\\) to node \\((k, l)\\) and \\(\\vec n_{ij, kl}\\) is its direction (unit vector). Finally, \\(\\vec u_{ij}\\) and \\(\\vec u_{kl}\\) are the nodal displacements. The above formula is implemented as follows.\n\ndef strain_energy(u):\n    N = u.shape[0] - 1\n    U = zero\n    for x in range(N + 1):\n        for y in range(N + 1):\n            # Horizontal springs\n            if x &lt; N:\n                U += kx / 2 * (e1.dot(u[x + 1, y] - u[x, y])) ** 2\n            # Vertical springs\n            if y &lt; N:\n                U += ky / 2 * (e2.dot(u[x, y + 1] - u[x, y])) ** 2\n            if (x &lt; N) and (y &lt; N):\n                U += k / 2 * (d1.dot(u[x + 1, y + 1] - u[x, y])) ** 2\n                U += k / 2 * (d2.dot(u[x, y + 1] - u[x + 1, y])) ** 2\n    return U"
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#potential-of-external-forces",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#potential-of-external-forces",
    "title": "Symbolic analysis of a spring mesh",
    "section": "1.2 Potential of external forces",
    "text": "1.2 Potential of external forces\nThe potential of external forces is the following sum\n\\[\\mathcal V=\\sum_{i, j}\\vec Q_{ij}\\cdot\\vec u_{ij},\\]\nwhere the sum runs over all nodes \\((i, j)\\) that are loaded and \\(\\vec Q_{ij}\\) is the applied nodal force. In the present case, only nodes on the left and right boundaries are loaded\n\\[\\mathcal V=\\sum_{j=0}^{\\mathcal N_y}w_j \\, Q \\, \\vec e_x\\cdot\\bigl(\\vec u_{N_x, j}-\\vec u_{0, j}\\bigr),\\]\nwhere \\(w_0=w_{\\mathcal N_y}=\\frac12\\) and \\(w_1=\\cdots=w_{\\mathcal N_y-1}=1\\).\n\ndef potential_external_forces(u):\n    N = u.shape[0] - 1\n    V = (u[-1, 0, 0] + u[-1, -1, 0] - u[0, 0, 0] - u[0, -1, 0]) / 2\n    for y in range(1, N):\n        V += u[-1, y, 0] - u[0, y, 0]\n    V *= Q\n    return V"
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#potential-energy",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#potential-energy",
    "title": "Symbolic analysis of a spring mesh",
    "section": "1.3 Potential energy",
    "text": "1.3 Potential energy\nMinimization of the potential energy \\(\\Pi=\\mathcal U-\\mathcal V\\) with respect to the unknown nodal displacements then delivers the solution.\n\ndef potential_energy(u):\n    U = strain_energy(u)\n    V = potential_external_forces(u)\n    return U - V"
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness",
    "title": "Symbolic analysis of a spring mesh",
    "section": "1.4 Apparent stiffness",
    "text": "1.4 Apparent stiffness\nThe apparent stiffness was defined in the post that introduced the representative volume element. It is computed as the following ratio \\[\\tilde{A}_x^\\text{app}=\\frac{\\langle N_{xx}\\rangle}{\\langle\\varepsilon_{xx}\\rangle}\\] where the macroscopic strain \\(\\langle\\varepsilon_{xx}\\rangle\\) reads\n\\[\\langle\\varepsilon_{xx}\\rangle=\\frac1{\\mathcal N_x\\mathcal N_y\\Delta x}\\sum_{j=0}^{\\mathcal N_y}w_j\\vec e_x⋅\\bigl(\\vec u_{\\mathcal N_x,j}-\\vec u_{0, j}\\bigr).\\]\nComparison with the potential of external forces delivers the following convenient expression\n\\[\\langle\\varepsilon_{xx}\\rangle=\\frac{\\mathcal V}{Q\\mathcal N_x\\mathcal N_y\\Delta x}.\\]\nThe macroscopic membrane stress \\(\\langle N_{xx}\\rangle\\) is given by\n\\[\\langle N_{xx}\\rangle=\\frac Q{\\Delta y},\\]\nwhich finally leads to the expression\n\\[\\tilde{A}_x^\\text{app}\n=\\mathcal N_x\\mathcal N_y\\frac{\\Delta x}{\\Delta y}\\frac{Q^2}{\\mathcal V}\n=\\frac{\\mathcal N_x\\mathcal N_y}{\\tan\\theta}\\frac{Q^2}{\\mathcal V}.\\]\n\ndef apparent_stiffness(u):\n    Nx, Ny = u.shape[0] - 1, u.shape[1] - 1\n    return Nx * Ny / sympy.tan(θ) * Q ** 2 / potential_external_forces(u)\n\nThe above functions are used in the sections below to compute the solution for 1×1, 2×2 and 3×3 systems."
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-11-system",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-11-system",
    "title": "Symbolic analysis of a spring mesh",
    "section": "5.1 Apparent stiffness of the 1×1 system",
    "text": "5.1 Apparent stiffness of the 1×1 system\n\nsympy.Eq(A_app, A1)\n\n\\(\\displaystyle \\tilde{A}_x^\\text{app} = \\frac{4 \\chi k \\left(\\chi + 1\\right)}{2 \\chi + 1}\\)"
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-22-system",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-22-system",
    "title": "Symbolic analysis of a spring mesh",
    "section": "5.2 Apparent stiffness of the 2×2 system",
    "text": "5.2 Apparent stiffness of the 2×2 system\n\nsympy.Eq(A_app, A2)\n\n\\(\\displaystyle \\tilde{A}_x^\\text{app} = \\frac{8 \\chi k \\left(\\chi + 1\\right) \\left(\\chi + 2\\right)}{\\left(2 \\chi + 3\\right) \\left(3 \\chi + 2\\right)}\\)"
  },
  {
    "objectID": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-33-system",
    "href": "posts/20210512-Symbolic_analysis_of_a_spring_mesh/index.html#apparent-stiffness-of-the-33-system",
    "title": "Symbolic analysis of a spring mesh",
    "section": "5.3 Apparent stiffness of the 3×3 system",
    "text": "5.3 Apparent stiffness of the 3×3 system\n\nsympy.Eq(A_app, A3)\n\n\\(\\displaystyle \\tilde{A}_x^\\text{app} = \\frac{144 \\chi k \\left(\\chi + 1\\right) \\left(4 \\chi^{4} + 24 \\chi^{3} + 41 \\chi^{2} + 24 \\chi + 4\\right)}{480 \\chi^{5} + 2888 \\chi^{4} + 5616 \\chi^{3} + 4771 \\chi^{2} + 1800 \\chi + 236}\\)"
  },
  {
    "objectID": "posts/20140219-On_the_double_dot_product/index.html",
    "href": "posts/20140219-On_the_double_dot_product/index.html",
    "title": "On the double dot product",
    "section": "",
    "text": "The double dot product of two tensors is the contraction of these tensors with respect to the last two indices of the first one, and the first two indices of the second one. Whether or not this contraction is performed on the closest indices is a matter of convention. In this post, I will show that this choice has some important implications.\nLet \\(\\mathbf a\\) and \\(\\mathbf b\\) be two second-rank tensors. The following two alternative definitions might be adopted for the double dot product \\(\\mathbf\na:\\mathbf b\\)\nIn continuum mechanics, most second-rank tensors (strain, stress) are symmetric, so that both definitions coincide. In the general case of asymmetric tensors however, it is important to check which convention is adopted by the author. In the present post, we examine both definitions in turn, and how they affect the expression of the transpose of fourth-rank tensors, the definition of which is first recalled."
  },
  {
    "objectID": "posts/20140219-On_the_double_dot_product/index.html#definition-1",
    "href": "posts/20140219-On_the_double_dot_product/index.html#definition-1",
    "title": "On the double dot product",
    "section": "Definition 1",
    "text": "Definition 1\nIn this section, Definition 1 of the double dot product is examined \\[\n\\mathbf x:\\mathbf y=x_{ij}\\,y_{ji},\n\\tag{3}\\] where \\(\\mathbf x\\) and \\(\\mathbf y\\) are second-rank tensors. Then \\(\\langle\\mathbf\nx,\\mathbf y\\rangle=\\mathbf x^{\\mathsf T}:\\mathbf y\\). Let \\(\\mathbf A\\) be a fourth-rank tensor. Eqs. (1) and (2) are used in conjunction with Eq. (3) to find the components of \\(\\mathbf A^{\\mathsf T}\\) \\[\n\\langle\\mathbf x, \\mathbf A:\\mathbf y\\rangle\n=\\mathbf x^{\\mathsf T}:\\bigl(\\mathbf A:\\mathbf y\\bigr)\n=\\bigl(\\mathbf x^{\\mathsf T}\\bigr)_{ji}\\bigl(\\mathbf A:\\mathbf y\\bigr)_{ij}\n=x_{ij}\\,A_{ijkl}\\,y_{lk}.\n\\]\nIntroducing the fourth-rank tensor \\(\\mathbf A'\\) defined component-wise by \\(A_{ijkl}'=A_{lkji}\\), the above identity reads \\[\n\\langle\\mathbf x, \\mathbf A:\\mathbf y\\rangle\n=y_{lk}\\,A_{lkji}'\\,x_{ij}\n=\\bigl(\\mathbf y^{\\mathsf T}\\bigr)_{kl}\\bigl(\\mathbf A':\\mathbf x\\bigr)_{lk}\n=\\mathbf y^{\\mathsf T}:\\bigl(\\mathbf A':\\mathbf x\\bigr)\n=\\langle\\mathbf A':\\mathbf x,\\mathbf y\\rangle,\n\\]\nwhich proves that \\(\\mathbf A'\\) is the transpose of \\(\\mathbf A\\). In other words, if Definition 1 is adopted for the double dot product, then the components of the transpose of any fourth-rank tensor \\(\\mathbf A\\) read \\[\n\\bigl(\\mathbf A^{\\mathsf T}\\bigr)_{ijkl}=A_{lkji}.\n\\tag{4}\\]"
  }
]